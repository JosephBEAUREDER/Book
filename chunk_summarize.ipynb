{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of all chunk : 2136\n",
      "Title: La question anthropologique (Cours 1954-1955), Author: Michel Foucault, Size: 2308 characters\n",
      "Title: Sainte Beuve, Biographie, Author: A. J. Pons, Size: 2360 characters\n",
      "Title: Histoire du structuralisme, Tome 2, Author: François Dosse, Size: 2083 characters\n",
      "Title: Franz Kafka, Author: Bernard Lahire, Size: 1516 characters\n",
      "Title: La question anthropologique (Cours 1954-1955), Author: Michel Foucault, Size: 1613 characters\n",
      "Title: Franz Kafka, Author: Bernard Lahire, Size: 2968 characters\n",
      "Title: Histoire du structuralisme, Tome 1, Author: François Dosse, Size: 1955 characters\n",
      "Title: La question anthropologique (Cours 1954-1955), Author: Michel Foucault, Size: 2083 characters\n",
      "Title: Franz Kafka, Author: Bernard Lahire, Size: 2482 characters\n",
      "Title: Franz Kafka, Author: Bernard Lahire, Size: 2365 characters\n",
      "Title: La fabrique des sciences sociales, Author: Johann Michel, Size: 2872 characters\n",
      "Title: Sainte Beuve, Biographie, Author: A. J. Pons, Size: 2044 characters\n",
      "Title: La question anthropologique (Cours 1954-1955), Author: Michel Foucault, Size: 2070 characters\n",
      "Title: La fabrique des sciences sociales, Author: Johann Michel, Size: 1532 characters\n",
      "Title: La question anthropologique (Cours 1954-1955), Author: Michel Foucault, Size: 2939 characters\n",
      "Title: Histoire du structuralisme, Tome 1, Author: François Dosse, Size: 2315 characters\n",
      "Title: Franz Kafka, Author: Bernard Lahire, Size: 1722 characters\n",
      "Title: Histoire du structuralisme, Tome 2, Author: François Dosse, Size: 2188 characters\n",
      "Title: Histoire du structuralisme, Tome 2, Author: François Dosse, Size: 2880 characters\n",
      "Title: Histoire du structuralisme, Tome 1, Author: François Dosse, Size: 1633 characters\n",
      "Title: La question anthropologique (Cours 1954-1955), Author: Michel Foucault, Size: 2112 characters\n",
      "Title: Histoire du structuralisme, Tome 1, Author: François Dosse, Size: 2665 characters\n",
      "Title: La question anthropologique (Cours 1954-1955), Author: Michel Foucault, Size: 1713 characters\n",
      "Title: Histoire du structuralisme, Tome 1, Author: François Dosse, Size: 2194 characters\n",
      "Title: Histoire du structuralisme, Tome 2, Author: François Dosse, Size: 2726 characters\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import openai\n",
    "from semantic_text_splitter import TextSplitter\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def split_and_merge_text(text, min_size=2500, max_size=3000):\n",
    "    \"\"\"\n",
    "    Splits the text using a TextSplitter and merges smaller chunks to meet size constraints.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be split.\n",
    "        min_size (int): The minimum size for each chunk.\n",
    "        max_size (int): The maximum size for each chunk.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of merged chunks that meet the size constraints.\n",
    "    \"\"\"\n",
    "    # Initialize the splitter with the chunk size range\n",
    "    splitter = TextSplitter((min_size, max_size))\n",
    "\n",
    "    # Split the text into initial chunks\n",
    "    initial_chunks = splitter.chunks(text)\n",
    "\n",
    "    # Merge chunks smaller than the minimum size\n",
    "    merged_chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for chunk in initial_chunks:\n",
    "        if len(current_chunk) + len(chunk) <= max_size:\n",
    "            current_chunk += chunk\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                merged_chunks.append(current_chunk)\n",
    "            current_chunk = chunk\n",
    "\n",
    "    if current_chunk:\n",
    "        merged_chunks.append(current_chunk)\n",
    "\n",
    "    # Ensure all chunks meet the minimum size requirement\n",
    "    final_chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for chunk in merged_chunks:\n",
    "        if len(chunk) < min_size:\n",
    "            current_chunk += chunk\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                final_chunks.append(current_chunk)\n",
    "                current_chunk = \"\"\n",
    "            final_chunks.append(chunk)\n",
    "\n",
    "    if current_chunk:\n",
    "        final_chunks.append(current_chunk)\n",
    "\n",
    "    return final_chunks\n",
    "\n",
    "def extract_title_and_author(text):\n",
    "    \"\"\"\n",
    "    Extracts the title and author from the first few lines of a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing title and author information.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the title and author as strings.\n",
    "    \"\"\"\n",
    "    title = None\n",
    "    author = None\n",
    "\n",
    "    # Split the text into lines and check the first few lines\n",
    "    lines = text.splitlines()\n",
    "    for line in lines[:5]:  # Look at the first few lines for these fields\n",
    "        if line.startswith(\"Titre :\"):\n",
    "            title = line.split(\":\", 1)[1].strip()\n",
    "        elif line.startswith(\"Auteur :\"):\n",
    "            author = line.split(\":\", 1)[1].strip()\n",
    "\n",
    "    return title, author\n",
    "\n",
    "# Function to retrieve a specific insight from a chunk\n",
    "def retrieve_insight(chunk, author, title):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": (\n",
    "                \"You are an analytical and thought-provoking assistant specializing in extracting deep insights from social science texts. \"\n",
    "                \"Your goal is to identify nuanced perspectives, uncover underlying themes, and present information in an engaging and intellectually stimulating manner. \"\n",
    "                \"Focus on creating clear, concise, and structured breakdowns of ideas, avoiding mainstream entertainment references.\"\n",
    "            )},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"\"\"Le texte suivant est extrait de \"{title}\", écrit par {author}.\n",
    "                    En mettant l'accent sur la perspective de {author}, identifie l'idée générale qu'il exprime selon son point de vue.\n",
    "                    Ensuite, décompose cette idée en étapes successives, chacune correspondant à une phrase courte.\n",
    "                    Chaque phrase doit décrire une étape claire et concise pour arriver à l'idée générale, tout en s'appuyant sur des détails du texte.\n",
    "                    Introduit chaque étape par \"1.\", \"2.\"...\n",
    "                    Si une phrase est trop longue, divise-la en deux phrases courtes.\n",
    "                    Voici le texte :\\n\\n {chunk}\\n\\n\n",
    "                    Étapes :\"\"\"\n",
    "                )\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def get_unique_filename(base_name):\n",
    "    # Split the base name into name and extension\n",
    "    name, ext = os.path.splitext(base_name)\n",
    "    counter = 0\n",
    "    new_name = base_name\n",
    "    # Increment counter until a non-existing filename is found\n",
    "    while os.path.exists(new_name):\n",
    "        counter += 1\n",
    "        new_name = f\"{name}_{counter}{ext}\"\n",
    "    return new_name\n",
    "\n",
    "def save_all_insights_to_json(output_file, insights):\n",
    "    # Get a unique filename for the output file\n",
    "    output_file = get_unique_filename(output_file)\n",
    "\n",
    "    # Load existing data if the file exists\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "    else:\n",
    "        data = {}\n",
    "\n",
    "    # Update the existing data with the new insights\n",
    "    data.update(insights)\n",
    "\n",
    "    # Save the updated data back to the file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # Update the pointer file with the path to the latest JSON file\n",
    "    pointer_file = \"config.json\"\n",
    "    with open(pointer_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"latest_file\": output_file}, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# Initialize the \"all_chunks\" variable to store data\n",
    "all_chunks = []\n",
    "\n",
    "# Path to the folder containing text files\n",
    "folder_path = \"Book\"\n",
    "\n",
    "# Loop through all .txt files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        # Read the text file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # Create the chunks for this file\n",
    "        chunks = split_and_merge_text(text, min_size=1500, max_size=3000)\n",
    "\n",
    "        # Get the title and author from the text\n",
    "        title, author = extract_title_and_author(text)\n",
    "\n",
    "        # Add chunks to all_chunks with their associated title and author\n",
    "        for chunk in chunks:\n",
    "            all_chunks.append({\n",
    "                \"title\": title,\n",
    "                \"author\": author,\n",
    "                \"chunk\": chunk,\n",
    "                \"size\": len(chunk),\n",
    "            })\n",
    "\n",
    "\n",
    "print(\"Lenght of all chunk : \" + str(len(all_chunks)))\n",
    "\n",
    "\n",
    "# Randomly select 20 chunks from \"all_chunks\"\n",
    "random_chunks = random.sample(all_chunks, min(25, len(all_chunks)))\n",
    "\n",
    "# Assuming all_chunks is already defined\n",
    "titles_and_authors = [\n",
    "    {\"title\": chunk[\"title\"], \"author\": chunk[\"author\"], \"size\": chunk[\"size\"]}\n",
    "    for chunk in random_chunks\n",
    "]\n",
    "\n",
    "# Display the unique titles, authors, and sizes\n",
    "for item in titles_and_authors:\n",
    "    print(f\"Title: {item['title']}, Author: {item['author']}, Size: {item['size']} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'La question anthropologique (Cours 1954-1955)', 'author': 'Michel Foucault', 'chunk': '3. Mais il faut tenir compte [, aussi,] du fait que les esprits ont dans le monde une pesanteur ontologique particulière (due au fait qu’ils peuvent « entrer en conversation ou du moins en société », Discours de métaphysique…, 35104) et que le monde le plus parfait ne peut être que le monde où ils peuvent acquérir le plus de perfection. Donc la subordination ontologique de la matière à l’esprit a pour suite la subordination de la perfection et du bonheur de la matière au bonheur et à la perfection de l’esprit. « La république générale des esprits est la plus noble partie de l’univers » (Leibniz, Correspondance avec Arnauld105).\\n\\n\\n\\nCe qui a pour conséquences que :\\n\\n– « De toutes les créatures qui nous environnent, il n’y a que l’esprit de l’homme qui soit susceptible d’un vrai bonheur » (Dialogue entre Polidore et Théophile106). Les autres (les âmes sans esprit) ne sont capables ni de bonheur ni de malheur.\\n\\n– Ce bonheur ne peut se réaliser que comme bonheur pris au bonheur les uns des autres. D’où l’intersubjectivité de la perfection : « Les esprits sont les substances les plus perfectionnables, et leurs perfections ont cela de particulier qu’elles s’entr’empêchent le moins, ou plutôt qu’elles s’entr’aident » (Discours de métaphysique…, 36107). La perfection de l’homme, c’est d’être citoyen, la vérité du monde, c’est d’être une cité.\\n\\n– C’est pourquoi finalement les lois de la nature obéissent aux lois du monde des esprits, qui ne sont elles-mêmes que les lois de la cité des bienheureux : « Tout est disposé en sorte que les lois de la force ou les lois purement matérielles conspirent dans tout l’univers à exécuter les lois de la justice ou de l’amour […] » (Leibniz, Correspondance avec Arnauld108).\\n\\nLa vérité de la nature emprunte donc son sens à la juridiction de la cité. La nature n’a pris le visage de monde que dans la mesure où son sens était de devenir entièrement monde humain dans une sorte de téléologie immanente, où la loi du meilleur monde possible est en fait la loi du monde le plus humain possible. Et on comprend que, dans cette téléologie universelle où l’homme culmine, la nature, dont on trouvait chez Descartes et Malebranche la préséance absolue, ait cédé la place à une notion de monde, par laquelle Leibniz donne la main aux philosophies précartésiennes.', 'size': 2308}\n"
     ]
    }
   ],
   "source": [
    "print(random_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve list of insights from chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each chunk and collect all insights\n",
    "all_insights = {}\n",
    "for i, chunk in enumerate(random_chunks, start=1):\n",
    "    # Retrieve an insight from the chunk\n",
    "    insight = retrieve_insight(chunk['chunk'], chunk['author'], chunk['title'])\n",
    "\n",
    "    # Parse the insight into individual points\n",
    "    points = [line.strip() for line in insight.strip().split('\\n') if line]\n",
    "\n",
    "    # Construct the JSON structure for this entry\n",
    "    all_insights[str(i)] = {\n",
    "        \"Title and author\": f\"{chunk['title']}, {chunk['author']}\",\n",
    "        \"Content\": points\n",
    "    }\n",
    "\n",
    "# Save all collected insights into a single JSON file\n",
    "save_all_insights_to_json(\"Insights/insights.json\", all_insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve questions from chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve a specific insight from a chunk\n",
    "def retrieve_question(chunk, author, title):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": (\n",
    "                \"You are an analytical and thought-provoking assistant specializing in extracting deep insights from social science texts avoiding mainstream entertainment references. \"\n",
    "                \"Your goal is to identify nuanced perspectives, uncover underlying themes, and present information in an engaging and intellectually stimulating manner. \"\n",
    "            )},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"\"\"Le texte suivant est extrait de \"{title}\", écrit par {author}.\n",
    "                    Résume en une phrase une des questions que pose ce texte.\n",
    "                    Voici le texte :\\n\\n {chunk}\\n\\n\n",
    "                    Étapes :\"\"\"\n",
    "                )\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Bernard Lahire',\n",
       "  'Franz Kafka, Chapitre 1',\n",
       "  'Titre : Franz Kafka, Chapitre 1\\nAuteur : Bernard Lahire\\n\\n\\nChapitre 1\\nL’enfermement dans le champLa seule manière de se défaire réellement de problèmes scientifiques, si l’on considère qu’une théorie sociologique est essentiellement un univers cohérent de problèmes-solutions articulés, c’est de les affronter, de les faire travailler, de les soumettre à examens, pour finalement les dépasser en découvrant leurs limites de validité et leur champ de pertinence. Partant d’une telle conception de la pratique scientifique, on ne peut qu’être d’accord avec l’analyse de Thomas S. Kuhn selon laquelle «\\u2005seules les investigations fermement enracinées dans la tradition scientifique contemporaine ont une chance de briser cette tradition et de donner naissance à une nouvelle1\\u2005». Et l’épistémologue ajoutait à la suite cette proposition d’une grande justesse : «\\u2005Le savant productif doit être un traditionaliste qui aime à s’adonner à des jeux complexes gouvernés par des règles préétablies, pour être un innovateur efficace qui découvre de nouvelles règles et de nouvelles pièces avec lesquelles il peut continuer à jouer2.\\u2005» Prolongeant une œuvre, on s’en détache fatalement, peu à peu, pour formuler de nouveaux problèmes et créer ses voies propres de résolution. Mais c’est tout le contraire de la stratégie qui consiste à laisser en plan l’adversaire en désertant le terrain pour créer son propre jeu en faisant tout pour faire préférer, au plus grand nombre possible, le nouveau jeu.\\n\\nFaire le choix déterminé (dans les deux sens du terme) de la stratégie de confrontation (vs stratégie de désertion), c’est toutefois prendre le risque de s’attirer les foudres de camps opposés, plutôt que de cumuler les faveurs, et de n’avoir pour lecteurs compréhensifs que le public des francs-tireurs de tous bords et de toutes disciplines. La chance d’être lu, et de l’être avec le minimum de patience nécessaire pour que la lecture soit correcte et ne soit pas le simple effet d’une projection d’a priori sur l’auteur du texte, est ainsi très faible. Mais un tel risque est à prendre lorsqu’on vise moins à plaire aux parties en présence qu’à convaincre à plus long terme de l’intérêt scientifique d’une démarche.'},\n",
       " {'Bernard Lahire',\n",
       "  'Franz Kafka, Chapitre 1',\n",
       "  'Impossible donc de parler de la création littéraire en sociologue sans se situer explicitement par rapport à une théorie du champ littéraire, qui est une déclinaison particulière de la théorie générale des champs. C’est d’autant plus difficile que cette dernière affiche comme ambition de penser autant les dimensions du monde littéraire les plus classiquement reconnues comme «\\u2005sociales\\u2005» (les trajectoires sociales et littéraires d’écrivains, la structuration de l’espace des positions littéraires et des luttes pour la domination symbolique, la sociologie historique des institutions littéraires telles que les maisons d’édition, les collections ou les revues, les stratégies éditoriales, les mouvements, courants ou écoles littéraires, les manifestes et manifestations littéraires de toutes sortes, le rôle de tous ceux qui — des éditeurs aux critiques en passant par l’institution scolaire, les médias et tous les pourvoyeurs de prix littéraires — contribuent à faire la valeur des œuvres) que les dimensions les plus spécifiquement littéraires des œuvres (thématiques, compositionnelles, stylistiques). Pierre Bourdieu affirmait même que «\\u2005la notion de champ permet de dépasser l’opposition entre lecture interne et analyse externe sans rien perdre des acquis et des exigences de ces deux approches, traditionnellement perçues comme inconciliables3\\u2005».'},\n",
       " {'Bernard Lahire',\n",
       "  'Franz Kafka, Chapitre 1',\n",
       "  'Les commentaires, positifs ou négatifs, portant sur une théorie aussi générale souffrent habituellement d’un certain nombre de défauts. Tout d’abord, les commentateurs ne distinguent pas toujours suffisamment ce qui est de l’ordre de l’affirmation d’un certain nombre de principes ou de directions théoriques et ce qui relève de leur mise en œuvre effective. De ce point de vue, on peut dire, sans faire offense aux utilisateurs de ses concepts, que Pierre Bourdieu a plus affirmé le dépassement des approches internes et externes, formelles et sociologiques, qu’il ne l’a réellement prouvé par des actes précis de recherche. Or, tout sociologue d’enquête sait bien qu’entre les principes et les concrétisations théoriques, méthodologiques et empiriques de ces principes, il y a parfois un gouffre. Le parcours, semé d’embûches, et notamment de limitations empiriques, qui mène des principes à l’étude circonscrite et fouillée amène souvent à la reformulation du problème initial, à la modification partielle des objectifs ou même à l’abandon des idées de départ. Le principe qui devrait guider tout examinateur d’une œuvre est celui qui consiste à ne croire que ce qu’il voit et à situer le débat sur le terrain de ce qui est fait, plutôt que sur celui des affirmations concernant ce que l’on prétend être en mesure de faire grâce au modèle théorique en question. Dans la réalité des travaux, la sociologie du champ littéraire a prouvé sa fécondité essentiellement en tant que sociologie des producteurs plutôt que comme sociologie des productions. Et lorsqu’elle parle des œuvres, elle est d’abord et avant tout une sociologie de la production sociale de la valeur des œuvres (des qualités littéraires qui leur sont collectivement attribuées et de leur degré de légitimité littéraire)4 et presque jamais une sociologie de la création littéraire (en tant qu’étude consacrée aux œuvres mêmes et à leur fabrication).'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Initialize the \"all_chunks\" variable to store data\n",
    "all_chunks = []\n",
    "\n",
    "# Path to the folder containing text files\n",
    "folder_path = \"Book\"\n",
    "\n",
    "# Loop through all .txt files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        # Read the text file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # Create the chunks for this file\n",
    "        chunks = split_and_merge_text(text, min_size=1500, max_size=3000)\n",
    "\n",
    "        # Get the title and author from the text\n",
    "        title, author = extract_title_and_author(text)\n",
    "\n",
    "        # Add chunks to all_chunks with their associated title and author\n",
    "        for chunk in chunks:\n",
    "            all_chunks.append({\n",
    "                title,\n",
    "                author,\n",
    "                chunk\n",
    "            })\n",
    "\n",
    "# Check the first few entries to confirm structure\n",
    "all_chunks[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Françoise Waquet\n",
      "L'ordre matériel du savoir\n"
     ]
    }
   ],
   "source": [
    "# Extract title and author from the text\n",
    "with open('Book/LOrdre matériel du savoir.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "title = None\n",
    "author = None\n",
    "\n",
    "# Extract title and author\n",
    "for line in lines[:5]:  # Look at the first few lines for these fields\n",
    "    if line.startswith(\"Titre :\"):\n",
    "        title = line.split(\":\", 1)[1].strip()\n",
    "    elif line.startswith(\"Auteur :\"):\n",
    "        author = line.split(\":\", 1)[1].strip()\n",
    "        \n",
    "print(author)\n",
    "print(title)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
