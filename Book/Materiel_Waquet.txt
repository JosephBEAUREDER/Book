Titre : L'ordre matériel du savoir
Auteur : Françoise Waquet

Introduction




* * *





« Tout commence par un tête-à-tête avec d’innombrables lectures. Pour écrire Les Structures de la parenté, j’ai débrouillé quelque chose comme sept mille livres et articles », répondait Claude Lévi-Strauss à qui l’interrogeait sur sa manière de travailler, d’élaborer un livre et de le rédiger. « Après le stade des fiches de lecture vient celui des notes de cours », poursuivait-il. « Depuis que je suis dans l’enseignement supérieur, tout ce que j’écris est indissociable de ce que j’enseigne. Il s’agit d’essayer les choses à la fois sur moi-même, en les formulant, et sur un auditoire, en observant comment il réagit. » La phase de rédaction consistait en deux temps. « Je commence par griffonner le brouillon du livre tout entier en m’imposant pour discipline de ne jamais m’arrêter. Peu importent les redites, les phrases qui s’arrêtent à mi-chemin ou qui n’ont aucun sens. » Suivait le stade de l’écriture qui « s’apparente au bricolage. Il ne s’agit pas, en effet, de remplacer des phrases mal écrites par des phrases bien écrites, mais de retrouver ce que j’aurais dit dès le départ […], si toutes sortes d’inhibitions n’avaient entravé le cours des choses. Entouré d’une montagne d’ouvrages et de dictionnaires […], je commence donc par raturer le premier jet tapé, à cette fin, à grands intervalles, à la machine, en rajoutant des corrections entre les lignes au moyen de divers feutres ou crayons de couleur (je ne choisis jamais la couleur a priori : ce serait établir quelque chose d’irrévocable). Lorsque le manuscrit est devenu illisible, je le barbouille de blanc afin de pouvoir le corriger à nouveau. Lorsque cette opération est devenue à son tour impossible, je me donne le moyen de réécrire ce qui doit l’être à l’aide de petits morceaux de papier que je découpe et colle sur le manuscrit ». S’était intercalée, entre fiches et rédaction, la phase portant à la conception de l’économie générale du travail : « Au départ, je me contente de distribuer mes fiches dans mes boîtes de façon arbitraire, selon les étiquettes les plus commodes […]. Puis, au moment où j’ai l’impression que je puis et je dois me mettre à écrire, je reprends toutes ces fiches. Je les étale sur ma table. Je les empile. Je cherche des arrangements entre les différents paquets […]. Je redistribue alors mes fiches […]. C’est après un certain nombre de ces regroupements (une bonne dizaine pour Les Structures de la parenté) […] que j’aboutis à un plan qui n’est pas pensé dans l’abstrait mais résulte d’une sorte de jeu manuel. » Encore il convient d’ajouter ce que le récit ne dit pas mais que des photos assortissant la publication montrent : les schémas tracés sur des feuilles de papier, les mots écrits sur le tableau, les clichés pris sur le terrain1.

Avec les écritures et les collages, avec la montagne de livres et d’articles, avec « les paroles aventurées » lors des cours, avec les images et les représentations graphiques, apparaissent quelques-unes des techniques intellectuelles auxquelles cet ouvrage est consacré. L’expression « techniques intellectuelles » ou « technologies intellectuelles » désigne les « outils » employés pour repérer et traiter l’information, pour produire et transmettre le savoir, outils qui réfèrent à l’écrit, à l’imprimé, à l’image, au numérique2. « Le jeu manuel » de Lévi-Strauss – la main qui distribue les fiches à l’instar de cartes à jouer –, invite à intégrer dans cet outillage les gestes que les savants accomplissent dans leur travail. « Les mains de l’intellect3 » ou, pour le dire autrement, le « penser avec ses doigts4 » ne sont pas seuls à l’œuvre dans les opérations du savoir où interviennent, suivant des modalités variables, les sens autres que le toucher. Ainsi, pour en rester à un exemple très simple, l’examen clinique dans ses étapes classiques de l’anamnèse, de l’inspection, de la palpation, de la percussion et de l’auscultation, mobilise à la fois la main experte, l’œil qui sait voir et l’oreille qui sait entendre.

En centrant la recherche sur les techniques intellectuelles mises en œuvre dans le monde savant, on se propose d’explorer une culture dans sa matérialité, c’est-à-dire dans sa dimension non idéelle – ce qui ne veut pas dire, et on le verra, que lesdites techniques, y compris le plus petit geste, n’aient pas été un jour pensées, réfléchies, argumentées. Cette exploration s’inscrit dans une approche que j’intitule écologie du savoir, une approche qu’au fil de mes travaux j’ai été amenée à formuler de façon d’abord empirique, puis méthodologique, en considérant le monde intellectuel comme un milieu. Il m’est apparu qu’une étude de ce monde ne pouvait être complète si l’on s’arrêtait à ses productions (idées, découvertes, etc.) ainsi qu’à ses structures institutionnelles et sociales ; elle devait intégrer les relations unissant les acteurs entre eux et à leur milieu. Par milieu, j’entends le monde dans lequel les acteurs agissent et pensent : un monde fait de centres et de périphéries, de savoirs situés et d’horizons communs d’intelligibilité, de courants d’idées et de passions, ainsi que de représentations et de préconceptions plus générales – telles les notions République des Lettres et communauté scientifique internationale avec leurs imaginaires – qui ne jouent pas moins dans l’ordre du savoir. Par relations, j’entends naturellement les liens entre les acteurs, liens singuliers (de personne à personne) et pluriels (les réseaux, les communautés), mais aussi les vecteurs des connaissances : soit, de façon générale, la parole, l’écriture, l’imprimé, les nouvelles technologies, ainsi que les modes de la communication non verbale, à commencer par les instruments, les modèles anatomiques, les maquettes et les collections scientifiques5 ; soit, de façon particulière, des modalités qui sont devenues des genres, tels l’article, le cours, le séminaire, etc., mais aussi des pratiques informelles, par exemple, la conversation impromptue, le gribouillis fait pour préciser les choses à soi-même ou les expliciter à autrui. Des travaux sur un certain nombre de ces vecteurs, personnels et réels, référant plus particulièrement à l’oralité6, m’ont permis de montrer la place et la fonction qui sont les leurs dans la production et la transmission des connaissances ; ils ont aussi mis en évidence l’infinie variété de formes qu’engendre une technique, la conjugaison de plusieurs techniques dans un même produit, la multiplicité des techniques convoquées dans une opération intellectuelle.

Ces remarques, accumulées au fil de recherches antérieures, sont à la base de ce travail systématique consacré à l’étude des techniques intellectuelles dans le monde occidental pendant la période moderne et contemporaine (XVIe-XXIe siècles). Il n’est pas une histoire de ces techniques, mais une histoire de leurs usages, soit très précisément de leurs emplois et des discours qui ont été tenus par ceux-là mêmes qui les utilisaient. Il est en quelque sorte une archéologie des techniques intellectuelles, du point de vue des usagers. Pour prendre un exemple, on ne trouvera rien ici sur le microscope et ses principes, sur sa diffusion et ses perfectionnements au fil du temps ; par contre, on s’arrêtera aux opinions de ceux qui ont employé cet instrument ainsi qu’aux modalités selon lesquelles ils l’ont approprié quand il ne suffit pas de regarder pour voir, mais qu’il faut éduquer le regard, voire dresser le corps tout entier. Ce point de vue « archéologique » explique donc que ce n’est pas tant la science faite qui est au cœur de cet ouvrage que la science en train de se faire, et de se faire dans sa matérialité même. Ce qui amène à privilégier des situations concrètes en suivant le conseil donné par François Jacob : « si vous voulez savoir comment fonctionnent les scientifiques […], n’écoutez pas ce qu’ils disent. Regardez ce qu’ils font7. »

Ici, le regard s’est voulu ample dans le temps comme dans l’espace. Il englobe un arc chronologique de plus de cinq siècles qui a son point de départ idéal dans l’invention de l’imprimerie, une technique qui a été aussi rapidement que largement employée par les savants. Il embrasse le monde occidental qui d’ailleurs, à l’aune des techniques intellectuelles, du moins de certaines d’entre elles, devient global : ainsi, aujourd’hui, un article scientifique est partout organisé suivant un même format IMRAD. Il balaie plusieurs disciplines (l’archéologie, l’histoire de l’art, la géographie, la botanique, la biologie, la médecine, la chirurgie) à des moments significatifs de leur histoire ; des lectures sur des techniques qui, pour nombre d’entre elles, sont d’un emploi quasiment général dans toutes les disciplines – tels les graphiques – augmentent à la faveur d’exemples la largeur du champ. Enfin, ce regard, on a fait en sorte qu’il soit mobile quand la vue d’un objet amène à percevoir des réalités autres. La « table à écrire » est assurément un outil essentiel du travail intellectuel8 ; elle est ainsi une pièce majeure du mobilier dans une bibliothèque publique, domaine de la lecture assise à une place parfois numérotée. Constater cela n’est pas sans rappeler qu’il existe d’autres modalités de l’écriture et de la lecture dans le monde savant, qu’elles soient dictées par les convenances personnelles ou par les circonstances. Ce peut être par terre : ainsi, l’exégète Richard Simon travaillait « ordinairement couché sur un tapis fort épais avec quelques coussins. Il avait […] auprès de lui une écritoire, du papier et les livres qu’il voulait consulter9 ». Ce peut être aussi un lit aménagé en bureau-bibliothèque, suivant l’ingénieux système mis au point par l’érudit de Bari Giacinto Gimma10. Ou bien plus simplement les genoux du chercheur comme le montrent des photos sur le terrain de Françoise Héritier ou de Maurice Godelier11. Sans compter que dans les bibliothèques publiques les lecteurs lisent à l’occasion debout, par exemple entre deux travées, prenant un livre sur le rayonnage et parcourant quelques passages pour une information rapide ou pour voir si l’ouvrage vaut la peine d’y consacrer plus de temps : lecture cursive, souvent inconfortable et pourtant fondamentale car opérant un tri qui peut être lourd de conséquences intellectuelles.

Ce terrain d’enquête dans le monde savant reflète un choix personnel, fait de sympathies et de curiosités qui m’ont portée vers telle ou telle discipline ainsi que de l’intérêt qui a été le mien pour des techniques intellectuelles, que je les emploie ou que je les ai découvertes à l’occasion de cette recherche. Le parti est sélectif, j’en conviens ; il ne correspond pas moins à une base de travail non négligeable, une base dont la configuration m’a paru susceptible de répondre à un certain nombre de questions qui sont à l’agenda de l’histoire et de l’anthropologie des savoirs et d’aller au-delà de l’état de l’art en la matière.

Prendre en compte plusieurs disciplines et non une seule visait d’abord à éviter la critique aussi facile qu’usuelle d’un ailleurs toujours plus fertile. Mais surtout, cela répondait à un parti méthodologique : saisir, d’une part, la mise œuvre d’une même technique dans des contextes disciplinaires différents, d’autre part, les combinaisons de plusieurs techniques – ce qu’une seule discipline ne permettait pas toujours. Parti dont l’intérêt s’appréciera au rappel des démarches de l’historiographie des techniques intellectuelles. Les travaux d’ordre général rapportent des inventions et des successions, soit grosso modo écrit (et graphique), imprimé, photographie, numérique et, dans cette marche en avant, ils privilégient le changement, l’innovation, la rupture. Les études particulières consacrées au manuscrit, au livre, à la revue, à l’informatique, etc., considèrent la technique en question le plus souvent isolément ; d’éventuelles remarques, parfois de grande portée, sur la persistance de technologies antérieures ne dépassent pas le stade du constat ponctuel12. Pourtant, la seule observation du travail scientifique ouvre sur des perspectives autres : elle montre la présence concomitante de plusieurs techniques, la coexistence des plus récentes avec les plus archaïques. Elle invite à distinguer résolument invention et usage : ceci n’a pas chassé cela. On s’en convaincra en portant un simple regard sur le bureau d’un chercheur : livres, revues, photocopies, manuscrits, tapuscrits, fiches, bouts de papier et autres post it voisinent avec un téléphone, un ordinateur, une tablette ; encore plus que de coexistence entre ces produits dont la liste pourrait être augmentée selon les pratiques de travail individuelles et les disciplines, conviendrait-il de parler d’interaction. Des historiens des sciences et des savoirs ont bien porté une attention à la mise en œuvre de techniques intellectuelles, y compris aux gestes accomplis dans telle ou telle activité savante, livrant des analyses aussi fines que stimulantes13. Cependant, parce que les travaux tendent à privilégier une approche microscopique, ils n’appréhendent le plus souvent qu’une réalité limitée, située en un lieu et un moment uniques, hors de toute historicité. En conséquence de cette prédilection pour les études de cas, ils n’apportent guère pour saisir la logique d’un discours général sur les techniques employées dans le travail scientifique. Et ce, à la différence de travaux d’échelle et de nature autres, qui ont rapporté ces emplois, outre à des explications génériques – la facilitation, l’efficacité14 –, à des types d’opérations intellectuelles – collecte, analyse, diffusion, production –, à de grandes idées – l’objectivité, la rationalité – ou encore à des finalités sociopolitiques15. Explications, opérations, idées et finalités que l’on ne discutera pas. Reste que ce ne sont pas là les références des usagers qui raisonnaient sur la base de catégories autres.

Ces considérations dictées par l’historiographie et son examen sont au principe de la démarche ici adoptée : inventorier, décrire, analyser. Un travail d’objectivation et d’historicisation fait ressortir la masse des techniques intellectuelles qui ont cours dans le monde savant, une invention constante au fil du temps et une extrême diversification. C’est là l’objet de la première partie qui donnera à voir un outillage assurément considérable. Encore celui-ci est fait des ressources multiples qu’offrent les « techniques du corps » : dans les activités intellectuelles même les plus sophistiquées, un corps tout aussi éduqué qu’il l’est dans les situations que Marcel Mauss a considérées dans son célèbre article16 est un instrument de premier ordre.

Cet inventaire laisse apercevoir la nature hybride de bien des techniques intellectuelles. Caractère qu’une étude sur le poster, forme actuellement dominante de la communication scientifique, m’a permis de noter. Cette affiche est faite, en effet, de textes – écrit et imprimé –, de dessins, de graphiques, de schémas, de photos ; s’ajoutent parfois des éléments audiovisuels. Sans atteindre à cette complexité, bien des outils intellectuels révèlent au fil d’une description minutieuse la conjonction ou, plus précisément, l’intégration de plusieurs techniques. Ce que l’on montrera dans une deuxième partie qui prendra aussi les choses dans une perspective dynamique, en considérant des activités intellectuelles dans leur développement. Ainsi, pour en rester au poster, il a son aboutissement dans la session poster où l’auteur le présente, parle, montre, et où des « visiteurs » posent des questions, prennent des notes, discutent entre eux. Poster et session poster répondent à des « arts de faire » qui sont manifestes dans des recommandations données pour la composition matérielle de l’affiche et pour sa présentation orale afin d’assurer au mieux la communication visuelle et auditive d’un message scientifique. Ils allèguent une multimédialité et une multisensorialité qui seront ici le sujet d’une exploration plus ample et plus poussée sur la base d’exemples aussi divers que nombreux.

Les résultats livrés par l’inventaire et la description seront appréciés, dans une troisième partie, en prenant en compte les discours que les hommes du temps ont tenus sur les techniques qu’ils employaient, en analysant les arguments qu’ils avançaient, les façons dont ils pensaient, les constructions intellectuelles qui en ont résulté. Leurs discours ne sont pas ceux de philosophes ou de cogniticiens, mais de praticiens raisonnant dans des situations de travail extrêmement concrètes. Ce qui implique de porter attention au cadre d’élaboration de ces pensées pratiques, aux contextes disciplinaires, bien sûr, mais surtout à des opinions intellectuelles générales se rapportant non à la vie des idées mais à la vie des savants qui, hier comme aujourd’hui, ont eu le sentiment d’un manque crucial de temps et d’une croissance exponentielle de l’information.

La démarche qui vient d’être exposée rend compte du propos qui est au cœur de cet ouvrage : contribuer à une histoire matérielle de la culture savante, une histoire qui, objectivant ces structures élémentaires du savoir que sont les techniques intellectuelles, porte le regard sur « ce que la culture matérielle a de plus rebelle à la pensée : sa matérialité17 ». Décrire et analyser l’équipement matériel du monde savant à un moment de l’histoire, porter attention à des outils ordinaires, expliciter les usages qui en ont été faits et les discours qu’ils ont suscités, amènent à dresser un état des lieux des pratiques savantes pendant cinq siècles. Cela conduit d’abord à rendre manifeste ce que l’on ne voit pas ou plus, comme l’alinéa qui ouvre ce paragraphe ou l’index qui clôt cet ouvrage, des modalités quasiment transparentes qui ont été ou sont l’ordinaire du chercheur, telles la fiche, l’image et sa légende, le format IMRAD de l’article scientifique, bref, des « choses banales18 ». Banales et le devenant vite : j’ai été frappée lorsque j’ai entrepris ma recherche sur le poster par le fait que, pour ses usagers, il semblait avoir toujours existé ; en effet, parmi les chercheurs que j’ai alors interrogés, bien de ceux qui avaient connu un monde sans poster ne purent se rappeler spontanément le premier poster qu’ils avaient vu ; quant aux plus jeunes, ils furent surpris d’apprendre que cette technique de présentation n’avait guère plus de quarante ans d’existence. Outre ces choses qui cependant sont visibles pour peu qu’on leur prête attention, à l’instar des exemples qui viennent d’être donnés, il en est qui ont disparu parce qu’elles relèvent de stades préalables de la recherche ou parce qu’elles sont de l’ordre de l’éphémère – à commencer par les écritures tracées au tableau. Il en est d’autres qui sont invisibles dans les productions scientifiques parce qu’elles ne sont pas aisément verbalisables, parce qu’il n’est pas nécessaire qu’elles le soient, ou pour les deux raisons à la fois. Il arrive pourtant qu’elles disent non seulement l’art de faire d’un chercheur mais encore son excellence, à commencer par le coup d’œil de l’historien d’art ou du radiologue, un œil longuement exercé dont ni l’article d’attribution ni le compte rendu du scanner ne font la moindre mention.

En objectivant ces techniques qui font le cours normal de la vie savante et participent de l’habitus, il ne s’agit pas de procéder à un inventaire de curiosa à l’enseigne du pittoresque et de l’anecdote, ni de dresser la toile de fond sur laquelle se déploieraient les théories, les idées, les découvertes, les inventions. Le propos est autre : montrer la place et le rôle des techniques intellectuelles dans l’organisation, la production et la communication des connaissances, et donc d’abord en faire ressortir toute la réalité. Ce qui ne veut pas dire « techniciser » et « matérialiser » à outrance le savoir en négligeant les gros bagages de théories, d’intuitions, d’hypothèses que les acteurs ont avec eux. « Le jeu manuel » de distribution et redistribution des fiches pratiqué par Lévi-Strauss va de pair avec un savoir livresque, un système d’idées, une méthode d’analyse.

Gestes, maniements des mots et des signes ainsi qu’autres opérations sont souvent rapportés aux catégories « muettes » du savoir tacite (des historiens des sciences) et du savoir-faire (des anthropologues) qui est qualifié d’indicible19. Que tout ne soit pas dit, est un fait qui se vérifie déjà dans ce que l’on pourrait appeler, en démarquant Kuhn, la phase « normale » de l’histoire des techniques intellectuelles. À son apparition, en effet, une technique est souvent l’objet de débats qui amènent à produire les raisons qui la fondent, et qui portent éventuellement à expliciter les raisons de la pratique alors en vigueur ; à la suite de quoi, se crée une sorte de consensus qui fait que l’emploi de ladite technique n’est plus guère explicité ; il n’en est plus besoin.

D’autre part, bien des savoirs pratiques sont dicibles, même si ce n’est pas aisément ou spontanément, même si leur transmission implique aussi la monstration, la mimique. Que des gestes médicaux et chirurgicaux, pour en rester à eux, soient devenus – et ils doivent le devenir – machinaux et automatiques, ne veut pas dire qu’ils n’aient pas été appris au cours d’une « éducation médicale des sens20 » ; et dans cette éducation aussi poussée que hautement spécialisée, le savoir de la main, de l’oreille, de l’œil se transmet dans un processus dont des pans entiers sont écrits et dits (et parfois plus que d’un mot). Il est d’ailleurs fascinant pour l’historien de découvrir des documents de tous ordres exposant et explicitant techniques, procédures, gestes. S’il faut parfois jeter un regard oblique, le plus souvent la lecture directe des documents de la pratique donne à voir la chose même. Et les documents du passé apprennent-ils moins que l’observation directe à laquelle se livre l’ethnologue sur le terrain ? Force est de constater qu’ils disent beaucoup, lorsque, de surcroît, ils assortissent la description de l’explication. Un exemple sera ici éclairant. En 1885, le Pr Edmond Landolt faisait sa conférence d’ouverture à l’École pratique de la faculté de médecine de Paris. Dans cette leçon consacrée au maniement des instruments en chirurgie oculaire, il était amené à traiter de l’« entraînement particulier » du chirurgien oculiste, de « la pose du corps et du bras, des mouvements de la main et des doigts », décrivant le moindre geste dans son plus petit détail, explicitant l’office de chaque doigt, de chaque phalange, voire de sa seule pulpe dans la prise et la conduite de chaque instrument. Alors que le comment et le pourquoi de chaque geste étaient, pour reprendre une expression de Landolt, pratiquement traités, il n’est pas sûr qu’un observateur extérieur aurait vu tous les détails jusqu’aux plus infimes – « la pulpe du médius s’appuie, à la limite de son tiers antérieur, sur l’anneau et le côté de la branche correspondante des ciseaux. L’indicateur [l’index], légèrement recourbé, doit s’appliquer sur la croisée des ciseaux, un peu en deçà d’elle… ». Il n’est pas sûr, non plus, qu’il aurait saisi toutes les raisons rendant compte de chaque geste : ainsi, l’extrémité du petit doigt, qui ne manie, et pour cause, aucun instrument, devait s’appliquer sur une partie voisine de l’œil à opérer ; non, comme il pourrait y paraître, pour assurer à la main du chirurgien un léger appui, mais « pour établir la communication entre nous et le malade » ; et Landolt de préciser : « un doigt bien exercé nous renseignera même sur toute la disposition du malade », avant d’expliciter en quoi21. Des textes similaires joignant description et explication, il n’en manque pas pour bien des techniques qui sont ici évoquées ; le problème serait plutôt à l’inverse : se frayer un chemin dans la masse des documents et voir au-delà de la multiplicité des détails.

Explorer l’histoire matérielle de la culture savante porte à terme à une relecture de cette même culture. Au fur et à mesure que l’on avançait dans l’inventaire et la description de techniques majeures et mineures, que l’on analysait les pratiques et les discours des usagers, des interrogations en sont venues à se poser avec insistance. Il est usuel de parler de culture écrite, de culture du livre, de culture de l’image, de culture numérique, voire de civilisation de l’écrit, de civilisation de l’imprimé, de civilisation de l’image, de civilisation du numérique. Étiquettes fort justes quand, en se tenant au seul monde savant, on fait l’inventaire des nombreux produits que recouvre chacune d’elles, tels, pour en revenir au document cité en ouverture et aux photos qui l’accompagnent, les multiples types d’écritures pratiquées par Lévi-Strauss – écriture manuscrite au stylo, au feutre, au crayon, sur le papier, à la craie sur le tableau, écriture mécanique à la machine. Étiquettes bien moins appropriées quand on passe à la description de produits – pour un exemple macroscopique, on pensera au très multimodal poster – et encore moins pertinentes quand on détaille des pratiques : pour en rester à Lévi-Strauss, texte et photo montrent que dans son enseignement au Collège de France il mobilisait les multiples ressources de la parole, de l’écrit (notes sur le papier et écritures au tableau), du geste – désignant ce qu’il venait d’écrire –, du regard – observant les réactions de son auditoire –, et qu’il les mobilisait ensemble dans la transmission des connaissances ainsi d’ailleurs que dans leur production : n’évoquait-il pas, à propos de ses cours, des « paroles aventurées ou peut-être malencontreuses, mais utiles à moi-même pour faire progresser mes idées22 » ? À ce point, les catégories susdites volent en éclats et deviendraient presque impertinentes. Ce qui m’était apparu sur la base d’un agenda de recherche plus limité, centré sur la seule oralité : j’avais pu montrer que la civilisation dite de l’imprimé était aussi dans ses plus hautes sphères une civilisation orale suscitant des formes multiples de la parole, traduisant dans ses pratiques mêmes une confiance majeure dans la force cognitive du parler. Porter attention aux techniques et aux pratiques du monde savant dans toute leur diversité amène donc à se défaire d’étiquettes réductrices et à voir dans la culture savante un ordre de nature différent, mixte. Et cet ordre est raisonné. C’est ce qui m’est apparu en prenant le point de vue des usagers, c’est-à-dire en repérant et en analysant les arguments qu’ils ont produits à l’appui de telle ou telle technique intellectuelle. Les explications et justifications données réfèrent à un certain nombre de motifs de fond, toujours les mêmes, quelles que soient la modalité, la période, la discipline. Mettre en lumière ces invariants permet de saisir la logique d’un discours unitaire qui fonde, si ce n’est la société du savoir, du moins, l’activité de ses représentants.


PREMIÈRE PARTIE


UN ORDRE PLURIEL



Introduction




* * *





« Ce bureau était un véritable capharnaüm, plein de vestiges humains, de crânes, de fémurs en cours d’étude, d’appareils de mesure, de livres, d’instruments de laboratoire, de téléphones, de dictionnaires » ; c’est ainsi qu’un roman présente le bureau d’un anthropologue du musée de l’Homme, à l’instar d’ailleurs de deux autres bureaux décrits, l’un comme « passablement encombré », l’autre comme « bourré de livres1 ». Ce n’est pas que dans la fiction que le bureau est un capharnaüm. Une vidéo de 1961 fait pénétrer dans le bureau de Gaston Bachelard, « une petite pièce encombrée de livres » – il y en a jusqu’au-dessus de la porte – mais aussi de dossiers. Outre l’encombrement, frappe la disposition des livres, tantôt alignés, tantôt empilés sur des étagères, voire intercalés dans le moindre espace. Rien d’étonnant que le maître des lieux eût un jour des difficultés à retrouver un petit dossier, en fait, qu’il le déclarât « à jamais perdu2 ». Plus près de nous, André Gunthert décrit son bureau comme un « capharnaüm », ajoutant, en bon praticien de l’histoire visuelle qu’il enseigne à l’EHESS, la preuve d’une photo montrant les piles irrégulières de documents qui y sont entassées de part et d’autre de l’ordinateur3. L’encombrement a également gagné ce bureau d’un nouveau genre qu’est l’écran de l’ordinateur : parfois surchargé d’icônes qui s’y accumulent, il offre à son tour l’image du désordre et de la confusion4.

Pour le passé lointain, des descriptions donnent à voir des lieux de travail tout aussi encombrés. À commencer par la bibliothèque personnelle d’Antonio Magliabechi (1633-1714), le bibliothécaire du grand-duc de Toscane. Cet homme qui fut consulté de toute l’Europe pour sa science bibliographique, comme son énorme correspondance l’atteste, vivait littéralement au milieu de livres. Non seulement il en possédait beaucoup – l’estimation est, à sa mort, d’environ 30 000 volumes –, mais encore il y en avait partout dans sa maison, jusque dans les escaliers ; dans les pièces, les livres étaient disposés non seulement le long des murs, mais aussi en piles de grande hauteur délimitant d’étroits passages5. L’exemple serait presque caricatural. Pourtant d’autres intérieurs sont aussi bien encombrés. À Venise, chez Apostolo Zeno (1668-1750), l’un des premiers lettrés de l’Italie du temps, il y avait des livres jusque sur les guéridons, les chaises et les armoires ; sur les rayonnages, bien des rangées étaient doubles et nombre de volumes étaient entassés les uns sur les autres. Encore faut-il ajouter beaucoup de papier – ses notes de lecture, ses manuscrits de travail, sa correspondance –, ainsi qu’une collection considérable de médailles – plus de 10 000 en 17476.

Dans ce même XVIIIe siècle, des laboratoires de physique offraient des accumulations d’objets et de matériaux divers. Le laboratoire de Lavoisier, celui qu’il organisa à l’Arsenal à partir de 1775 – un des mieux équipés de l’Europe, il est vrai – ne contenait pas moins, lors de sa confiscation, 123 catégories différentes d’instruments ; plus de 8 000 objets furent alors catalogués ; précisons que les inventaires ne sont pas complets et qu’ils ne tiennent pas compte du petit matériel ni des produits chimiques. Une pièce adjacente était dévolue à une bibliothèque ; aux livres, s’ajoutait la masse de papier, faite de registres, de carnets, de dossiers, suscitée par les recherches7. Ce laboratoire, il convient de l’imaginer en se rapportant à l’impression qu’il produisit sur Arthur Young. Dans ses Voyages, l’agronome anglais contrastait les cabinets de physique composés pour la montre et ceux où l’on travaillait. « Un laboratoire bien rangé, bien propre, bien en ordre, endimanché est détestable, écrivait-il. Mais j’ai trouvé bien du plaisir dans les laboratoires sales et en désordre de MM. de Morveau et Lavoisier. On sent l’activité ; il y a à l’évidence du travail qui se fait, et par conséquent de l’utilité8. »

« La science en train de se faire » n’a pas nécessairement pour environnement la saleté et le désordre, bien sûr, mais certainement pas une pièce rangée au cordeau dans laquelle aucun papier ne traîne, aucun livre n’échappe à un impeccable alignement, dans laquelle la table de travail ne porte que la feuille de papier sur laquelle le chercheur dans ses plus beaux habits écrit en levant les yeux vers un photographe – tels ces portraits, posés et apprêtés, de physiciens que l’on peut voir sur le site des Archives visuelles Emilio Segrè. On y trouve aussi quelques images plus réalistes, à commencer par une photo de Louis Neel ainsi légendée « assis à sa table de travail, enseveli sous les papiers et les livres9 » – et le commentaire n’est nullement exagéré.

Les quelques situations que j’ai brièvement rapportées montrent à l’évidence la masse nombreuse de documents et d’objets de nature diverse qui sont quotidiennement maniés. C’est cette masse que je me propose ici de démêler, en mettant en quelque sorte de l’ordre dans les bureaux. Cela amènera à procéder d’abord à un inventaire. Qu’y a-t-il, par exemple, aujourd’hui dans les piles de documents sur les tables ? Des manuscrits de travail et autres archives personnelles de la recherche ? Des rapports, thèses et autres produits de la littérature dite grise ? Je serai ici conduite à faire un travail assez similaire à celui des archivistes classant le patrimoine scientifique et technique qu’ils collectent. Ce sera l’objet du chapitre 1 qui amènera, d’une part, à ordonner des masses confuses et, d’autre part, à distinguer des produits qui, s’ils relèvent d’une même technologie, sont néanmoins profondément différents : un gribouillis sur un post-it n’est pas un manuscrit de prise de notes, et la revue imprimée qui s’aligne sur les rayonnages d’une bibliothèque n’est pas un livre. Cet inventaire sommaire, au sens que les archivistes donnent à l’expression, amènera à objectiver la quantité d’outils qui font l’ordinaire ou l’extraordinaire de la vie des savants, un outillage imposant, en fait plus nombreux et plus divers qu’il n’y paraît et qu’ils ne le pensent.

Ce travail préliminaire servira de base à une enquête d’ordre historique dont le but ultime n’est ni de dater l’apparition des produits multiples de la communication verbale et non verbale, ni de retracer la chronologie de leur diffusion. Bien différemment, il vise, en s’appuyant sur des informations érudites, à montrer le processus à l’œuvre dans la genèse de cette multiplicité : l’invention constante de nouveaux produits combinée avec la déclinaison « à l’infini » de chacun d’eux en des arborescences parfois touffues dans lesquelles on verra la traduction matérielle de la demande des usagers. La description historique qui sera au cœur du chapitre 2 permettra également de voir comment des produits se sont réglés, normalisés, constitués en genres. Ce qui veut dire que ces instruments ne vont pas de soi, qu’ils nécessitent un apprentissage qui, s’il est parfois minime, n’en est pas moins réel.

L’outillage considérable mis en œuvre dans le repérage et le traitement de l’information scientifique serait incomplet si l’on n’y intégrait les ressources que les savants apportent avec eux – ce que, depuis Marcel Mauss, on appelle « les techniques du corps ». Le chapitre 3 leur sera consacré. Il visera en observant la technologie du travail scientifique à prendre en compte des gestes, bien sûr, et avec eux toutes les formes du toucher – on se rappellera ici la gestuelle décrite par le Pr Landolt –, mais aussi les autres sens humains tels qu’ils sont mobilisés dans les opérations intellectuelles – par exemple, le voir chez le spécialiste des écritures anciennes. Le corps du savant fonctionne comme un instrument cognitif, encore faut-il que les sens aient été éduqués, par exemple que l’œil soit devenu « paléographique ».

Dans ce chapitre, comme dans les deux précédents, on sera amenée à porter l’attention sur des actes ordinaires, sur des objets banals, sur des détails apparemment insignifiants, autant d’éléments qui, au-delà d’approches microscopiques, n’entrent pas dans une vue globale de l’histoire du travail intellectuel, quand ils ne sont pas rejetés dans l’anecdotique. Pourtant prendre en compte ces actes, ces objets, ces détails donne à voir non seulement un pan – souvent implicite – des savoirs et des idées, mais d’abord la masse colossale d’outils qui font de l’ordre du savoir, hier comme aujourd’hui, un ordre du multiple, un ordre pluriel.



CHAPITRE 1


Le nombre et la diversité




* * *





La masse des ressources dont les savants ont disposé et disposent dans leur travail est une réalité ; cela ressort des situations qui ont été précédemment rappelées. Au fil des exemples, des moyens particuliers ont été mentionnés – livres, manuscrits, instruments, etc. – qui invitent à un dénombrement plus systématique. Il se fondera sur des catégories ressortissant aux technologies de la production et de la communication du savoir : la parole, l’écriture, l’imprimerie, l’image, l’instrumentation, le numérique. Toutes, sauf la première, sont utilisées par les archivistes dans le classement du patrimoine scientifique et technique1. Toutefois, le propos sera ici d’esprit différent. Il ne s’agira pas seulement d’ordonner des ensembles confus, à l’instar de fonds d’archives versés dans un grand désordre. On s’appliquera tout particulièrement à distinguer les produits qui relèvent d’une même catégorie. Pour autant, cet inventaire ne sera pas exhaustif et, on le verra, il ne saurait l’être. Il ne comptabilisera pas moins un nombre impressionnant d’outils qui ont été mis en œuvre dans la société du savoir pendant cinq siècles d’histoire. Les descriptions seront brèves – ce chapitre ne relève pas de l’histoire des technologies de la parole, de l’imprimé, du numérique et autres ; elles seront cependant suffisantes pour situer l’emploi de cet outillage dans le travail intellectuel, comme l’illustreront des exemples pris dans des disciplines diverses.





Oralités


On commencera par, ce qui selon l’expression commune, disparaît, s’envole : la parole. Un simple coup d’œil sur un bureau aujourd’hui en montre pourtant toute la réalité. On y voit des lettres ou « conversations entre absents », selon la définition classique ; des notes de cours et des Cours, formes de la parole magistrale ; des actes de colloque et autres réunions, attestant une oralité collective ; un téléphone qui allègue la parole vive ; un ordinateur qui offre des ressources audio en quantité considérable. Ainsi, en un instant, on a les indices multiples d’une masse de paroles qui entrent dans la production et la communication du savoir.

Le monde savant apparaît comme un univers de langage, aussi dense que varié, qui investit les multiples lieux du travail aussi bien que leurs marges – pensons aux seuils des bureaux, aux couloirs dans les centres de recherche et les laboratoires, aux pauses-café lors des colloques. De sorte que si l’on prend en compte tous les actes de parole, des plus informels aux plus formels, des plus élémentaires aux plus sophistiqués, des plus privés aux plus officiels, il n’est pas extravagant de conclure comme j’ai pu l’écrire dans un précédent ouvrage que, hier comme aujourd’hui, mutatis mutandis bien sûr, le monde savant a plus parlé qu’il n’a écrit2.





Écritures


Il a pourtant beaucoup écrit. Des archives personnelles de savants révèlent d’énormes masses de papier. La Leibniz Archiv à Hanovre comprend quelque 50 000 unités, ce qui représente de 150 000 à 200 000 feuilles. On y trouve des lettres (environ 15 000) reçues par l’illustre savant, les manuscrits d’un grand nombre de ses ouvrages, souvent accompagnés d’une ou plusieurs copies faites par ses secrétaires, avec bien des annotations marginales ou des traits de soulignement, des extraits de livres, de journaux et autres documents de sa main ou de celle de ses secrétaires, un grand nombre de notes pour de futures recherches ; encore faut-il ajouter les annotations marginales que Leibniz portait dans des livres3. Sans arriver à ce record, d’autres fonds impressionnent par leur volume. L’archéologue et historien d’art Émile Espérandieu (1857-1939) ne jetait rien, conservant jusqu’aux remarques qu’il se faisait à lui-même dans la conduite de ses recherches et aux bouts de papier qu’à cause de sa surdité il utilisa à la fin de sa vie pour communiquer avec ses visiteurs. Le gros de ses archives de travail, aujourd’hui conservées à Avignon, compte environ 20 000 pièces dont une très importante correspondance, 126 dossiers de notes et travaux divers, plusieurs manuscrits d’ouvrages et d’articles publiés et non4. Autre savant qui « gardait tout, absolument tout » : Henri Piéron (1881-1964), l’un des fondateurs en France de la psychologie scientifique. Le fonds actuellement aux Archives nationales comprend des documents concernant les études, la carrière et la vie privée du savant, 2 907 lettres reçues et parfois des brouillons de réponse, des documents de travail aussi divers que des notes, parfois sur de minuscules bouts de papier, et des cahiers d’expériences, des manuscrits d’ouvrages, de conférences, d’allocutions, la totalité des notes préparatoires à ses cours au Collège de France, des dossiers relatifs à sa direction de l’Année psychologique ainsi qu’à son activité au sein de nombreuses institutions. Encore à ce gros fonds – 7,7 m linéaires –, s’ajoutent plus de 12 000 lettres et des notes manuscrites, soit 30 cartons, qui ont été retrouvées en 1999, à la faveur d’un déménagement5. Le chimiste Pierre Potier (1934-2006), lui aussi, conservait tout, pour des raisons de priorité scientifique notamment : ses archives contiennent « outre la correspondance privée et personnelle, la majeure partie de ses écrits – cahiers de laboratoire, notes, brouillons, avant-textes, “papiers intermédiaires” rédigés pour des cours, des conférences, textes envoyés pour être publiés, publications définitives, textes préparés pour déposer des brevets » ; on y trouve encore « les feuilles annotées qui firent le va-et-vient entre deux chercheurs [de son laboratoire], les différentes versions d’un projet de recherche6 ».

Ces fonds massifs – et on aurait pu en citer bien d’autres – donnent à voir, avec la gamme des manuscrits que produit un savant dans une vie de travail, des écritures multiples qui ressortissent au repérage, au traitement, à la production, à la transmission des connaissances : notes de lecture, de cours et de travail7, cahiers de laboratoire, manuscrits de travaux publiés et non, manuscrits de cours et de conférences, correspondance. Encore, convient-il de relever dans les fonds cités la diversité des présentations, que ce soit les multiples états d’un manuscrit – de notes rapides à la copie préparée pour la publication –, que ce soit la variété des supports – du papier au bristol, d’une feuille en son entier au tout petit bout de papier, d’une feuille vierge au verso d’épreuves, d’imprimés, voire de publicités.

Quelques autres exemples, anciens et modernes, révèlent, avec des pratiques personnelles, des modalités d’inscription particulières. Les archives de Malpighi, du moins celles conservées à Bologne, donnent à voir des produits divers référant à son activité de professeur, de chercheur et de médecin : un volume d’Anatomica, comptes-rendus des autopsies qu’il fit ou auxquelles il assista entre 1666 et 1693 ; des notes de lectures et des extraits de livres disposés non par auteurs mais par matières ; un journal, fait d’un gros paquet de feuilles in-folio pliées en deux et encartées les unes dans les autres, où il a noté, en les datant, des observations médicales ainsi que ses conversations avec des visiteurs de choix, tels Leibniz ou l’anatomiste danois Nicolas Sténon ; les cours qu’il fit à l’université de Bologne ; le manuscrit de son autobiographie par lui préparé pour l’impression ; sa correspondance ; plusieurs volumes de consultations8. Les papiers de Montesquieu contiennent des recueils d’informations les plus diverses, des extraits de livres, des brouillons de chapitres, des notes pour diriger le travail de ses secrétaires, des listes de vérifications à faire, des corrections rédigées à introduire ; ils renferment également des exemplaires des fameux « bulletins » ou « papillons », fiches d’environ 15 × 8 cm sur lesquelles Montesquieu, au moment où il se mettait à la composition, faisait recopier des passages des extraits9. Les archives des historiens Lucien Febvre, Fernand Braudel, Robert Mandrou, Georges Duby contiennent des milliers de fiches que ce soit sur support papier ou bristol ; on y reviendra au chapitre suivant.

L’écriture est aussi entrée dans les livres. Des savants ont annoté – et parfois abondamment – les livres qu’ils lisaient. Ils ont écrit dans les marges, d’où le nom de marginalia donné à ces écritures minimes10, mais aussi en d’autres endroits de l’ouvrage, en début, en fin, sur les rabats de la couverture, là où il y avait de la place11. Ou bien, ils ont inséré dans le livre des feuilles sur lesquelles ils écrivaient – tels, au XVIIe siècle, Vossius qui retravaillait ainsi ses propres ouvrages ou, au XXe siècle, Lucien Febvre qui prenait ses notes de lecture sur des feuilles 21 × 27, soigneusement découpées en quatre fiches, inserts qui sont demeurés dans les livres12.

Il est un groupe d’écritures qui, par leur nature même, échappent à la collecte, telles, dans les laboratoires, des inscriptions sur des cahiers de brouillon, sur des boîtes et des tubes, voire sur les paillasses13. Autant d’écritures qui n’ont qu’un temps et ne sont pas moins essentielles dans le processus de recherche, comme le sont aussi les écritures au tableau. Les mathématiciens restent aujourd’hui attachés à cet outil ancestral. Il est partout des tableaux, dans les salles de cours, les laboratoires, les couloirs, les toilettes, voire, comme au Newton Institute à Cambridge, dans l’ascenseur ; on rappellera qu’à Göttingen Hilbert en avait fait installer un jusque dans son jardin. Le physicien Pierre-Gilles de Gennes, lui aussi, faisait dans les discussions scientifiques un grand usage du tableau et de la craie qui n’allaient pas sans l’effaceur ; dans ses bureaux, un tableau a toujours garni un pan de mur, les parties hautes étant occupées par l’information à garder14.

Encore l’inventaire serait incomplet si l’on n’enregistrait ces produits humbles qui « annoncent » le post-it, tels les carrés de papier portant les lettres A à T que Malpighi avait collés sur les marges droites du volume Anatomica ou « les petits morceaux de papier mouillé » que Mabillon suggérait de coller dans les livres pour signaler un passage intéressant15. Il le serait tout autant si, à l’autre extrême, on oubliait ces livres qui, à l’heure de l’imprimé triomphant, firent toute leur carrière en manuscrit : telle la traduction italienne du De natura rerum de Lucrèce faite entre 1664 et 1669 par Alessandro Marchetti qui, copiée et recopiée, circula amplement jusqu’en Angleterre16.

Majeures ou mineures, longues ou brèves, durables ou éphémères, les écritures du monde savant offrent une considérable variété qui n’est pas sans contribuer à l’effet de masse qui en ressort. Effet qui était par exemple saisissant pour qui pénétrait dans le cabinet de travail de l’historien Leopold von Ranke : les murs étaient couverts d’in-folio reliés contenant les notes et extraits accumulés au long d’une vie de recherche, volumes imposants qui étaient surnommés « les bois » en raison de leur matériau, de leur taille et de leur quantité17.





Imprimés


Dans les descriptions du travail intellectuel, il est un produit toujours mentionné : le livre. Le monde savant a même suscité des produits imprimés spécifiques qui arriveraient presque à le symboliser : des ouvrages de grand format, en plusieurs volumes, possédant parfois même les deux caractéristiques. Ce sont d’abord ces livres sur les livres, autrement dit les répertoires et bibliographies qui, apparus dès le XVIe siècle, ont enregistré, suivant des modalités multiples, la production typographique, ainsi que tous les multiples catalogues de livres, à commencer par ceux des bibliothèques. Recueils nombreux et parfois gigantesques, dont on prend facilement la mesure en entrant dans une salle de bibliographie18. Le grand format est encore plus usuel dans les atlas, un type d’ouvrage dont le nom même est évocateur d’une certaine dimension. Originellement appliqué à des recueils de cartes géographiques, ce terme s’étendit, dès la fin du XVIIIe siècle, à des publications de données d’astronomie et d’anatomie pour gagner au cours des XIXe et XXe siècles toutes les sciences d’observation ; il en est résulté des ouvrages nombreux, parfois hautement sophistiqués, mais toujours massifs, recourant volontiers à l’in-folio, voire au grand in-folio19. Les mêmes remarques valent pour des publications de textes qui, en France, ont leurs modèles dans les éditions qu’aux XVIIe et XVIIIe siècles firent paraître les mauristes20. Une discipline, l’archéologie, a particulièrement donné dans les grands et gros volumes. Au cours du XVIIIe siècle, des antiquaires avaient fait paraître des publications déjà imposantes, les fameux Museum. Le développement des fouilles au XIXe siècle radicalisa cette tendance : d’une part, les musées qui enrichirent alors notablement leurs collections publièrent des catalogues raisonnés, nécessairement gros ; d’autre part, sous l’impulsion germanique, il s’élabora une forme originale de publications : les corpus documentaires visant à livrer la totalité des documents disponibles d’un type donné, tel le Corpus Inscriptionum latinarum qui, entre 1863 et nos jours, a publié 17 volumes en 70 livraisons in-folio21.

Il est un autre genre d’imprimés – typique du monde de l’enseignement universitaire – que l’on peut voir sur la table des apprentis aussi bien que des maîtres : les manuels et supports de cours qui constituent un chaînon dans la transmission des savoirs22. Aux ouvrages imprimés, très nombreux déjà sous l’Ancien Régime et qui étaient l’apanage des maîtres, on ajoutera la montagne de papier lithographié puis dactylographié que sont les polycopiés23. Faits à l’initiative de professeurs mais aussi d’étudiants et alors autorisés ou non par les auteurs des cours, diffusés par des éditeurs mais, plus souvent, semble-t-il, par des associations étudiantes, ils poursuivent aujourd’hui encore leur carrière, notamment en médecine et en droit, dans des présentations variables (cours en entier ou simple plan), sous la forme papier ou électronique. Ce sont là des produits souvent d’un gros volume24.

Ces publications, produits de grand usage, n’ont souvent, pour cette raison même, qu’un temps. Il en va de même d’un autre type d’imprimés qui a pourtant fait et fait le quotidien ou la base de travaux. Ce sont les questionnaires imprimés qui sont apparus afin de normaliser la collecte de matériaux et d’obtenir des données uniformes et comparables, documents intermédiaires destinés à disparaître. On en donnera trois exemples. Broca élabora des feuilles d’Observations anthropologiques sur le vivant à l’intention des voyageurs ; ceux-ci les rempliraient en tenant compte d’instructions extrêmement précises et les renverraient à la Société d’anthropologie25. En 1913, le géographe Jean Brunhes qui travaillait à réunir les archives de la planète fit imprimer une fiche sur laquelle les opérateurs qu’il envoya autour du monde noteraient dans les rubriques définies un certain nombre d’indications26. Marcel Cohen élabora en 1931 pour le Comité international de linguistique des questionnaires imprimés, sous la forme de carnets à feuilles détachables ; ils étaient destinés à recueillir sur un plan uniforme des documents linguistiques27.

Dans le monde du savoir, il est un produit imprimé – le périodique – qui a concurrencé le livre, et victorieusement dans les disciplines scientifiques. Une enquête de 1972 a établi que, pour leurs travaux, 85 % des chercheurs dépouillaient d’abord les revues spécialisées28 ; et une visite dans la bibliothèque d’un laboratoire relevant des sciences de la vie ou de la matière montre à l’évidence que le gros des collections est fait de périodiques. On est à l’aboutissement d’un processus à succès qui a commencé en 1665 avec la création du Journal des savants ; entre cette date et 1730, 330 périodiques furent créés dans les sept pays de l’Europe occidentale29. Le mouvement se poursuivit au XIXe siècle ; les périodiques quadruplèrent entre 1866 et 1898 ; leur volume global connut même à partir de 1890 une augmentation de près d’un tiers tous les deux ans30. La tendance s’amplifia encore au siècle suivant et, avec la Big Science, les chiffres ont explosé. Il a été établi, au début des années 1960, qu’il existait environ 30 000 revues et que, chaque année, plus d’un million d’articles était publié. Trente ans plus tard, on était parvenu à un autre niveau de grandeur : on comptait alors 40 000 périodiques scientifiques, soit 25 millions d’articles31. Dans le domaine plus étroit des seules sciences sociales et humaines, il a été calculé qu’en France en 1987 il n’existait pas moins de 700 revues32. Plusieurs raisons expliquent cette multiplication des périodiques : l’explosion des connaissances, la spécialisation croissante, voire l’hyperspécialisation, l’apparition de nouveaux champs de recherche, des innovations théoriques ou méthodologiques, la croissance de la population scientifique, sans compter des ambitions personnelles – « toute notabilité dans le monde scientifique doit avoir sa revue33 ».

Bien présent dans le travail quotidien des chercheurs, le périodique scientifique l’a aussi été dans la forme minime du tiré à part de l’article, dont l’histoire reste à écrire. À côté des fonctions sociales et sociables que ce produit a remplies34, il a aussi joué un rôle non négligeable dans la circulation de l’information scientifique. Le mathématicien Felix Klein qui, à l’université de Göttingen organisa à la fin du XIXe siècle une salle de lecture et bibliothèque de mathématiques, destinée à servir de modèle, fit en sorte qu’elle reçût des tirés à part afin de se tenir au courant très rapidement des découvertes dans la discipline35. Les laboratoires de sciences ont mis en place dans les années 1950 et jusqu’à l’arrivée du numérique, une gestion des tirés à part (ainsi d’ailleurs que des preprints) : on demandait les tirés à part qui se rapportaient aux recherches menées dans le laboratoire et, à leur réception, ils étaient placés dans la bibliothèque, s’ils étaient d’intérêt général, ou remis à un chercheur, s’ils correspondaient à ses recherches particulières36. Dans les sciences humaines où le processus ne fut pas ainsi institutionnalisé, un même usage du tiré à part exista comme on le voit bien à la faveur d’un exemple. La bibliothèque de l’archéologue Claude Rolley contenait à sa mort (2007) près de 2 000 tirés à part ; la plupart étaient placés dans des dossiers de travail, et certains dans les ouvrages de sa bibliothèque, en particulier, ceux dont il avait fait le compte rendu, pour des compléments bibliographiques37.

Enfin, dans les documents qui s’empilent aujourd’hui sur les bureaux, il en est imprimés (ou multigraphiés) qui relèvent de ce que l’on appelle littérature grise. Sous cette étiquette, on place les publications qui échappent au circuit commercial, des publications aussi nombreuses qu’hétérogènes avec, au premier chef, les thèses et surtout les rapports – une immense catégorie qui, à son tour, recouvre une grande variété de produits. En 1958, la production mondiale de documents scientifiques et techniques gris était estimée à un peu plus d’un million ; ce chiffre était multiplié par quatre en 1970. Les usages de la littérature grise dépendent des disciplines, des sujets, des méthodes : une étude scientométrique portant sur les années 1987-2005 a montré que les sciences de l’ingénieur s’appuient bien davantage que d’autres sur les ressources grises38.

Un inventaire sommaire montre que les savants manient beaucoup d’imprimés et de plus en plus au fil du temps si l’on prend en compte l’apparition de nouveaux produits et la multiplication de ceux-ci. Il n’est donc pas impertinent qu’ils se soient fait représenter devant des livres, c’est-à-dire devant leurs instruments de travail.





Images


À vrai dire, ils auraient tout autant pu être figurés au milieu d’images. Non seulement parce que dans certaines disciplines, ils en ont fait une très forte consommation, mais aussi parce que l’image a dans le monde scientifique une grande diversité, enfin et surtout parce qu’elle est un outil de la pensée. C’est ce qui ressort d’études qui ces dernières années se sont multipliées, stimulées peut-être par le phénomène contemporain de la prolifération exponentielle des images et de leur accumulation dans une culture du tout écran39.

Les savants vivent entourés d’images, de présentations diverses suivant la chronologie des techniques de production, suivant la destination de ces images, suivant aussi les temps d’une recherche. Cartes, planches, dessins, croquis, schémas, graphiques, photos, films, etc. sont d’ailleurs l’ordinaire de quelques disciplines, ici très généralement considérées.

Les botanistes des XVIe-XVIIIe siècles ont beaucoup dessiné, fait dessiner et fait graver afin d’identifier les plantes, de les reconnaître et de les classer. Ils n’ont guère tenu compte des réserves de Pline quant à la possibilité d’une représentation fidèle d’une plante tant en raison des changements de son aspect au cours de sa croissance qu’à cause de la variété des couleurs dans la nature. Et il en alla ainsi jusqu’à Linné et sa nomenclature qui rendit inutiles les images. Les œuvres majeures du botaniste suédois n’ont pas d’appareil iconographique. Pour autant, son système n’aurait pu être élaboré sans la consultation de bien des images. Par ailleurs, il n’en a pas moins placé dans sa Philosophia botanica (1751), qui contient la première description publiée de sa nomenclature binominale, onze planches pour représenter non une plante déterminée mais pour donner à voir un système abstrait d’éléments, par exemple, planche 10, la foliaison40.

Antiquaires et archéologues ont produit et manié une masse d’images diverses. Le numismate Charles Patin possédait non seulement une très belle collection de médailles, une bibliothèque spécialisée en la matière, mais encore une quantité considérable de dessins et de gravures de médailles – plus de 6 000 en 1678 ; lui-même dessinait, et il eut toujours chez lui des dessinateurs et des graveurs formés à une reproduction exacte. Ce « musée de papier » était un instrument de travail, la base de publications mais aussi et d’abord de l’étude41. Prisse d’Avennes, un des premiers « égyptologues », revint en 1860 de deux ans passés « sur le terrain » avec un dessinateur et un photographe, chargé de 300 dessins dont des calques coloriés de 7 à 8 m, de plus de 4 000 m d’estampages, de 150 photographies, de « pareil nombre de stéréoscopes », sans compter, pour en rester aux images, de quantité d’esquisses et de croquis. Ses archives iconographiques conservées à la BNF contiennent également des gravures issues de publications antérieures ou découpées dans la presse illustrée ainsi que des photos d’auteurs divers, soit un ensemble de 2 000 images42. Au tournant du XIXe siècle, l’archéologie qui, à la suite de Pitt Rivers, donna une place centrale à l’image, produisit en masse cartes, plans, coupes, croquis, dessins, gravures, photographies. Des développements technologiques et méthodologiques ont amené de nouvelles images, notamment avec la fouille stratigraphique et l’introduction de la prospection aérienne43.

Médecins et chirurgiens ont toujours vécu au milieu d’images, modestes ou splendides. Les livres de médecine sont souvent illustrés, voire très illustrés, et il est depuis les débuts de l’imprimerie une production remarquable dans le domaine de l’anatomie qui a l’un de ses premiers chefs-d’œuvre dans le De humani corporis fabrica (1543) de Vésale, riche de plus de 200 planches gravées44. Pour leurs publications, mais d’abord pour leurs recherches et aussi pour leur enseignement, les anatomistes ont beaucoup dessiné. Farabeuf qui enseigna à la faculté de médecine de Paris dans le dernier tiers du XIXe siècle fut célèbre tant par sa science de l’anatomie que par son talent de dessinateur. Son Précis de manuel opératoire (1re éd. : 1872-1881) qui fut pendant quelque soixante ans la bible des candidats aux concours d’anatomie, de chirurgie et de médecine opératoire, comprenait dans l’édition de 1893 pour le seul tome premier 532 figures, et toutes avaient été faites par lui. Il accompagnait ses leçons de dessins qu’il faisait à main levée au tableau noir avec des craies de couleurs différentes – dessins d’une qualité surprenante quand on regarde les copies qu’en a faites un de ses élèves. Quant aux salles de dissection de la nouvelle École pratique (1878), salles de sa conception, elles portaient sur les murs latéraux des planches qu’il avait dessinées45. Ce talent naturel, l’un de ses successeurs, le Pr Hovelacque ne le possédait pas : il dessinait mal ; cependant, il avait mis au point pour ses leçons d’anatomie un système de repères qui lui permettait de dessiner en quelques minutes au tableau n’importe quelle région du corps humain, impressionnant un de ses plus célèbres étudiants46.

La photographie s’introduisit rapidement en médecine où elle suscita, comme ailleurs, « l’euphorie des scientifiques47 ». La technique particulière de la photomicrographie saisit des observations faites au microscope, et celle de la chronophotographie le mouvement. En 1895, la découverte des rayons X fut le point de départ des images transparentes de la radiographie. Dès la fin du XIXe siècle, les savants disposaient d’une pléthore d’images photographiques48. Le Dr Doyen avait ajouté en 1898 les images animées. Si les films de Doyen et de ses successeurs portaient sur de la grande chirurgie, l’intérêt se fit sentir dans les années 1930 de documenter aussi la plus courante petite chirurgie ; en fait, on filma tout ce qui s’y prêtait et on essaya de multiples techniques dont le dessin animé qui eut en France un de ses premiers exemples avec La Technique d’ablation des ulcères de l’estomac haut situés (1929) du Pr Victor Pauchet. La production cinématographique médicale se développa au fil du temps, principalement à partir des années 1920, à la mesure des progrès en la matière, et elle connut ses années les plus florissantes dans la période 1960-1980, ayant alors intégré la couleur. Elle répondait à des finalités multiples – toujours de formation universitaire et post-universitaire ainsi que, parfois, de recherche, comme c’est le cas avec le Dr Comandon qui fit du microcinématographe « un instrument de laboratoire49 ».

Plus traditionnellement, les planches colorées, de grande et petite taille, ont constitué un véhicule de transmission du savoir anatomique tant en direction d’étudiants que de médecins. Un cas particulier est représenté par ces gravures apparues dès 1536 et qui perdurèrent pendant tout le XVIIe siècle où les figures sont composées de bandes de papier superposées qui peuvent être successivement relevées afin de faire apparaître la structure du corps et les organes internes50. Aujourd’hui encore le monde médical demeure attaché dans l’enseignement de l’anatomie topographique aux planches, et il s’en produit beaucoup ; les photos et les films n’ont pas eu ici raison des dessins, gravures, schémas et couleurs conventionnelles51. À faire la somme de tous ces types d’illustrations – planches, dessins, schémas, photos, radios, films –, l’imagerie médicale avait plus qu’une tradition tant dans les apprentissages que dans la recherche avant que le numérique n’amène un nouveau développement.

Partout, dans le monde du savoir, l’image a eu une place et a gagné du terrain pendant la période prise en considération. Il n’est que de penser à la géographie qui allègue immédiatement les cartes ainsi qu’à toutes les sciences d’observation. Je prendrai l’exemple de la géologie. Elle fut longtemps une science sans images : à la fin du XVIIIe siècle, les publications ne contenaient que peu d’illustrations et celles-ci étaient de faible qualité. Quelque trente ans plus tard, le changement était notable : les géologues travaillaient au milieu d’images, une production croissante dont le développement et la qualité furent favorisés, ici comme ailleurs, par les progrès de la technique de la gravure. Plus encore, il en résulta une gamme de produits spécifiques – cartes, coupes, diagrammes, paysages –, en fait un langage visuel distinctif, fait de règles et de conventions, propre à la discipline52.

Même une discipline aussi iconophobe que le droit a recouru à l’image. Faute de mieux et de façon limitée, il est vrai. Quand en matière de législation matrimoniale, il a fallu connaître les degrés de parenté les plus lointains possibles pour détecter les empêchements à mariage, des arbres de parenté ont été dressés, auxquels on a parfois joint aussi un arbre de l’affinité ou parenté par alliance, elle aussi génératrice d’empêchements. La complexité des situations a amené en matière successorale à dresser un arbre de l’hérédité. Le procédé de l’arbre fut encore utilisé dans des questions procédurales délicates. Cette figure que l’on dit avoir disparu des livres après le XVIe siècle, se trouve dans la plupart des nombreuses éditions des Loix civiles de Domat jusqu’à la fin du XVIIIe siècle ; ainsi, dans l’édition de Paris, 1777, on peut voir à la suite de la section « Comment succèdent les enfants » (t. II, p. 405) une planche représentant un arbre de parenté assez imposant53. Elle poursuivit sa carrière au lendemain de l’Ancien Régime : elle est reproduite dans l’édition revue, corrigée et augmentée des Œuvres complètes de Domat, qui parut en 1829.

De façon variable suivant les disciplines et la nature des recherches, les savants ont travaillé avec des images, minimes comme un schéma ou une esquisse, majeures comme des plans ou des cartes. Bien des exemples ont été donnés qui permettent de mesurer l’ampleur de l’appareil visuel mis en œuvre dans le monde du savoir. Encore pourrait-on ajouter le procédé des projections lumineuses qui, né vers la fin du XIXe siècle, s’est largement imposé notamment dans les sciences de la vie, en géographie, en histoire de l’art, pour faire voir des images, à des étudiants lors des cours, à des pairs dans les colloques et conférences. Le succès en fut éclatant et, dans le domaine de l’histoire de l’art, on en vint vite à souhaiter, devant la pléthore d’images projetées, qu’il y eut « un peu moins à regarder ». Ce souhait ne fut pas exaucé : diapositives et transparents ont fait dans le monde scientifique une splendide carrière54.





Objets et instruments


Farabeuf qui, on l’a vu, dessina beaucoup, a été photographié vers 1905 dans son laboratoire devant une grande maquette de l’articulation de la hanche et des modèles anatomiques du crâne, de l’articulation du genou, du bassin et des fémurs, autant de pièces de ce matériel qu’il fabriquait et qu’il utilisait dans son enseignement, tout comme ces « appareils faits […] avec des élastiques et des ressorts, tel cet œil articulé pour figurer l’action des muscles oculomoteurs55 ». Maquettes et modèles constituent une catégorie de ce que Renato R. Mazzolini a appelé les « sources non verbales de la communication du savoir », sources dans lesquelles entre aussi l’instrumentation scientifique56.

S’ouvre ici un immense domaine que le rappel de quelques situations de travail donnera à entrevoir. Dès la seconde moitié du XVIIe siècle, les voyageurs savants, philosophes et naturalistes se munirent d’instruments et appareils de mesure qui, au fil du temps et en réponse à des exigences de quantification, de précision et de standardisation, se multiplièrent et se perfectionnèrent. Ainsi, lorsque George Shuckburgh-Evelyn partit pour les Alpes au milieu des années 1770, afin d’opérer des mesures des sommets, il se procura, selon ses propres mots, « une sorte de cabinet philosophique portable » ; celui-ci contenait « des baromètres de Ramdsen, un baromètre de Deluc, trois ou quatre thermomètres, des boussoles d’inclinaison et de déclinaison, des balles électrisables, un sextant équatorial de Ramdsen, une chaîne d’arpentage en acier, des perches de plomb et d’étain de trois pieds de long57 ». L’inventaire du laboratoire de Lavoisier, qui a été précédemment cité, permet de prendre la mesure du nombre et de la diversité des appareils et instruments utilisés dans la chimie des années 1780. La naissance de la physiologie moderne et son développement dans la seconde moitié du XIXe siècle sont allés de pair avec une instrumentation qui, depuis le kymographion (1846-1847) de Carl Ludwig, s’est multipliée et diversifiée58. Les chirurgiens, quant à eux, ont utilisé très tôt une masse d’instruments, en fait, un véritable « arsenal » dès le XVIIIe siècle, qui n’a fait que croître à partir notamment des dernières décennies du XIXe siècle. De nouvelles opérations, permises par l’anesthésie et l’asepsie, ont amené l’apparition de nouveaux outils, le perfectionnement de ceux qui existaient et des variations multiples – chaque type d’instrument engendrant « des descendances spécialisées ». Farabeuf, pour en rester à lui, inventa plusieurs instruments qui portent son nom et qui, pour certains, sont encore utilisés aujourd’hui. Un véritable « âge d’or » de l’instrumentation chirurgicale s’est alors ouvert et le mouvement d’invention a perduré : de quelques centaines d’instruments répertoriés à la fin des années 1930, on était passé en 1988 à plus de dix mille. Une technique opératoire, la cœliochirurgie a engendré une panoplie particulière d’instruments microchirurgicaux ; leur nombre s’accroît de jour en jour au point que « tenter une description exhaustive tiendrait de la gageure59 ». Partout dans le monde de la recherche scientifique, nombre et diversité n’ont fait que croître. Les équipements des plateaux ou plateformes techniques ou technologiques des laboratoires contemporains constituent des ensembles impressionnants ; encore ne sont expressément mentionnés sur leurs sites Web que les appareils les plus distinctifs et les plus prestigieux60. C’est-à-dire hautement complexes et totalement mystérieux pour qui écrit ces lignes. J’en resterai donc à des « outils » souvent bien plus modestes mais qui n’en ont pas moins eu pour leurs usagers une haute valeur cognitive. Le développement qui suit ne vise pas à l’exhaustivité mais simplement à faire ressortir, à partir de quelques exemples types, la masse et la variété d’objets qui, entrant dans le processus du travail scientifique, sont sources d’acquisition de données ou moyens de transmission du savoir, ou encore les deux.

J’en reviens aux modèles et maquettes qui offrent une considérable variété à la mesure de leur présence dans bien des champs du savoir61. Les modèles ont été d’un grand emploi dans la science anatomique et ils ont donné lieu à des produits aussi nombreux que divers – écorchés, squelettes, parties du corps humain –, parfois articulés et même démontables, fabriqués dans les matériaux les plus divers (bois, ivoire, plâtre, cire, papier mâché, plus tard plastique). Les écorchés et autres modèles étaient utilisés dans l’enseignement dès les années 1570 et les modèles anatomiques de toutes sortes le sont encore aujourd’hui ; le mannequin (ou « fantôme » au XVIIIe siècle) employé pour la formation à l’accouchement a poursuivi sa carrière jusqu’à nos jours, avec succès si l’on en croit une étude de 201162. À côté d’utilisations pédagogiques évidentes, ces modèles anatomiques ont parfois aussi servi la recherche ne serait-ce que comme les modes de publication les plus décisifs, par exemple, en embryologie dans la seconde moitié du XIXe siècle63.

Dans cette même période, les chimistes commencèrent à construire des maquettes moléculaires tridimensionnelles ; elles ne servirent pas seulement à illustrer des concepts théoriques, mais elles furent, outre des outils pédagogiques, des instruments de recherche, aidant à la compréhension de mécanismes inconnus et à la prédiction de réactions possibles64. À leur tour, les biologistes moléculaires ont construit bien des maquettes – et tout le monde connaît le modèle en double hélice de l’ADN par Crick et Watson – qui sont le résultat de processus multiples de manipulation, de discussion, de mesure, de mise à l’épreuve des données, de correction, de perfectionnement. Ces maquettes, d’une très haute complexité, sont de véritables outils de recherche et elles ont contribué à la constitution de la nouvelle science65.

C’est plus au service de la divulgation vers un public d’amateurs que des maquettes ont été construites en archéologie dès le XIXe siècle. Ce qui n’empêche pas qu’elles aient parfois été très sophistiquées ; parmi la centaine de maquettes que possédait le général Pitt Rivers (1827-1900), il y en avait qui, par des systèmes mobiles, permettaient de découvrir des strates sous-jacentes. Une photo montre aussi que ce pionnier de la fouille moderne utilisa au moins en une circonstance une maquette sur le terrain : elle figurait l’état des lieux au terme de la précédente campagne et servit peut-être de guide pour la suite des travaux. Quand au XXe siècle on construisit des maquettes, parfois de grande dimension, ce fut principalement pour des musées et à destination du public. Elles n’en furent pas moins parfois aussi des objets à haute valeur cognitive : pour l’archéologue Gerhard Bersu, la construction de maquettes, voire des reconstructions qu’il fit en Angleterre (1937-1947) et surtout les conjectures que cela entraînait furent l’occasion « de remarquer des particularités dans le sol qu’autrement nous aurions négligées66 ».

L’archéologie a fait un grand usage d’une autre technique de reproduction : le moulage. L’enseignement universitaire de la discipline s’est accompagné de la création de musées de moulages d’abord en Allemagne où le premier, à Heidelberg, date de 1848. En France, mis à part Strasbourg qui, alors sous domination allemande, eut un musée de moulages dès 1872, ce n’est qu’à la fin du siècle que les nouvelles chaires d’archéologie s’accompagnèrent de collections à but pédagogique (Montpellier, 1890 ; Lyon, 1893-1899). À Paris, deux salles présentant des moulages furent organisées en 1897 au rez-de-chaussée de la nouvelle Sorbonne, préfigurant les collections de l’Institut d’art et d’archéologie qui ne s’ouvrit qu’en 1932. Avec le temps, ces musées perdirent de leur fonction didactique et des plâtres furent relégués dans les caves quand ils ne furent pas purement et simplement détruits67.

Pour autant le moulage a gardé si ce n’est amplifié son rôle d’instrument de conservation et de recherche, tout particulièrement dans le domaine de la préhistoire. De nouveaux matériaux d’utilisation relativement simple (silicones, résines synthétiques) ont permis de prendre des moulages des sols. Alors que la fouille détruit, le moulage peut conserver l’empreinte de chaque niveau rencontré ; à cette pratique du moulage horizontal s’ajoute celle du moulage vertical, où les coupes stratigraphiques sont moulées de manière à en conserver l’exacte reproduction. Le moulage qui permet de fixer et de conserver la trace de vestiges fragiles (jusqu’à des empreintes de squelettes, de foyers, de traces de pas, etc.) donne une image fidèle en grandeur nature et en relief qui peut être présentée dans un musée mais aussi consultée et analysée par les spécialistes. Ainsi, le moulage de coupes stratigraphiques joue un rôle actif dans la compréhension d’un site. Le moulage devient un objet d’étude scientifique, voire d’étude partagée, car il est facilement dupliqué, particulièrement pour de petits vestiges : ainsi, un paléontologue peut avoir sur sa table de travail tous les fragments d’ossements fossiles antérieurs à l’homme moderne, c’est-à-dire tous ses objets d’étude68.

Les archéologues ont aussi largement utilisé cette technique de moulage en creux qu’est l’estampage. Il permet de relever des inscriptions, graffitis et autres fines gravures, d’obtenir des copies fidèles. Il était déjà largement utilisé au XIXe siècle : Prisse d’Avennes, on l’a vu, revint d’Égypte, chargé de plus de 4 000 m d’estampages. Au XXe siècle, de grosses collections se sont constituées, telle celle de la Maison de l’Orient et de la Méditerranée à Lyon [MOM], l’une des plus importantes en Europe avec quelque 10 000 pièces. La technique est toujours en vigueur ; au papier et au plâtre s’est ajouté le silicone qui pallie certains des désavantages des matériaux traditionnels et permet de nouveaux emplois, par exemple en archéologie sous-marine69.

Le moulage a aussi été d’un grand usage en dermatologie et vénérologie qui se constituèrent en disciplines médicales dans les années centrales du XIXe siècle : il offrait le moyen de faire distinguer les différentes lésions de la peau suivant leur forme, leur couleur et leur matérialité. L’hôpital Saint-Louis à Paris eut ici un rôle pionnier. Les moulages étaient faits dans une étroite collaboration entre un médecin, le Pr Charles Lailler, et un mouleur, Jules Beretta. Ils devinrent si nombreux qu’un musée fût créé pour les présenter au mieux. Il fut inauguré en 1889 à l’occasion du premier congrès international de dermatologie et syphiligraphie. Les congressistes furent frappés par ce mode de reproduction en couleurs et en trois dimensions, et la technique se diffusa largement. Jusque dans les années 1950-1960, les moulages furent un instrument essentiel dans l’acquisition du savoir dermatologique : le musée de l’hôpital Saint-Louis en réunit jusqu’à 4 000. C’est d’ailleurs en raison même de leur fonction pédagogique qu’à Vienne, ils furent rangés, non comme à Paris et à Londres en groupes nosologiques, mais disposés de façon volontairement non ordonnée70.

En détaillant quelque peu la catégorie des modèles, maquettes et moulages, on perçoit la masse de produits qui y ressortit. Encore aurais-je pu mentionner, du côté de la géographie, les plans et cartes en relief ou, du côté de l’économie, la machine hydraulique que Bill Phillips construisit à la fin des années 1940 pour rendre plus intelligible la théorie macroéconomique de Keynes71.

L’observation des pratiques du travail scientifique amènerait à une énumération interminable des moyens matériels qui ont été utilisés. À titre d’exemples, on mentionnera les préparations anatomiques, objet d’étude mais aussi d’enseignement, et d’abord technique hautement sophistiquée : l’anatomiste Frederik Ruysch (1638-1731) ne fit pas moins de 2 000 préparations dont le côté parfois spectaculaire ne doit pas dissimuler l’extrême qualité72. On donnera la liste des instruments dont, selon Broca, le voyageur devait se munir pour pouvoir remplir les feuilles d’observations : un double mètre, un ruban métrique, un fil à plomb, une grande équerre, une équerre exploratrice, un crayon dermographique, un compas glissière, un compas d’épaisseur, des goniomètres faciaux, une équerre flexible auriculaire, des lames de plomb, un dynamomètre de Mathieu, une boîte d’aquarelle, une montre à secondes, et éventuellement une petite bascule – groupe d’instruments qu’il qualifiait de « restreint », en comparaison, il est vrai, des instruments de laboratoire, eux « très nombreux73 ». On rappellera le barda que le géographe peut emporter sur le terrain et l’un d’eux se disait aussi chargé qu’une bête de somme ; lors de ses premières expéditions dans le désert égyptien au début des années 1980, il avait toujours avec lui, sans compter ses affaires personnelles, un appareil photo avec plusieurs objectifs, un autre pour le noir et blanc, des jumelles, un magnétophone, une presse pour les plantes, un filet pour capturer des oiseaux à photographier ainsi que des classeurs74. On arrêtera là cette énumération suffisamment abondante pour conclure que les savants ont utilisé beaucoup d’objets sans lesquels ils n’auraient pu produire, avancer et transmettre les connaissances ou, du moins, aussi bien.





Produits numériques


La présence désormais quasi universelle d’un ordinateur personnel sur les bureaux, souvent en leur centre, dit la place que ce nouvel instrument a conquise dans le travail intellectuel. D’ailleurs, le géographe, que nous avons vu partir bien chargé, ajouta en 1995 à son attirail un Macintosh portable avec, terrain oblige, un chargeur solaire et des batteries de rechange75.

Avant de passer à l’ordinateur et au numérique, il s’impose de faire un détour par une technique qui semble aujourd’hui préhistorique, la mécanographie. Pourtant, elle suscita bien des enthousiasmes dans les sciences humaines et sociales : la carte perforée, et il y en eut toute une gamme, devint alors l’outil moderne76. En France, les premiers usages en auraient été faits en démographie et en archéologie. Dans cette dernière discipline, c’est en 1955 que fut constituée, à l’initiative de Jean-Claude Gardin, « une documentation expérimentale sur cartes perforées relative à certains aspects de la culture matérielle à l’âge du bronze en Asie occidentale77 ». L’histoire sociale quantitative fit dans les années 1960 largement usage de la nouvelle technique, inaugurée par l’article d’Adeline Daumard et François Furet, « Méthodes de l’histoire sociale : les archives notariales et la mécanographie », paru dans les Annales ESC en 1959. À côté de traitements en machine pour de très gros volumes de données ou pour des chercheurs bénéficiant de financements importants, la technique fut souvent manuelle et artisanale : on partait de cartes, généralement de format oblong, perforées sur leurs bords ; on ouvrait à l’aide d’une pince (type pince à tiercé) les perforations correspondant aux caractéristiques étudiées ; on plaçait les cartes les unes contre les autres en sorte qu’elles se superposent exactement ; on passait une aiguille (type aiguille à tricoter) à travers tout le paquet dans les perforations correspondant aux caractéristiques recherchées ; une secousse faisait tomber toutes les cartes intéressant la documentation que l’on voulait recueillir ; des tris croisés pouvaient être faits en utilisant simultanément plusieurs aiguilles78. L’ordinateur a eu raison des cartes perforées de toutes espèces.

On n’entrera pas ici dans le développement de la science informatique ni dans les progrès des technologies en la matière (appareils, matériels, logiciels) et on ne retracera pas comment la société scientifique est aussi devenue numérique. La science informatique a pénétré toutes les autres sciences, leur fournissant non seulement des techniques de calcul, mais encore des concepts et des points de vue nouveaux79. Elle a amené des bouleversements considérables dans les environnements et les instruments de travail : les plates-formes techniques du Genopole qui ont été évoquées en sont l’exemple concret, tout comme l’imagerie numérique et la robotique chirurgicale sur laquelle on reviendra.

On s’en tiendra ici à la documentation scientifique. Les chercheurs se sont saisis des possibilités que « la machine » leur offrait, possibilités qui, dans un temps très court, se sont multipliées. Un ouvrage publié en 1995 donne à voir « les services », déjà nombreux, dont « la communauté enseignement et recherche » pouvait disposer en France grâce à « l’Internet », que l’on se connecte via RENATER ou via des prestataires privés : la messagerie électronique, des news, l’accès au Web – « système d’information réparti hypermédia (hypertexte et multimédia) », la possibilité de monter un serveur d’informations pour un laboratoire ou une université, des banques et bases de données, l’édition électronique, plus particulièrement de revues, la numérisation de catalogues et de documents80. Une dizaine d’années plus tard, le paysage numérique s’était considérablement densifié. Déjà en 2006, la masse de documents numériques et de nouveaux objets numériques – les hyperdocuments (ou documents hypertextes) et les documents multimédia (plurimédia ou hypermédia) – amenait à parler d’une « banalisation de la documentation numérique81 ».

À cet effet, joua, à côté d’avancées technologiques, le libre accès (Open Access), ou plus précisément « la science ouverte », c’est-à-dire « toutes les formes de libres mises à disposition des connaissances produites par des scientifiques ». Les dispositifs d’accès direct ont, en un temps très court, proliféré : archives ouvertes, sites de laboratoire, bibliothèques numériques ouvertes, revues type PLOS, carnets de recherche, blogs de chercheurs, dépôts institutionnels, plateformes de recherche, etc.82. Si l’édition électronique reste encore limitée pour les livres, mis à part les bibliographies, elle a très largement investi les revues : des collections papier ont été numérisées, des revues ont été publiées dans une double présentation papier numérique ou sous la seule forme numérique – la revue étant alors soit née numérique, soit devenue telle. Le mouvement vers la numérisation a été rapide depuis la première véritable revue électronique, avec texte, illustrations et un comité de lecture qui parut en 1992, The Online Journal of Current Clinical Trials ; en 1994, on comptait 400 titres électroniques, en 1997, plus de 3 000 et, début 2006, plus de 16 000. En 2008, à s’en tenir à l’édition scientifique de langue anglaise, on pouvait lire en ligne 96,1 % des revues de sciences, techniques et médecine et 86,5 % des revues consacrés aux sciences humaines et sociales83.

L’augmentation considérable des ressources a amené la création d’outils de repérage. Ce furent d’abord parfois des outils papier. Ainsi, dès le premier tiers des années 1990, les bases de données scientifiques étaient devenues si nombreuses qu’il devenait difficile de s’orienter dans un univers aussi immense que mouvant. En 1993, l’éditeur Bowker Saur commença à publier des répertoires spécialisés en la matière où les produits étaient non seulement listés, mais encore précisément décrits et évalués. Le premier à paraître, en 1993, le fut pour la médecine ; en 1996, était publié le 8e volume : il concernait la chimie et ne comptait pas moins de 1 200 pages grand format, ce qui suffit à dire la quantité de bases de données qu’il y avait déjà dans cette discipline84.

Les outils papier pour le numérique n’ont eu qu’un temps ; d’ailleurs, la série World Databases in s’arrêta en 1996 avec le volume X. À leur tour, ils sont devenus numériques. Moteurs de recherche, portails, dispositifs de veille et d’alerte permettent de se repérer dans la masse exponentielle des données et d’y accéder. Les plateformes de revues, constituées par des éditeurs ou des agrégateurs qui publient ou diffusent plusieurs dizaines ou centaines de titres, offrent des fonctionnalités multiples de recherche.

Les chercheurs disposent donc d’une masse considérable d’outils pour s’orienter dans des ressources numériques en constante expansion. Ils en ont fait un usage croissant, ce qui ne veut pas nécessairement dire expert, et variable suivant les individus et les disciplines, avec toujours un écart entre sciences et humanités85. De façon assez générale, il apparaît que l’énorme potentiel à disposition n’est pas toujours employé à sa pleine mesure, qu’il serait même sous-exploité86. L’« important analphabétisme informationnel » qu’un spécialiste constatait en 200487 n’a point disparu, s’il ne s’est pas aggravé à la mesure de l’arrivée de nouveaux outils ; ce que laisserait entendre la demande récente et insistante d’une éducation aux outils numériques, y compris pour les natifs numériques88. De sorte que l’on n’a jamais autant parlé de bricolage, de hasard et de sérendipité que dans ce contexte de surabondance d’informations et d’instruments de recherche89.



*

* *

L’inventaire auquel on a procédé met en évidence la masse colossale des outils existants dans le monde du travail scientifique. Cela entraîne deux remarques. La première est de portée générale. Le tri qui a été fait l’a été suivant des catégories génériques dans la production et la communication du savoir : il en ressort que chacune de ces catégories recouvre une diversité incroyable de produits, si grande que l’on n’a parfois pu en donner qu’une simple idée. Sur la base de ce constat, on mesurera toute la justesse d’expressions usuelles comme culture de l’écrit, de l’imprimé, de l’image, du numérique. Bien plus, on soulignera ce qu’ont de réducteur ces expressions pour insister sur l’extension qui est la leur dans le monde pourtant limité de la société du savoir.

La seconde remarque porte particulièrement sur l’outillage lui-même, très nombreux. Certains de ces outils ont une existence qui dure encore à l’égal de ce qu’elle était dans un lointain passé, par exemple, le bout de papier sur lequel une note rapide est jetée ; d’autres ont été « recyclés » par le numérique90, telles la revue ou les projections lumineuses qui sont devenues des présentations PowerPoint. Il en est qui, d’origine récente, se sont avérés des produits d’usage courant, comme les photocopies qui, parfois très annotées, sont une part notable de bien des dossiers de recherche, alors que d’autres, accueillis avec enthousiasme, ne furent utilisés qu’avec réticence, comme le microfilm ou le cédérom, sans compter ces supports « modernes » qui ont largement disparu, comme les disquettes et les listings papier à pliage paravent. Ces quelques observations invitent, sur la base des données fournies par l’inventaire, à procéder à une enquête génétique et historique si l’on veut comprendre, au-delà du décompte des outils, ce que furent leur conformation et leur usage.




CHAPITRE 2


Le multiple et la norme



L’inventaire sommaire qui a été effectué dans le premier chapitre a montré la masse formidable de l’outillage dont les savants ont disposé au cours du temps, que l’on prenne en compte les divers champs disciplinaires, que l’on se tienne à l’un d’eux, que l’on considère une spécialité, voire une sous-spécialité. Après avoir recensé des produits relevant d’une catégorie technologique donnée (oral, écrit, imprimé, etc.), il s’agit désormais de porter le regard sur les produits mêmes, de retracer leur devenir dans ses principaux moments. Par la force des choses, alors que cette masse défie le comptage, on s’en tiendra à quelques outils seulement. Leur choix a été fait en prenant en compte deux facteurs principaux : une fréquence d’emploi dans le monde savant en général ou dans un grand domaine disciplinaire, ce qui leur confère une certaine représentativité ; une durée conséquente permettant de saisir une évolution sur un temps relativement long et d’éventuelles mutations technologiques. Le séminaire, la fiche, la revue, le graphique, tels seront les objets étudiés. Le focus fait sur chacun d’eux n’empêchera pas, ne serait-ce qu’à titre contextuel, d’évoquer des realia voisines.

L’inventaire raisonné auquel on procédera visera non tant à établir des datations qu’à saisir les pratiques des usagers inventant un outil, le conformant et l’adaptant à leurs nécessités. On pourrait dire qu’il en va de même avec le séminaire, la fiche, la revue et le graphique, leurs catégories et leurs types, qu’avec les pinces de nombreuses sortes que des chirurgiens ont conçues ou perfectionnées pour le meilleur usage dans tel ou tel acte opératoire1. Comptera ici, au premier chef, la matérialité des outils ; leur mise en œuvre ne sera considérée qu’en tant qu’éclairant leur nature, leur conception ou leur fonction.

L’approche génétique permettra également de montrer comment des techniques intellectuelles se sont constituées en de véritables genres avec leurs règles et leurs normes. Des conventions se sont établies, qu’il convient de respecter pour que les meilleurs effets soient produits, c’est-à-dire afin d’opérer au mieux le repérage, l’enregistrement, la transmission des connaissances. Ce respect implique un apprentissage partagé au sein d’une communauté, large ou étroite selon que l’outil est commun à beaucoup ou qu’il n’est employé que par un groupe restreint ; peu importe que le processus d’acquisition soit important ou minime.





Le séminaire et « la science parlée »


Le séminaire est aujourd’hui une modalité ordinaire de la communication orale dans l’Université : il n’est que de penser aux « quelque mille séminaires » qu’héberge en 2013-2014 la seule EHESS3. Une vue rétrospective montrera le succès de cette forme depuis son invention à la toute fin du XVIIe siècle, sa grande plasticité ainsi que les multiples actualisations auxquelles elle a donné lieu.

L’histoire du séminaire a son point de départ dans le monde germanique4, et elle commence avec le Seminarium praeceptorum fondé à l’université de Halle en 1695 et, plus encore, avec le séminaire philologique de Göttingen qui date, lui, de 1737, et qui a véritablement servi de modèle. Les créations se multiplièrent au XVIIIe et plus encore au XIXe siècle. Ainsi, à Berlin, le nombre des séminaires doubla entre 1820 et 1870, et doubla encore entre 1870 et 1909. Alors qu’au XVIIIe siècle, les séminaires n’existaient principalement qu’en théologie et en philologie, par la suite, il s’en créa dans toutes les disciplines : ainsi à l’université de Bonn en 1878, il y avait huit séminaires (théologie catholique, théologie protestante, droit, philologie ancienne, philologie romane, sciences naturelles, histoire, mathématiques). Toutefois, les quinze séminaires scientifiques qui avaient été fondés en Allemagne au cours du XIXe siècle eurent une existence moins heureuse, et tous disparurent quand ils ne furent pas absorbés par des instituts spécialisés à partir des années 1860.

Les étrangers qui allèrent outre-Rhin dans les années 1860-1880 pour observer l’université allemande furent frappés par cette « institution éminemment originale » qu’était le séminaire et, dans leurs rapports, ils sentirent la nécessité d’en donner une définition. « On désigne sous ce nom un lieu de réunion où quelques étudiants particulièrement studieux ou bien doués, choisis par le professeur, travaillent une fois par semaine sous sa direction », écrivait Edmond Dreyfus-Brisac dans sa relation sur l’université de Bonn. Publiée dans le même volume, la définition que donna M. Cammartin qui, lui, séjourna à Heidelberg était de nature différente, présentant le Seminar comme « une conférence servant de complément à certains cours, conférence dans laquelle les étudiants sont interrogés et apportent des travaux préparés qui sont discutés tant par les autres étudiants que par le professeur lui-même5 ». Définitions qui, si elles appellent bien des retouches, allèguent deux facettes d’une même réalité : un lieu institutionnel, une modalité pédagogique.

Les séminaires furent d’abord d’initiative privée, se tenant chez le professeur et mettant à profit sa bibliothèque. Puis, et sans que cette forme privée disparût, des séminaires furent, surtout dans la seconde moitié du XIXe siècle, richement dotés par la puissance publique ; ils disposèrent dans l’université de locaux particuliers, d’une bibliothèque et offrirent des facilités aux séminaristes (une salle de travail, parfois des bourses, des prix pour les meilleurs travaux) ; il est cependant des séminaires d’État sans locaux spéciaux. La diversité qui ressort en prenant un point de vue institutionnel est encore plus grande lorsque l’on considère la modalité pédagogique – un enseignement « pratique » complétant le cours. À l’origine le séminaire, celui de Halle, avait été créé afin de former des professeurs de « l’enseignement secondaire » et de remplacer ainsi les pasteurs peu préparés à ces fonctions. Les séminaires philologiques qui s’établirent sur le modèle de celui de Göttingen eurent le même but principal ; à cet effet, les séminaristes, pour une partie, boursiers, complétaient là le cours reçu à l’université par des exercices pratiques sur les matières enseignées ainsi que par des exercices didactiques prenant la forme de leçons. Cette finalité demeura encore au XIXe siècle, et l’on a noté la corrélation entre la prolifération des séminaires philologiques et l’apothéose du Gymnasium humaniste. À cette époque, toutefois, s’était développé, d’abord dans quelques universités novatrices, puis dans toutes, un idéal de Wissenschaft qui inspira un haut niveau non seulement d’enseignement mais encore de recherche : les séminaires en furent la traduction institutionnelle. Dans un premier temps, toutefois, les gouvernements continuèrent à voir dans ces institutions des lieux de formation non pour des chercheurs mais pour de futurs fonctionnaires, n’accordant des financements importants qu’à partir des années 1840 ; d’où des séminaires de recherche qui demeurèrent privés, se tenant chez les professeurs6. Le développement des séminaires amena dans le dernier quart du XIXe siècle la création du Proseminar, subdivision inférieure réservée à des étudiants moins avancés ; alors que le séminaire n’accueillit jamais qu’une élite d’étudiants, le proséminaire était à la fin du siècle obligatoire pour tous, du moins dans les matières juridiques.

Si le séminaire prit une orientation de recherche, les activités qui s’y déroulaient relevaient surtout d’une formation à la recherche. Des étudiants apprenaient à travailler sous la conduite d’un professeur en se livrant à des exercices qui étaient exclusivement oraux – par exemple, en histoire, la lecture et le commentaire de documents – ou qui se fondaient sur un travail écrit fait par un séminariste et discuté par un Opponent comme dans une dispute. Les échanges étaient parfois animés, parfois réduits à peu de choses. Il arriva aussi que le séminaire tournât à la conférence : ainsi Mommsen parlait seul à partir du travail d’un étudiant et du compte rendu qu’un autre lui avait remis. En fait, les variantes sont nombreuses suivant les universités, voire au sein d’une même université, suivant les disciplines et, bien sûr, suivant les professeurs. Les observateurs étrangers ont insisté sur ce point et ont assorti toute généralisation d’exceptions et de particularités donnant à voir, déjà dans ces années-là, la diversité des actualisations d’une même modalité pédagogique7.

La fascination qu’exercèrent alors les universités allemandes fut largement partagée dans le monde occidental, et le modèle que représenta le séminaire se diffusa amplement. Hors de l’espace germanique, il ne fut pas toujours une institution richement dotée disposant de locaux, d’une bibliothèque et autres ressources ; par contre, pas plus qu’en Allemagne, il ne fut le lieu d’une collaboration en vue d’un travail collectif original, mais une forme d’enseignement « pratique » consistant généralement en exercices – étude de documents, exposés – que des étudiants faisaient sous la conduite du professeur dans le cadre d’une formation approfondie. En France, le séminaire ne gagna que tardivement l’Université. Par ailleurs, on évita longtemps le mot séminaire qui sentait à la fois l’Église et l’Allemagne et on lui préféra celui de conférences que ce soit à l’École pratique des hautes études (1868) ou encore à l’École libre des sciences politiques (1871-1872). Dans les facultés de droit, le séminaire juridique allemand aboutit, au tournant du siècle, à une création originale, « la salle de travail » qui, pourvue d’une bibliothèque, était aussi le lieu d’une conférence réunissant autour du professeur une dizaine d’étudiants avancés : les exposés ne devaient point tourner à la leçon d’agrégation, mais être interrompus, susciter des questions, des discussions ; il s’agissait d’apprendre à manipuler les sources, et de pratiquer l’explication de texte, singulièrement celle de la jurisprudence.

De ces descriptions et de ces exemples du XIXe siècle, il ressort que le séminaire fut d’abord et avant tout le lieu d’une formation « pratique ». Il l’est resté à côté de modalités qui, dans les divers domaines du savoir, l’ont orienté vers de la recherche de très haut niveau, à l’instar des séminaires que François Jacob fréquenta à l’Institut Pasteur ou à l’Institut de biologie physico-chimique dans le cadre du Club de physiologie cellulaire fondé en 1947 par Jacques Monod : là, le chercheur devait « faire en public, devant ses pairs, la preuve de son talent ou de sa nullité », et les pairs comprenaient le fleuron de la science en la matière et, à l’occasion, des invités de grande distinction8.

Dans le dernier tiers du XXe siècle, les séminaires se sont multipliés et diversifiés à la mesure de la croissance de la population universitaire et des niveaux de publics. Cela ressort, on ne saurait mieux, d’une étude portant sur la physique théorique en France. On distingue, d’une part, des séminaires classiques : ils comprennent des séminaires d’intérêt général, de périodicité hebdomadaire ou bimensuelle, censés intéresser tous les chercheurs du laboratoire ou du département par le choix de grands sujets ; des séminaires spécialisés, le plus souvent hebdomadaires, destinés à un public plus restreint ; parfois des séminaires internes, eux, mensuels, où chaque chercheur du laboratoire « planche » à tour de rôle pour rendre compte à ses collègues de ses recherches. Il est, d’autre part, des séminaires qui ont été qualifiés d’atypiques mais qui, avec le temps, le sont moins : les séminaires sandwichs – variante française des brown bag ou lunch seminars américains – qui sont des séminaires spécialisés, mais moins formels ; le journal club, lui aussi importé des États-Unis, où un conférencier expose les travaux d’un autre chercheur qui n’est pas nécessairement de sa spécialité, où l’on invite des doctorants à présenter leurs recherches ; le rendez-vous des thésards (devenu séminaire de doctorants) qui a lieu une fois par semaine pour les seuls étudiants en thèse dont on a constaté qu’ils étaient incapables de suivre le séminaire général : il est ouvert à tous les doctorants du campus qui entendent là des exposés d’un niveau très bas, comparables à des cours. À l’autre extrémité, c’est-à-dire pour les seuls chercheurs, il existe le séminaire de l’Institut Henri-Poincaré, séminaire phare de la discipline, commun à tous les laboratoires de physique théorique de la région parisienne ; de très haut niveau et accueillant des invités de renom, il réunit un auditoire fourni et permet de faire l’économie des autres9.

Le mot séminaire recouvre une gamme de pratiques, référant soit à une initiation et à une formation à la recherche, soit à une véritable activité de recherche, depuis la diffusion de l’information scientifique jusqu’à l’élaboration en commun du savoir. Alors que la forme séminaire se décline à l’infini, joue la personnalité du professeur-directeur pliant la modalité à son gré, privilégiant un type d’exercices, organisant des séminaires de niveau, mettant en place un groupe de recherche, voire un plan d’études, invitant des membres du séminaire ou des chercheurs extérieurs à présenter leurs travaux, etc., transformant un exercice universitaire en un rituel avec ses normes, ses usages, ses codes10.

Derrière la variété de formes que le séminaire a engendrée, il est une armature de règles plus ou moins explicites, plus ou moins visibles. Les séminaires allemands du XIXe siècle et, plus précisément, les séminaires d’État, eurent un véritable règlement, souvent imprimé, avec parfois des mises à jour, fixant tout dans les moindres détails : le nombre des membres, les modalités d’admission, la discipline à observer, la périodicité et l’horaire des séances, la nature des exercices et des travaux, la gestion de la bibliothèque et des locaux, les bourses, prix et récompenses, etc. Plus près de nous, le séminaire de recherche en physique théorique se déroule selon des règles communes à l’Europe et aux États-Unis, « règles d’or » qui ont été formalisées et qui s’imposent à la communauté. Il se tient en une heure, sauf en Russie où l’on parle pendant une heure quarante-cinq minutes ; cette durée, relativement brève, a été jugée adéquate à la nécessaire concentration. L’exposé de l’intervenant comprend trois séquences de vingt minutes environ chacune : dans la première, il se livre à des considérations générales qui, situant l’exposé dans un contexte plus large, sont censées être compréhensibles par toute l’assistance ; dans la deuxième, il démontre les résultats obtenus ; dans la troisième, il donne des explications plus techniques qui intéressent les spécialistes, puis il répond aux questions qui sont posées. À la différence de ce qui peut se passer dans un groupe de travail, l’intervenant n’est pas interrompu pour une précision, un éclaircissement ou une question : toutes les demandes sont regroupées à la fin de l’exposé11.

Des styles nationaux contribuent à l’occasion à régler le séminaire, plus précisément le régime de la parole en séminaire. Une étude comparée de séminaires d’anthropologie culturelle et de littérature en Angleterre et en Italie a montré que cette même forme de communication orale donne lieu à deux modalités différentes, dialogique dans le premier pays avec des interventions brèves et des procédés visant à instaurer une discussion, monologique dans le second avec des exposés longs et une place limitée accordée à la discussion collective12.

Il est enfin des dispositions matérielles qui organisent la parole en séminaire : tous les participants sont assis autour d’une table. Cette installation qui semble aujourd’hui banale ne l’était pas au XIXe siècle quand elle s’instaura : le professeur montait alors en chaire. À sa création en 1868, l’École pratique des hautes études exclut délibérément la chaire afin, expliqua-t-on, de marquer l’originalité de l’organisation de son enseignement, la profonde différence avec les « leçons dogmatiques » de l’Université, avec le « monologue de la chaire13 ».

Le plus souvent, les règles ne sont pas aussi détaillées ni explicitées que dans les règlements des séminaires allemands du XIXe siècle ou dans la communauté des physiciens théoriciens contemporains. Toutefois, il existe toujours des recommandations, des instructions, des dispositions, parfois minimes, il est vrai, qui concernent la durée de la séance, son format, l’ordre des prises de parole, la durée de cette parole, etc., avec de multiples variantes, telle la distribution à l’avance d’un texte qui, après une brève présentation par son auteur et parfois par un répondant (lointain descendant de l’Opponent des séminaires allemands), fait l’objet d’une discussion. Généralement, tous ces principes de structuration vont de soi et, le plus souvent, c’est un incident ou un insuccès qui les rend manifestes. Il n’est rien là de naturel : dans la sphère de « la science parlée », le séminaire est un véritable « genre académique14 ».





Fiches et fichiers


L’expression déballage de fiches est utilisée pour qualifier un ouvrage, notamment une thèse, où l’auteur livre ses matériaux en vrac, du moins sans les avoir véritablement mis en œuvre suivant un plan, autre technique qui coordonne notes et idées. Au-delà du jugement négatif qu’elle contient, cette expression donne à voir ce qui ne devrait plus se voir à la lecture de l’ouvrage, mais qui a existé dans sa genèse : des fiches, à la fois produits de la collecte de l’information, voire d’une première élaboration, et résultat d’une activité, faire des fiches. La question est de savoir comment la fiche est devenue un outil aux mains des chercheurs et quelles conséquences son emploi a emportées au-delà de la production de masses de papier – Henri-Jean Martin faisait état pour sa thèse de quelque 45 000 fiches15.

Je passerai rapidement sur un genre de fiche très commun jusqu’à ces dernières années : la fiche catalographique, que l’on pouvait voir, également en masse, dans les bibliothèques ; pensons aux longues rangées d’énormes fichiers qui occupaient le gros de l’espace dans la salle des catalogues du Département des Imprimés de la Bibliothèque nationale. En France, si l’on excepte un bref essai de catalogage sur fiches (en fait, au dos de cartes à jouer) au lendemain de la Révolution, on en resta à des registres, les fiches ne s’imposant qu’à la fin du XIXe siècle, puis se normalisant progressivement dans leur format et dans le contenu de la notice. Jouèrent dans la diffusion et l’adoption de la fiche cartonnée les réalisations de la documentation et, tout particulièrement, les initiatives du bibliographe belge Paul Otlet16. Reste que les grandes bibliothèques ont imprimé les catalogues de leurs fonds – entreprises de temps long, parfois très long comme à la Bibliothèque nationale où la publication du Catalogue général Auteurs s’étala sur quatre-vingt-cinq ans (1897-1982). Cela amena dans cette institution à ouvrir des fichiers de suppléments qui en côtoyaient d’autres pour les anonymes ainsi que pour les « catalogues matières » qui, eux, se trouvaient divisés en quatre tranches chronologiques. Le lecteur devait développer une petite expertise pour s’orienter dans ce labyrinthe de fichiers – et il y en avait d’autres –, retrouver la cote du livre qui l’intéressait ou faire une recherche par sujet. Par ailleurs, il pouvait mesurer la diversité de la fiche catalographique, dans sa présentation matérielle (manuscrite, dactylographiée, imprimée), dans son support (de divers aspects et dimensions), dans son rangement (dans des meubles à tiroirs mais parfois aussi dans des registres) et, enfin, dans la disposition et le contenu de la notice qui avaient varié au fil du temps. Avec l’informatisation des catalogues, à la BNF aussi bien qu’ailleurs, les fichiers à l’usage des lecteurs ont quasiment disparu, mis à part pour des collections spécialisées17. Sur ce bref rappel d’un temps pas si lointain que cela, on conclura, qu’à côté de faire des fiches, le chercheur en voyait en abondance : la fiche participait de son environnement familier.

Depuis le début de la période ici étudiée, les exemples ne manquent pas de savants qui ont fait un grand usage, à côté de registres, carnets, feuillets pliés en cahiers et feuilles volantes, de bouts de papier, soit des morceaux plus ou moins grands, voire des bandelettes, sur lesquels ils jetaient des notes ou copiaient des titres d’ouvrages ou des extraits de leurs lectures ; puis, ils les collaient sur des pages, par exemple, pour confectionner un catalogue, ou ils les groupaient en liasses ou encore ils les laissaient volants18. Dans ce dernier cas, cette technique de notation emportait, en engendrant une masse de papier mobile, le risque de la perte ainsi que la difficulté à mettre la main sur l’information que l’on cherchait.

Le problème se serait posé très tôt – à la mesure de la diffusion de la pratique ? – pour qu’en 1640 l’Anglais Thomas Harrison pensât à une sorte d’armoire à fiches qui permettrait de stocker, de classer et de retrouver les notes de lecture. Ce projet non réalisé fut repris par l’érudit allemand Vincent Placcius. Il le perfectionna et le publia dans son De arte excerpendi (1689). Des gravures permettent de se faire une idée concrète de cette « armoire savante » (scrinium literatum). Le corps du meuble ainsi que l’intérieur des battants étaient équipés de tringles métalliques verticales correspondant chacune à une lettre de l’alphabet (A, B, C, etc.). Des crochets étaient placés sur les tringles et à chacun était affectée une vedette-matière commençant par la lettre de l’alphabet de ladite tringle. Des bandelettes de papier portant les notes étaient, au fur et à mesure de leur confection, enfilées sur les crochets correspondant à leur sujet. L’armoire pouvait comprendre de 3 000 à 3 300 entrées matière. Deux exemplaires en furent construits : l’un appartint à Placcius, l’autre à Leibniz qui l’aurait peut-être utilisé quand il travailla à son histoire de la maison de Brunswick19. Le juriste Jakob Moser (1701-1785), lui, employa bien un système matériel de gestion des fiches et il en a laissé la description. Il avait fait fabriquer des casiers où il pouvait, de part et d’autre d’une séparation médiane, placer des fiches (en fait des demi-feuilles) qui avaient un format vertical ; elles étaient séparées par « des bandes de carton large d’un doigt et demi et un peu plus hautes que les demi-feuilles, où, précisait-il, figurent les noms de tous les domaines du droit public allemand, selon un classement systématique, ainsi que des rubriques sur lesquelles je prends des notes pour les utiliser plus tard ». Sur les feuilles placées entre les intercalaires, il notait non des extraits de livres, mais de brefs renvois aux passages intéressants. Chaque casier avait une capacité d’environ mille feuilles. Le dispositif avait plusieurs avantages tant en raison de la possibilité d’extension de chaque rubrique et de la flexibilité du système de classement qu’en ce qu’il facilitait l’écriture des livres, le fichier ayant été constitué selon un plan préalable ; au moment de la rédaction, la documentation était ordonnée et facilement repérable. La masse même de l’œuvre imprimée de Moser – 331 titres, soit plus de 100 000 pages – en apporterait la preuve20.

Ce système aussi bien que l’armoire de Placcius était à la fois un instrument de stockage et de classement des fiches et un outil de production du savoir. On ne peut lire ces descriptions sans que ne revienne à l’esprit un texte de Lévi-Strauss évoquant une machinerie analogue de plus grande ampleur. L’anthropologue qui pratiqua largement le travail par fiches décrivait dans un article consacré à l’étude structurale du mythe « la technique » qu’il utilisait à cet effet : inscription de chaque phrase du récit sur une fiche portant un numéro d’ordre correspondant à sa place dans le récit, mise en relation des fiches de façon à former « des paquets de relations », disposition tabulaire desdits paquets. Après avoir insisté sur la nécessité absolue de prendre en considération l’ensemble des versions de chaque mythe, il concluait à la masse des fiches qui était ainsi engendrée : les textes mythiques sont « extrêmement volumineux » et « une variante de dimension moyenne fournit plusieurs centaines de cartes ». Si un travail d’équipe et un personnel technique pouvaient opérer la mise en fiches, l’étape ultérieure impliquait la confection d’un mobilier spécifique. « Pour découvrir la meilleure disposition de ces cartes en colonnes et en rangées, il faudrait avoir des classeurs verticaux d’environ 2 m × 1,50 m garnis de casiers où l’on puisse ranger et déplacer les cartes à volonté. Et dès qu’on se propose d’élaborer des modèles à trois dimensions, pour comparer plusieurs variantes, autant de classeurs que de variantes sont nécessaires, ainsi qu’un espace suffisant pour les mouvoir et les disposer librement. Enfin si le système de référence fait appel à plus de trois dimensions (ce qui risque de se produire rapidement […]), il faut recourir aux cartes perforées et à la mécanographie ». Les « conditions précaires » de la recherche en France ne permettaient ni l’acquisition de ces multiples meubles classeurs ni le recours à la mécanographie21. Lévi-Strauss en resta au « jeu manuel » décrit dans l’entretien qui a été précédemment cité.

Il n’est pas toujours aisé, ni même possible, de savoir comment par le passé lointain des savants ont travaillé avec des petits bouts de papier, feuilles découpées ou fiches, de repérer les usages qu’ils en ont fait au-delà, par exemple, d’un simple mémo. Ce put être des cartes à jouer dont le verso était souvent blanc. L’abbé Rozier s’en servit pour dresser l’index matières des publications de l’académie des sciences22. Leur utilisation aurait été moins exceptionnelle, plus précoce et plus diverse que l’exemple toujours cité du catalogage des livres sous la Révolution le laisserait entendre. Rousseau nota sur des cartes à jouer des réflexions qui lui venaient au cours de ses promenades23, et son compatriote de Genève le mathématicien Paul-Louis Lesage (1724-1803) en fit un usage courant à l’instar de feuilles de blocs-notes : quelque 30 000 cartes ont été conservées24.

Les dispositifs mis en place par Linné sont tout à fait révélateurs de la fonction dévolue à la fiche par le botaniste suédois dans le processus du travail intellectuel. Linné a utilisé plusieurs modalités d’enregistrement des données : des carnets, des feuilles pliées en cahiers, des feuilles volantes et, vers la fin de sa vie, alors qu’il préparait un livre contenant des descriptions d’espèces et de genres nouvellement découverts, des fiches. Elles se présentent sous la forme de petits morceaux de papier de dimension uniforme (7,5 × 13 cm). Sur chacune sont portées, sous le nom d’un genre écrit en lettres capitales, des notes sur ce genre, éventuellement accompagnées de dessins. Les fiches portant le même nom de genre fournissent par leur accumulation la description complète, ou la plus complète, du genre en question. Ce système totalement flexible permettait d’enregistrer des découvertes ou des informations nouvelles (et la botanique n’en manquait pas) sans perdre une vue d’ensemble ; il s’agissait simplement de faire une fiche et de l’insérer à la bonne place25.

Des archives de savants et d’érudits des XVIe-XIXe siècles montrent, avec la présence de bouts de papier de diverses présentations, la place que ce support eut dans l’économie du travail intellectuel. Reste l’impression qu’il s’agit là de pratiques personnelles. Sauf exception, on ne trouve pas un usage systématique de la fiche, tel qu’il s’imposa à partir de la fin du XIXe siècle. On ne saurait dire si ce fut alors sous l’influence des techniques de la documentation, du positivisme, d’une démarche scientifique, d’une professionnalisation de la recherche, ou encore sous l’effet combiné de tout cela. Quoi qu’il en soit, on voit alors des savants parler couramment de fiches et en faire, et des manuels expliquer comment s’y prendre et pourquoi.

Les fiches deviennent un « système » pour reprendre une expression de Langlois et Seignobos dans leur Introduction aux études historiques (1898). Après avoir noté que l’accord est général sur cette technique (« tout le monde admet aujourd’hui qu’il convient de recueillir les documents sur des fiches »), les deux historiens indiquaient comment procéder : « chaque texte est noté sur une feuille détachée, mobile, munie d’indications de provenance aussi précises que possible ». Ils soulignaient les avantages du système : classement et reclassement à volonté, possibilité de fiches de renvoi pour des documents intéressants à plusieurs points de vue. Ils ne dissimulaient pas le désavantage d’un surcroît d’écriture qui en dérivait portant des personnes à s’obstiner « à préférer la méthode si défectueuse des cahiers » ; cette « complication infime » était vite balayée. Quant aux inconvénients liés à la « mobilité » des fiches, feuilles volantes, ils étaient aisément palliés par « des précautions très simples » : l’emploi de fiches de dimension uniforme, résistantes et le classement au plus tôt dans des « chemises » ou des tiroirs. Des indications étaient données quant au classement des fiches : l’érudit qui compose des corpus ou des régestes et qui organise la documentation pour autrui procédera, selon le but précis de son travail et la nature des documents, par date, lieu d’origine, contenu ou forme ; le « travailleur ordinaire » qu’est l’historien privilégiera un ordre systématique correspondant à la monographie qu’il prépare ou, de façon provisoire, un ordre alphabétique de mots choisis comme rubriques. Dans un cas comme dans l’autre, Langlois et Seignobos recommandaient d’observer « des habitudes matérielles », à savoir : « en tête de chaque fiche, inscrire, s’il y a lieu, la date, et, en tout cas, une rubrique ; multiplier les cross-references et les index ; tenir état (sur des fiches rangées à part) de toutes les sources utilisées, afin de pas être exposé à recommencer, par inadvertance, des dépouillements déjà faits, etc. – L’observation régulière de ces pratiques, soulignaient-ils, contribue beaucoup à rendre plus aisés et plus solides les travaux d’histoire qui ont un caractère scientifique ». Dans le chapitre consacré à la critique d’interprétation, ils revenaient sur la nécessité d’« adopter le système des fiches » : « chaque fiche recevra l’analyse, soit d’un document, soit d’une partie distincte de ce document, soit d’un épisode d’un récit ; l’analyse devra indiquer non seulement le sens général du texte, mais autant que possible, le but et la conception de l’auteur. On fera bien de reproduire textuellement les expressions qui sembleront caractéristiques de la pensée de l’auteur ». Dans un troisième passage, ils mettaient en évidence le rôle de la fiche dans une démarche scientifique qui, en histoire, comme ailleurs, passait par la comparaison des affirmations. « On commence par classer les résultats de l’analyse critique, de façon à réunir les affirmations sur un même fait. Matériellement, l’opération est facilitée par le procédé des fiches (soit qu’on ait noté chaque affirmation sur une fiche, soit qu’on ait créé pour chaque fait une fiche seulement, sur laquelle on aura noté les différentes affirmations au fur et à mesure qu’on les rencontrait). Le rapprochement fait apparaître l’état de nos connaissances sur le fait ; la conclusion définitive dépend du rapport entre les observations26 ».

Le « système des fiches » se diffusa vite et largement, comme il ressort de l’ouvrage de Paul Chavigny sur l’organisation du travail intellectuel. L’auteur, professeur de médecine à l’université de Strasbourg, partait de la nécessité qu’il y avait désormais dans le travail intellectuel à avoir une méthode pour économiser temps, forces et argent : le travailleur devait commencer par « apprendre la technique pratique de toute production intellectuelle ». Prendre des notes ne passait plus par les cahiers mais par le « système des fiches » que Chavigny qualifiait de « nouveau ». Dans le chapitre qu’il lui consacrait, il en expliquait le principe et précisait les avantages ; puis, il indiquait la manière de faire des fiches et de les classer, les classifications possibles (dont la classification décimale) et la nécessité de tenir un cahier-répertoire de la classification adoptée. Dans un autre chapitre portant sur l’ordre matériel et le rangement pratique, il décrivait le mobilier qui, « ces dernières années », avait été conçu pour ranger les fiches : boîtes, tiroirs, meubles, tables-meubles. Ce matériel qui répondait au nouvel impératif de classement vertical imposé par la fiche offrait les moyens de les stocker sans qu’elles s’abîment et de retrouver aisément celles dont on avait besoin : à ce dernier effet, on pouvait intercaler des fiches subdivisionnaires ou bien placer des « cavaliers » en tête de groupes de fiches. Des gravures montraient ces différentes pièces de matériel ainsi que les types de fiches qui se vendaient dans le commerce pour des usages personnels ou pour ceux d’une bibliothèque. Les plus simples modèles de ce « matériel classeur » pouvaient d’ailleurs être facilement construits ou improvisés par les « travailleurs », par exemple à partir de boîtes de cigares. Le « système » lui-même n’impliquait qu’un apprentissage minime et il montrait vite ses avantages : « avec un peu d’habitude, on retrouve aisément dans un classement vertical le feuillet qu’on souhaite consulter, on le lit, on le copie même sans le déplacer ». Son utilité ressortait bien plus encore lors de la mise en œuvre des matériaux, quand il fallait « produire ». Une fois le plan tracé, on y reliait les notes. La « technique de détail » était alors la suivante : numéroter toutes les fiches, reprendre les fiches une à une et inscrire le numéro de chacune à l’endroit voulu sur le plan. Au terme de cette opération, « le plan est non seulement un répertoire des idées principales, mais aussi un guide de l’emploi de tous les documents » : ainsi était évité le double risque d’être submergé par les documents et d’en omettre. Le travailleur « n’avait plus d’autre souci que de rédiger son travail27 ». Publié en 1918, l’ouvrage de Chavigny en était l’année suivante à sa quatrième édition ; trois autres éditions parurent en 1920, 1925 et 1928 ; une refonte fut faite en 1933, avec une nouvelle édition en 1939.

L’ouvrage de Jean Guitton sur le travail intellectuel paru en 1951 donne de façon brève des éléments désormais courants sur les fiches et leurs avantages. Il n’apporte guère de nouveau, si ce n’est la suggestion d’avoir sur soi « un petit carnet de fiches mobiles aux dimensions établies selon le format choisi pour toute l’existence » : ainsi pourrait-on saisir et noter une idée venue à l’improviste et intégrer ensuite la fiche à sa place dans le fichier sans avoir à recopier28.

Le système des fiches ne demeura pas une pure idée. Des masses de fiches ont été produites pendant la première moitié du XXe siècle et jusque dans les années 1980 pour le moins. Marc Bloch évoque ce procédé quand, dans Apologie pour l’histoire, il écrit à propos des communautés de tisserands comme terrains d’hérésies entre les XIIe et XVIe siècles : « Voilà assurément une belle matière pour une fiche d’histoire religieuse. Rangeons donc soigneusement ce bout de carton dans son tiroir. Dans les casiers voisins étiquetés, cette fois, “histoire économique”, précipitons une seconde moisson de notes29. » Lucien Febvre a laissé de gros fichiers « très hétéroclites [rassemblant] à la fois des notes prises sur des ouvrages, des références bibliographiques ou des citations, des commentaires ou des idées lancées sur des bouts de papier de toutes tailles (souvent au verso d’autres documents)30 ». Les archives de Fernand Braudel comprennent pour La Méditerranée des milliers de fiches bristol de format 10 × 15 cm rédigées, dans la quasi-totalité, par lui-même ; de couleur généralement blanche, elles ont été utilisées dans le sens de la hauteur. Lors des premiers dépouillements effectués dans les archives espagnoles (1928), l’historien avait procédé autrement, prenant les notes sur « des supports différents (papier de cahier, de bloc-notes, etc.) et [dans] des formats également différents », les collant ensuite « sur du papier bristol d’épaisseur moyenne et de format 10 cm × 15 cm ». Des signes, par exemple, un petit rectangle rayé ou une sorte de triangle, fonctionnaient comme une indexation matière. Le fichier mêle, du moins dans le classement actuel, des fiches rédigées à partir de dépouillements dans les archives et des lectures d’ouvrages imprimés31. Robert Mandrou commença son fichier au début des années 1950, au plus tard lors du choix de son sujet de thèse (1953) ; il l’organisa de façon thématique et l’alimenta tout au long de sa vie active ; il en reste 15 boîtes fabriquées par lui et contenant chacune entre 1 300 et 1 500 fiches32. Pierre Goubert a fait état des « dizaines de milliers de fiches collectées pour des travaux de démographie historique et qu’il n’a pas eu le temps de mettre en œuvre33 ». Il se rappelait avoir vu chez Denis Richet « de longues boîtes garnies de fiches, couvertes de sa fine écriture, des milliers34 ». Georges Duby, lui aussi, a fait beaucoup de fiches. D’abord pour sa thèse. « Pendant deux, trois ans, je ne sais plus, écrit-il dans son autobiographie, j’accumulai par dizaines de milliers de petits rectangles de papier que j’entassais dans des boîtes. » Les fiches étaient groupées en fichiers thématiques : « un fichier fief, un fichier défrichement, un fichier justice, etc. » Puis, au sortir de sa thèse, quand il reçut la commande de ce qui devint L’Économie rurale et la vie des campagnes dans l’Occident médiéval, il fut amené à « lire, beaucoup lire » et, très concrètement, à « entass[er] les fiches dans de nouveaux fichiers ».

Il fit encore des fiches pour ses cours au Collège de France ; sont conservés à l’IMEC « plusieurs milliers de fiches cartonnées, toujours de la même dimension (10 cm sur 15), parfois numérotées mais jamais datées, et couvertes d’une écriture fine et raturée de biffures et d’accolades. Ces fiches sont écrites tantôt au stylo rouge, tantôt au stylo bleu ou noir et corrigées en rouge35 ». Un « petit paquet de fiches » constituait lors de ses cours « tout son bagage ». Cette pratique étend la gamme des emplois de la fiche dans le monde savant. On peut l’illustrer d’exemples antérieurs. Ferdinand Lot fit ses « conférences » à l’École des hautes études, où il enseigna à partir de 1900, avec « un jeu de fiches », « ne disposant d’autres éléments que ses fiches sur lesquelles se fondait son exposé36 ». Au début des années 1950, René Pintard se servait pour son cours d’agrégation d’« un paquet de petites fiches cartonnées ». L’un de ses agrégatifs a conservé « le souvenir visuel » du « simple et fascinant jeu de fiches. Un seul tas au départ, mais qui aussitôt se dédoublait et, à mesure que l’analyse avançait, on voyait diminuer le tas de gauche et se hausser le tas de droite, jusqu’à l’unicité retrouvée ». Alors, le cours était terminé37.

Cet usage de la fiche comme support de cours souligne encore la diversification d’un outil, largement employé, et pas seulement en histoire. Chavigny s’adressait à tous les travailleurs, le nom de René Pintard renvoie à la littérature, et il est des savants relevant d’autres disciplines qui firent dans leurs recherches un large usage de la fiche. Marcel Mauss, Henri Hubert, Robert Hertz pratiquèrent largement « le système de travail par fiches » dont Hertz faisait en 1905 l’apologie : « pratique, rapide et méthodique », il entrait dans le processus du travail intellectuel et permettait, avec un bon répertoire bibliographique et la critique des textes, de venir à bout « de la masse d’abord effroyable des faits ». Hubert laissa à sa mort (1927) plus de 25 000 fiches. Marcel Mauss qui pratiqua la mise en fiches depuis ses premières études alimenta sa vie durant un « grand meuble métallique38 ». Les recherches que Mauss et Hubert menèrent conjointement au début de leur carrière sur le sacrifice et la magie passèrent par une importante production de fiches – la fiche donnant d’ailleurs la mesure de l’activité. Alors qu’il dépouillait des textes sacrés, Mauss écrivait à son ami en 1898 : « Mon travail traîne et avance. C’est du “deux fiches par jour”. Les documents ethnographiques vous donnent une autre moisson39. » À la génération suivante, les ethnologues qui allèrent sur le terrain recoururent aussi à la fiche, à côté de feuilles, de classeurs, de carnets et de cahiers. Les gros fichiers laissés par Marcel Griaule montrent un usage intensif de ce support dans ses multiples variantes matérielles selon que le travail était personnel ou collectif40. Michel Foucault travailla, par fiches, des feuilles A 4 pliées ou découpées en deux, par exemple, pour L’Histoire de la folie ou pour Les Mots et les choses. Les 856 fiches préparatoires du second ouvrage sont de trois sortes : fiches de prise de notes, fiches bibliographiques qui portent pour un sujet la liste des lectures à faire, fiches thématiques, plus rares, qui réunissent sous un sujet diverses lectures. Les fiches de prise de notes portent en tête à gauche la référence abrégée, mais précise, de l’ouvrage lu, à droite une vedette-matière élaborée par Foucault41.

Ces exemples montrent la large diffusion d’un système au-delà des appartenances disciplinaires ainsi que des orientations méthodologiques, par exemple, chez les historiens. L’Introduction aux études historiques de Langlois et Seignobos est devenu, comme l’a noté Gérard Noiriel, la « bible » de générations d’historiens, définissant un métier avec ses outils et le différenciant des pratiques d’amateurs. Le métier est si bien rentré que les outils de travail et leur maniement sont devenus « naturels » même chez ceux qui avaient répudié « le modèle des pères », tel Lucien Febvre42. Et ces outils, c’étaient entre autres des fiches, tout à la fois découpage et organisation de la matière première historique, avec ce qui est noté et ce qui ne l’est pas, avec un classement même provisoire sous des vedettes-matières même sommaires. En conséquence, l’utilisation des cahiers, blâmée par Langlois et Seignobos, fut considérée comme relevant d’une pratique non professionnelle. C’est ce qui ressort du jugement qu’Édouard Jordan, professeur à l’université de Rennes, porta en 1912 sur Frédéric Ozanam qui avait pris ses notes sur de « gros registres » et n’avait pas « pratiqué la méthode des fiches : c’est un détail de métier qui lui manquait et dont le défaut se fait sentir ». Peu importe que ladite méthode n’existât pas du temps d’Ozanam (1813-1853) : son emploi était désormais un critère du métier d’historien43.

Reste à savoir comment le métier a été acquis, chez les historiens entre autres. On fera l’hypothèse que ce fut moins à la lecture de l’Introduction à l’instar d’un mode d’emploi qu’en recevant des conseils, en entendant parler ou en voyant faire. On peut penser qu’après la première génération qui découvrit « le système des fiches », une discipline, voire une routine, s’est prise, peut-être parce que l’outil bien manié donnait dans l’ensemble satisfaction.

Les fichiers que des historiens ont constitués ont été, avant de finir sur les rayonnages de dépôts d’archives, des organismes vivants et féconds. Il a été noté que Lucien Febvre « modifiait l’arrangement et les classements [de ses fichiers] en fonction de l’évolution de ses projets et des plans qu’il cherchait dans les années 1950-1956 à propos des engagements éditoriaux qu’il avait pris ». Ce qui se voit dans les fichiers qui furent communiqués à Robert Mandrou lorsqu’après la mort de Febvre (1956) il rédigea l’Introduction à la France moderne – un beau livre qui fut aussi une douloureuse affaire. Lucien Febvre avait laissé un travail préparatoire et son fichier atteste d’ébauches de plans : en témoignent « les fiches de séparation qui comportent des numéros de référence et des titres directement liés à ces plans successifs » ; de ces mêmes fiches de séparation ressort aussi le plan d’une partie avec ses différentes subdivisions ; ces sous-parties renvoient à « des dossiers ouverts comprenant ou non des fiches […], les titres choisis comportant très souvent une signification, une question précise, une grille de réflexion, voire de rédaction ». Mandrou, outre son apport personnel, que son propre fichier démontre, est intervenu sur les fichiers qui lui avaient été communiqués : « on trouve fréquemment son écriture sur des fiches de séparation de Lucien Febvre, non seulement les chiffres au crayon rouge indiquant des parties et sous-parties de son plan, mais encore la structuration d’un chapitre44 ». Les fichiers apparaissent ici dans toute leur fonction d’outil de pensée ; ce que l’on eût aimé savoir, c’est comment ils furent concrètement utilisés au moment où Mandrou se mit à l’écriture.

Georges Duby a donné dans son autobiographie bien des éléments permettant d’apprécier l’usage qu’il faisait de ses fichiers pour penser alors qu’il travaillait à sa thèse. Après avoir évoqué les petits rectangles de papier qu’il entassait dans des boîtes, il poursuivait : « J’en sortais de temps en temps quelques-uns que j’étalais sur la table comme pour d’extravagantes réussites attendant que la révélation surgisse de leur rapprochement […] Parfois, […] une bouffée de satisfaction venait me consoler de mes peines : je voyais une vingtaine de pièces éparses s’emboîter les unes dans les autres, et tout d’un coup une sorte de puzzle se recomposer. » Les fiches lui offraient aussi la solution quand « se trouvant devant deux pistes », elles lui fournissaient « autant de raisons, et aussi persuasives, de m’engager sur cette voie-ci plutôt que sur celle-là ». En revanche, il n’a pas manqué de pointer la dictature intellectuelle qu’avait été la méthode du fichier pour le débutant qu’il était, encore sous l’influence des « questionnaires dressés par mes immédiats devanciers […] Parmi les boîtes où, selon les problèmes à traiter, je rangeais mes fiches, certaines se remplissaient, d’autres demeuraient vides. J’aurais dû fermer celles-ci. Je n’osais pas. Je me croyais tenu de les garnir tant bien que mal en y fourrant quelques glanures ». Défaut de jeunesse qui ne remettait pas en cause le système des fiches que Duby a toujours pratiqué. Un exemple de 1982-1983 montre qu’il prenait ses notes toujours sur ce même support : des feuilles demi A4 utilisées en format italien en haut desquelles il plaçait deux mentions, à gauche, une sorte de vedette-matière, à droite une indication numérique (par exemple, A16, A2A, A26) renvoyant à un plan détaillé. La première servait-elle à un classement dans un fichier ? La seconde, explique Patrick Boucheron, renvoyait au plan, « constellation de concepts, avec des mots-clés reliés en arborescence, parfois des locutions latines extraites des sources, ou des qualifications d’historien […], et reliés à la numérotation du plan qui renvoie donc aux fiches des sources45 ». La composition était pour le moins facilitée. On est là dans la droite ligne des principes de Langlois et Seignobos ou des « recettes » de Chavigny.

Des « habitudes matérielles » ont été prises, qui ont été durables dans le monde des historiens. Les fiches-bordereaux imprimées qui ont été utilisées dans les enquêtes collectives des années 1960-1970 les ont, si besoin était, renforcées46. Aujourd’hui, alors que la fiche s’est dématérialisée, des digital natives sont sidérés par des fichiers papier. Telle la réaction de l’un d’eux devant une description, assortie d’une photo, du fichier de ses lectures que le sociologue allemand Niklaus Luhmann tint sa vie durant : « cela me paraît vraiment fou ! Quel travail, et comment s’y retrouver47 ? » Il n’y a là pourtant que des fiches manuscrites portant en haut les indications classiques d’une indexation chiffrée et d’un intitulé thématique. On n’entrera pas dans l’ère nouvelle qui s’est ouverte avec des logiciels de gestion et d’organisation des données. On en restera à ces quelques éléments qui pourraient alimenter une « histoire de la fiche de l’érudit » à laquelle Lucien Febvre avait songé48, quand la fiche fut bien plus qu’un bout de papier, un demi A4 ou un rectangle de bristol : un instrument de collecte des données ainsi qu’un outil de la pensée.





Périodiques, articles, preprints


Les périodiques sont l’un des outils majeurs de la communication scientifique formelle. Depuis 1665 et la création du Journal des savants, ils se sont multipliés, que ce soit sous forme papier, par le passé, électronique, ces dernières années. Les chiffres donnés au chapitre 1 allèguent une croissance exponentielle et une production massive. Toutefois, ils confondent sous une même étiquette des publications diverses apparues au cours du temps. Un inventaire historique permettra de dresser une typologie ; la description se focalisera, dans un second temps, sur l’élément de base qu’est l’article scientifique. Il ne s’agit pas ici de tracer même à grands traits une histoire des périodiques et de leur contenu, mais de souligner, sur la base de quelques exemples, la fécondité qui a été celle d’un genre de publication, un genre qui, s’il a servi la communication des connaissances, n’a pas été sans conditionner leur formalisation.

Dès le premier siècle de son existence, le périodique savant s’est diversifié entre des publications générales, d’une part, et des publications spécialisées, de l’autre. Ainsi, le Journal des savants s’intéressait à « ce qui se passe de nouveau dans la République des Lettres » et recensait des livres de toute l’Europe49 ; d’autres périodiques privilégièrent la production savante d’un pays, tel le Giornale de’ letterati d’Italia (1710 – >) qui se limita à la seule Italie, ou plus fréquemment, s’attachèrent à un sujet, à commencer par la médecine qui domine les publications, critères géographique et thématique pouvant se combiner en de multiples façons. Le succès du genre est rapide et certain comme l’atteste la multiplication des titres, entre XVIIe et XVIIIe siècles. Il ressort aussi de traductions, de réimpressions, voire de contrefaçons dont furent l’objet plusieurs de ces périodiques, dont le Journal des savants. Une autre forme de l’intérêt que le périodique suscita se voit dans des publications, elles aussi périodiques, reprenant des articles publiés dans divers journaux, telle la Bibliothèque choisie de médecine (1748-1770) qui publia dans deux éditions contemporaines in-4° (10 vol.) et in-8° (31 vol.) des extraits traduits en français de périodiques étrangers50.

La spécialisation qui s’était vite dessinée crût avec le temps. Ainsi, au XIXe siècle, apparut dans le domaine des périodiques techniques, une catégorie de revues faites par et pour des ingénieurs et diffusant des connaissances d’une haute technicité. Ces revues, nombreuses, et de plus en plus au fil du siècle, ont des caractéristiques matérielles précises qui renvoient aux demandes et aux usages d’une profession en plein essor, dont un recours croissant au grand format afin de présenter au mieux une illustration à visée opérationnelle. Par ailleurs, l’éclosion dans le second tiers du siècle de revues très spécialisées en conséquence de la seconde révolution industrielle, de nouveaux procédés de construction, d’innovations techniques, etc. s’accompagna d’un mouvement complémentaire de création de revues généralistes répondant aux besoins communs de la profession, celles-ci étant de parution hebdomadaire, celles-là mensuelle51.

L’institutionnalisation des disciplines qui s’opéra dans ces mêmes années et le caractère scientifique qu’elles revendiquèrent amenèrent la création de revues qui prirent à cet effet des configurations intéressantes. D’abord dans la polarisation général-spécial. La Revue historique lancée en 1876 se voulait « générale ». Il devenait « de plus en plus difficile, même pour les savants de profession, de se tenir au courant de toutes les découvertes, de toutes les recherches nouvelles qui se produisent chaque jour dans ce vaste domaine », écrivaient les directeurs dans l’avant-propos. En cela, leur publication se démarquait de « revues spéciales », telles la Revue archéologique ou la Bibliothèque de l’École des chartes qui « cherchent à étudier des points particuliers de l’histoire de l’Antiquité ou du Moyen Âge ». Elle n’en appliquerait pas moins la « même sévérité de méthode et de critique et la même impartialité d’esprit » et n’accueillerait que des « travaux originaux et de première main ». Ni « œuvre de vulgarisation », ni « recueil de pure érudition », elle embrassait, dans une perspective générale, « un point de vue strictement scientifique » que garantissait la liste des cinquante-trois savants de profession parrainant la revue52. Les Annales de géographie fondées en 1892 par Vidal de la Blache offraient dans l’avis au lecteur du premier numéro un panorama de la presse géographique tout en pointant la nouveauté typologique qu’elles présentaient. Le constat de départ était de « la multiplication outrée des périodiques » ; le développement des sociétés de géographie avait été « prodigieux » et chacune avait voulu avoir son bulletin ; mais ces publications étaient dans l’ensemble médiocres et donnaient « sous couleur de géographie, toute autre chose que de la science ». Par ailleurs, il n’existait pas en France d’organe autorisé à l’instar des Mittheilungen de Petterman pour l’Allemagne et des Proceedings de la Royal Geographical Society pour l’Angleterre. Un travail de veille, pourrait-on dire, était accompli par le bulletin de la Société de géographie qualifié d’excellent. Ce qui manquait, c’était un type de publication « intermédiaire » qui « suive systématiquement le progrès des sciences géographiques », qui « classe » les résultats nouveaux, les rattache « logiquement à tout un passé de recherches et de travaux analogues », qui enfin « acclimate » à la géographie des renseignements utiles épars dans « des recueils spéciaux » de géologie, de météorologie, d’histoire naturelle, etc. « Discipline » et « méthode » étaient les mots d’ordre de la nouvelle publication qui devait satisfaire « les obligations du métier de géographe ». D’où le titre générique choisi : Annales pour marquer la différence avec un bulletin ou une revue « au sens le plus strict du mot, puisque le dessein des fondateurs n’est pas seulement de résumer, de faire part, de tenir au courant, mais de raisonner, de lier, d’interpréter ». D’où aussi le découpage : une première partie consacrée à l’étude des questions géographiques avec deux ou trois articles de fond ; une deuxième partie, « la plus étendue et la plus importante », qui contiendra des comptes rendus critiques et bibliographiques ; une troisième partie, « restreinte », pour la correspondance, les études régionales, des articles d’information plutôt que de recherche. À la fin de chaque année, serait présenté « un tableau résumé du progrès des connaissances géographiques ». L’avis au lecteur se terminait sur l’affirmation du « caractère scientifique » des Annales, du souci de « réforme méthodique » qui les portait et, en conséquence, de leur distinction d’avec « la plupart des revues » qui n’offraient que des récits d’explorations et de découvertes53.

Un panorama encore plus diversifié, et pour cause, ressort de l’étude que Robert Boure a consacrée aux revues françaises en sciences humaines et sociales à la fin des années 198054. La revue scientifique trouve son identité par contraste avec le magazine scientifique. Son comité de rédaction et ses auteurs ne sont pas des journalistes mais des chercheurs professionnels, ce qui n’est pas sans incidence sur les techniques rédactionnelles (articles longs ; appareillage technique important : notes, bibliographies, tableaux ; style). La revue scientifique en sciences humaines et sociales présente un profil paratextuel caractéristique qu’une publication « alternative », les Actes de la recherche en sciences sociales, fait particulièrement ressortir. Se proposant une conception de la science sociale autre, elle se donna un « mode d’expression » différent. « On trouvera ici côte à côte, écrivait Pierre Bourdieu dans la présentation du premier numéro, des textes qui diffèrent très profondément dans leur style et leurs fonctions : textes “achevés”, bien sûr, tels que les appellent les revues académiques, mais aussi notes brèves, comptes-rendus d’exposés oraux, textes de travail, tels que projets et mémoires intermédiaires de recherche, où se voient mieux les intentions théoriques, les procédures empiriques de vérification et les données sur lesquelles s’appuie l’analyse. La volonté de donner l’accès à l’atelier lui-même, qui ne connaît d’autres règles que celles de la méthode, et de livrer les archives d’un travail en train de se faire implique l’abandon des formalismes les plus évidemment rituels : alignement à droite de la typographie, rhétorique du discours suivi, articles et numéros de longueur uniforme, et, plus généralement, tout ce qui conduit à la standardisation et à la “normalisation” des produits de la recherche55. »

De l’étude de R. Boure sur les revues françaises en sciences humaines et sociales, il ressort qu’elles sont non seulement nombreuses – quelque 700 titres (estimation basse) – mais aussi extrêmement diverses lorsqu’on les classe suivant les critères du contenu, de la discipline, de l’espace, de l’autorité : il en est ainsi toute une gamme, de la revue locale à la revue internationale, de la revue mono-disciplinaire à la revue inter- ou pluridisciplinaire, etc. Ce dernier cas de figure, pour en rester à lui, ouvre sur « plusieurs types de revues » : « revues approchant les objets de façon transversale ou à travers la confrontation de disciplines » ; « revues cherchant à intégrer à plusieurs disciplines une théorie, une approche […] ou une thématique » ; « revues cherchant […] à faire passer certaines préoccupations d’une discipline dans d’autres » ; « revues à perspective ouvertement anthropologique » ; « revues d’interdisciplines ». La diversité s’augmente, naturellement, lorsque l’on croise les critères.

Avec l’électronique, les revues ont acquis un nouveau support. À l’heure actuelle, il est des revues papier, des revues paraissant sous la double présentation papier et électronique et des revues uniquement électroniques, qu’elles soient nées telles ou qu’elles le soient devenues. L’open access publishing, qui débute en 2000 avec le lancement de PubMedCentral par la National Library of Medicine, a amené un nouveau produit, un e-journal purement électronique sans contrepartie imprimée et reposant sur un nouveau modèle économique : l’auteur ou son institution paie pour la publication de l’article dans le journal ; les articles publiés sont libres d’accès à tous. Ces journaux peuvent inclure des contenus à valeur ajoutée (comptes rendus, articles de commentaire, images, bases de données, etc.) dont l’accès est soumis à un payement. Un développement supplémentaire dans l’open access publishing a été constitué par la création de la Public Library of Science (PLOS), organisation à but non lucratif, qui a lancé un premier journal en biologie (2003), vite suivi de plusieurs autres. L’open access publishing est une tentative pour ôter à l’édition commerciale le contrôle sur la communication scientifique et pour le rendre aux chercheurs. Il n’est en rien une remise en cause de l’évaluation par les pairs ni une transformation de l’article56.

Les périodiques savants contiennent de multiples rubriques dans des agencements divers : articles, qui peuvent se diviser en plusieurs catégories (article de tête ouvrant un numéro thématique, article de fond, varia, etc.), comptes rendus et notes de lecture, informations scientifiques, listes de livres reçus, etc. Certains de ces éléments structurels existaient dès les premiers temps du journalisme scientifique. Toutefois, celui qui est aujourd’hui majeur – l’article – ne s’est développé que vers la fin du XIXe siècle. Auparavant, les revues publiaient des contributions brèves – mention d’un résultat, compte rendu d’observations faites et publiées ailleurs – ou très longues, proches d’une monographie. Les formes étaient celles d’une lettre ou d’un rapport purement descriptif présentant les résultats en ordre chronologique. La forme lettre a été abandonnée alors que le rapport se structurait : les méthodes et les résultats commencèrent à être décrits et interprétés. Progressivement, apparut dans la seconde moitié du XIXe siècle une organisation générale interne : théorie, expérience, discussion. Début XXe siècle, les normes actuelles commencèrent à être standardisées et, au cours du siècle, le format IMRAD (Introduction, Methods, Results and Discussion) adopté. Dans le domaine de la médecine, jusque dans les années 1945 les articles étaient organisés comme un chapitre de livre. Le format IMRAD y apparut en 1950-1960, commença à prédominer après 1965 et s’imposa exclusivement après 1980. Dans ce processus ont joué des recommandations lors de colloques disciplinaires et professionnels, et encore plus les instructions des éditeurs. En physique, le format IMRAD aurait été introduit plus tôt et il aurait été adopté de façon extensive dans les années 1950. Il a progressivement gagné des sciences autres que les sciences de la vie et de la matière, la psychologie, les sciences de l’éducation, les sciences cognitives, etc. Au fil du temps, il s’est aussi imposé dans les thèses relevant de toutes ces disciplines et dans cette forme quantitativement majeure de la communication orale qu’est le poster.

L’article scientifique, tout particulièrement, dans les sciences de la vie et de la matière, n’est pas seulement formaté dans son économie générale. Des instructions très précises sont données par les éditeurs, réglant toutes ses composantes : titre, présentation des auteurs, résumé (passé en tête de l’article et composé suivant le format IMRAD), mots-clefs, bibliographie, crédits57.

Ces règles supposent un apprentissage qui se fait par le mimétisme, par des cours spécifiques ou par la lecture de guides, manuels et autres instructions imprimées ou en ligne. L’article scientifique a ainsi pu être caractérisé comme un genre universitaire ou, plus exactement, comme désignant une « famille de genres » avec, à côté de l’article de recherche sur lequel portent les lignes qui précèdent, les rapports, études de cas, articles de revue de la littérature, méta-analyses qui, à leur tour, constituent des sous-genres avec leurs normes spécifiques58. Les recherches n’ont guère porté sur les sciences humaines et sociales où les articles sont plus réglés qu’il n’y paraît, comme il ressort de la simple comparaison entre articles de revues scientifiques, de magazines scientifiques et de revues d’idées59.

La numérisation a eu une incidence considérable dans la presse scientifique qui est maintenant très majoritairement en ligne (avec ou sans publication papier). Elle a fortement modifié la chaîne de l’information en termes de diffusion des articles et de leur accessibilité. Par contre, son impact a été limité sur l’unité même de communication, l’article, qui, dans son format, est quasiment inchangé, demeurant apparemment, du moins, « une copie numérique de la forme imprimée ». On mesure à ce point la différence entre un processus de communication – le numérique – et un genre – l’article scientifique. Celui-ci est devenu un instrument qui, par l’adoption d’un format (IMRAD) et aussi d’une procédure (le peer review ou évaluation par les pairs), a contribué à la construction d’une science objective. Les possibilités de customisation offertes par la numérisation pourraient porter vers de l’informalité et de la subjectivité. D’où une réticence à les employer, du moins tant qu’un format numérique ne crée une solution qui, en termes de certification et d’objectivité, soit recevable par la communauté, une solution qui, dans l’économie du travail scientifique, soit aussi efficace que le format IMRAD60.

La numérisation a entraîné une « indépendance » de l’article qui n’est pas sans conséquences. La revue perd de son rôle de vecteur des connaissances, et la mise en contexte idéologique ou thématique qu’elle opérait disparaît. Elle fonctionne alors uniquement comme une marque de légitimation et un indicateur de notoriété et d’évaluation.

Le libre accès et les archives ouvertes vont dans ce sens. Tout a commencé dans les années 1950, donc bien avant le numérique, et dans le domaine de la physique théorique. Les chercheurs échangeaient leurs preprints ou prépublications, c’est-à-dire les manuscrits de leurs articles, tels que soumis pour publication, et ce afin d’éviter le long délai entre soumission et parution. Les laboratoires géraient la diffusion de ces photocopies qui étaient « le véritable instrument de la communication scientifique ». Les choses prirent un tout autre tour avec la création à Los Alamos en 1991 par Paul Ginsparg d’un système commun de gestion des preprints, en mettant alors à profit le courrier électronique. L’initiative, d’abord limitée à un secteur disciplinaire et ne gérant que des résumés, eut un succès immédiat. Les progrès technologiques ont favorisé son développement, et très vite xxx.lang.gov a pu envoyer les textes mêmes. La couverture s’est élargie et, cinq ans après les débuts, elle s’étendait à 25 sous-disciplines. La success story d’arXiv (le nouveau nom à partir de 1998) s’est poursuivie en dépit de craintes (notamment dans les débuts, concentration de l’information en un point, pas d’évaluation par les pairs, surinformation et, en retour, hyperspécialisation) et de critiques de divers ordres ; elle a incarné l’idéal du libre accès des chercheurs aux résultats de la recherche et l’opposition au quasi-monopole des éditeurs et à la cherté des revues. Dès la fin des années 1990, cette archive était devenue un instrument de travail fondamental pour les physiciens au point que le numéro de dépôt sur arXiv était la référence de l’article. Aujourd’hui, arXiv, qui est hébergée à Cornell, accueille des preprints de plusieurs domaines – physique, mathématiques, astronomie, informatique, biologie quantitative, statistique ; leur nombre dépassait les 900 000 fin 2013. Des initiatives analogues se sont développées dans d’autres domaines, avec l’archivage d’articles publiés et non, ou des seules prépublications61.

Avec le numérique, l’article, voire l’un de ses éléments, est devenu l’unité d’information et de recherche. Cet article n’est pas seulement une publication dans une revue (papier ou en ligne, peu importe), il peut être aussi une prépublication qui d’ailleurs a tous les caractères formels du produit fini. Les chercheurs ont désormais à leur disposition un nouvel instrument de travail qui a été mis au point par eux en réponse aux demandes internes de la communauté en termes de communication de l’information. L’utilisation en est variable suivant les disciplines et les personnes. On verra dans l’article en prépublication une ultime preuve des multiples possibilités du périodique se déclinant à l’infini. Ou une marque supplémentaire de l’inventivité humaine adaptant, pliant un outil aux nécessités des usagers. Ou encore les deux.





Graphiques et arbres


« Les graphiques sont devenus un instrument si usuel de présentation et d’analyse des données que l’on ne peut guère concevoir de science se faisant sans eux ; c’est pourtant sans eux que s’est produite la Révolution scientifique du XVIIe siècle », a remarqué Thomas Hankins dans un essai sur le sujet62. L’histoire des graphiques qui s’ouvre au XVIIIe siècle les a vus se multiplier et « envahir » les publications : 25 % du contenu des dix revues scientifiques les plus citées dans les années 1951-2000 est constitué de graphiques, de schémas et de tableaux63. Ce pourcentage serait probablement plus élevé aujourd’hui alors que des logiciels permettent de tracer les formes les plus sophistiquées avec une facilité déconcertante. Les graphiques ont pénétré tous les ordres du savoir, même ceux qu’on ne leur associe pas le plus spontanément, par exemple, les études littéraires où les publications des digital humanists sont riches de représentations visuelles, linéaires, réticulaires ou arborescentes64. Au cours du temps, les graphiques se sont grandement diversifiés engendrant une nombreuse famille d’outils de travail permettant la visualisation des données scientifiques. Des situations concrètes le montreront ; elles feront aussi ressortir leur fonction cognitive, quand, à leur meilleur, ils sont des instruments de la pensée.

L’histoire de la visualisation des données, telle que Michael Friendly et Daniel J. Denis l’ont retracée, révèle une production nombreuse de cartes, de tables, de diagrammes, de graphiques ainsi que leur considérable variété. Elle se découpe en plusieurs époques, s’inaugurant véritablement pour les graphiques au XVIIIe siècle avec notamment les réalisations de William Playfair (1759-1823) qui inventa la plupart des formes utilisées aujourd’hui : graphique linéaire, graphique en barres (1786), graphique sectoriel, graphique circulaire (1801). Les années 1800-1850 virent une très forte croissance des graphiques statistiques comme d’ailleurs des cartes thématiques, préparant l’âge d’or que fut la période 1850-1900. Le demi-siècle suivant offre un fort contraste ; il n’y a que peu d’innovations graphiques et, à partir des années 1930, l’enthousiasme pour la visualisation baissa au profit de la quantification et de modèles formels dans les sciences sociales ; dans ces mêmes années, toutefois, les graphiques statistiques deviennent d’un emploi courant. La visualisation des données connut une renaissance dans les années 1950-1970 sous l’incidence de trois facteurs : l’invention aux États-Unis par le statisticien John Tuckey (1915-2000) d’une grande variété de méthodes d’analyse et de présentation des données ; la méthode graphique de Jacques Bertin appliquée à la visualisation de relations d’ensemble ; les débuts de l’informatique. Avec l’ordinateur, une ère nouvelle s’est ouverte. Des avancées technologiques ont fourni des outils de visualisation des données, inconcevables ne serait-ce qu’il y a cinquante ans. Aujourd’hui des logiciels font une banalité de la traduction de très grands volumes de données en courbes et en surfaces en 3D qui peuvent se zoomer, se déformer et tourner dans tous les sens65.

Les graphiques ne se sont pas imposés sans opposition aucune même dans leur âge d’or du XIXe siècle. Des statisticiens leur dénièrent toute rigueur, leur reconnaissant au mieux une valeur pédagogique. À l’opposé, il est vrai, des savants, tel Marey en firent un emploi enthousiaste. Sa vie durant, il inventa ou perfectionna une série d’appareils afin d’enregistrer toutes sortes de mouvements jusqu’aux plus rapides et aux plus faibles. La méthode graphique, suivant le titre qu’il donna en 1878 à l’ouvrage où il exposait ce qui était à la fois un mode d’expression et un moyen de recherche, était présentée comme « le langage des phénomènes eux-mêmes66 ».

On s’arrêta à une représentation qui a eu un grand succès dans la visualisation de données quantitatives ou qualitatives : l’arbre, qu’il soit figuré au vrai ou schématique. Giulio Barsanti a montré comment dans le monde des naturalistes l’arbre remplaça au XIXe siècle la carte qui, elle, avait supplanté l’échelle. Il a retracé les discours métaphoriques qui, dans la seconde moitié du XVIIIe siècle, précédèrent les représentations graphiques ; il a montré comment le fait que l’arbre se prête à des lectures diverses et permette d’en tirer des informations de nature, elle aussi, diverse fut certainement la cause de son succès ; il a reconstitué l’histoire de ces multiples arbres qui furent produits entre l’arbre botanique qu’Augustin Augier publia dans son Essai d’une nouvelle classification des végétaux (1801) et le célèbre diagram que Charles Darwin plaça au chapitre IV de On the Origin of Species (1859), quand il s’imposa comme une figure particulièrement efficace pour suggérer et traduire visuellement la théorie de l’évolution67. Ernst Haeckel (1834-1919) fit un grand emploi de cette forme graphique pour présenter ses idées quant à l’évolution des espèces jusqu’à la généalogie de l’homme, le Stammbaum des Menschen (1874).

À ce point, il convient de rappeler que l’arbre était une image qui avait cours depuis des siècles en Occident. Les médiévaux l’avaient largement employée pour représenter les degrés de parenté et les divisions du savoir. Le XVIe siècle vit une prolifération d’arbres pour traduire des réalités autres, sociales, politiques ou religieuses, tels l’Arbre des estats et offices de France de Charles Figon (1579), l’Arbre des hérétiques d’Artus Désiré (1550), la Hierachia ecclesiastica de Diego de Valadés (1579). Pendant les XVIe-XVIIIe siècles, on dressa de très nombreux arbres généalogiques des nations, des princes, des nobles, des ordres religieux, etc.68.

Cela rend moins surprenant les multiples usages de cette figure qui furent faits par les savants sans qu’il y eût un lien avec la théorie de l’évolution et dans des domaines autres que les sciences de la nature. On observera, pour en rester d’abord au monde des naturalistes, que des cartes, suivant la typologie de Barsanti, ont, pour le moins, des allures d’arbres, telle la planche intitulée « généalogie des fraisiers » qu’Antoine-Nicolas Duchesne plaça dans son Histoire naturelle des fraisiers (1766). Cet auteur se référait à l’ordre généalogique, « le seul que la nature indique », pour présenter ses conjectures selon lesquelles les variétés de ce fruit étaient les modifications d’un même type ; pour les faire « mieux saisir », il avait fait faire cette gravure qui montrait « à la tête de l’arbre », le fraisier des mois considéré « comme le père de tous69 ». L’image de l’arbre servait aussi à donner d’une classification une image aisément mémorisable. En 1712, le médecin de Modène Francesco Torti plaçait dans sa Therapeutice specialis ad febres quasdam perniciosas, où il prônait la quinine dans le traitement des fièvres, une gravure figurant un arbre des fièvres. Du tronc qui désignait les fièvres, partaient deux branches maîtresses, à droite pour les fièvres simples, à gauche pour les fièvres putrides. Les nombreux rameaux indiquaient les fièvres alors connues. Ceux de gauche, au beau feuillage, indiquaient les fièvres qui pouvaient être soignées avec la quinine, ceux du centre, moins feuillus, les fièvres parfois guérissables avec ce remède, ceux de droite, tout secs, les fièvres réfractaires à cette thérapie. Cet arbre était présenté comme « une aide mnémonique » à l’intention des apprentis médecins70. Cet ouvrage eut un réel succès avec plusieurs éditions (1732, 1743, 1755, 1769) jusqu’en 1821. Il fut une source d’inspiration pour Jean-Louis Alibert, médecin chef à l’hôpital Saint-Louis de Paris. « Torti a élevé l’arbre des fièvres ; je cherche à élever celui des dermatoses », déclarait-il dans son ouvrage sur le sujet où il plaça une gravure présentant un arbre au vrai sans feuillage : le tronc figurait le derme, les branches principales les diverses maladies qui lui sont particulières, les rameaux indiquaient les genres, les ramifications les espèces et les variétés. Si une intention pédagogique sous-tendait la présentation imagée, un propos autre était à l’œuvre. Alibert caractérisait les dermatoses comme « une famille de maladies », « une famille nombreuse de maladies », qu’il classait selon « la méthode des botanistes » ; l’arbre des dermatoses était défini par lui comme « un arbre généalogique qui nous offrira en un ordre régulier les groupes, les genres et les espèces de la famille des dermatoses71 ». Ainsi, une représentation usuelle servait de support à une classification scientifique inspirée de Linné et de Jussieu.

L’arbre a aussi connu un beau succès dans les sciences humaines, dans la linguistique et la philologie textuelle. Dès avant le XIXe siècle, les grammairiens ont noté des changements linguistiques et ils les ont interprétés suivant certains présupposés et finalités. Il est ainsi des travaux traitant des parentés, des similarités entre les langues et des essais d’explications sur l’évolution des langues. Ce que l’arbre permet de traduire visuellement. Le premier à avoir été dressé date de 1800 environ et il est dû à un certain Félix Gallet. Peu importe pour nous que cet Arbre généalogique des langues mortes et vivantes, un bel arbre au vrai avec un élégant feuillage, fût linguistiquement pauvre (avec 60 langues seulement), qu’il traduisît un état obsolète des recherches, qu’il ne distinguât pas entre les familles de langues. D’une autre nature scientifique sont les arbres que tracèrent, cinquante ans plus tard, František Čelakovsk pour les langues slaves et August Schleicher pour les langues indo-européennes. Le Stammbaum que Schleicher publia en 1853 reposait sur une théorie qui l’avait amené à considérer les langues comme des organismes naturels avec des périodes de développement, de maturité et de déclin72.

Le graphique-arbre est entré dans la philologie textuelle où on le désigne sous le nom de stemma. Le premier n’a pas été tracé par un philologue allemand, comme Sebastiano Timpanaro l’avait écrit, mais par un savant suédois, Carl Johann Schlyter qui avait été officiellement chargé de l’édition des lois du royaume de Suède au Moyen Âge. Dans le volume relatif aux lois de la province de Västergötland (1827), il indiquait avoir dressé « une sorte d’arbre généalogique » afin de « bien marquer les relations entre les manuscrits ». Il ne devance, il est vrai, Carl Gottlob Zumpt et Friedrich Ritschel que de peu, de quatre et cinq ans. Toutefois, alors que les deux savants allemands groupaient des manuscrits sous des lettres signifiant leur qualité (d’excellent à très mauvais), Schlyter donnait un « schéma de parenté des manuscrits » (schema cognationis codicum manuscriptorum) d’ordre historique et génétique : les dix manuscrits considérés (A, B, C, etc.) étaient représentés dans leur filiation en un schéma vertical sur plus de trois siècles (avec des lignes-repères tous les vingt-cinq ans). On conservera néanmoins à Zumpt la paternité de stemma, le mot qui a prévalu en philologie pour désigner ce graphique présentant la tradition manuscrite73. Assez rapidement, faire le stemma devint une pratique courante des éditeurs de textes anciens et médiévaux.

L’emploi de cette figure à succès qu’était l’arbre connut au tournant du XIXe siècle un fléchissement. Les biologistes se concentrèrent davantage sur des problèmes de fonction organique et ils se détournèrent de l’idéal d’une explication historique au profit des promesses qu’offrait la recherche expérimentale de processus vitaux. Ce changement d’intérêt ne fut pas général, mais il fut large, et pendant une bonne partie du siècle on dénigra les approches historiques que l’on considéra comme spéculatives. Ce n’est qu’au cours des années 1970, avec la diffusion de la cladistique74, que la reconstruction phylogénétique reprit de l’importance et que se multiplièrent ces nouveaux arbres que sont les cladogrammes. Une évolution parallèle se note dans les études linguistiques et philologiques. Dans les années 1900, les linguistes se détournèrent des études diachroniques sur le temps long, de l’histoire des langues, et ils se mirent à des travaux d’ordre synchronique ou structural, les jugeant plus scientifiques. Dans ce nouvel agenda, l’arbre n’avait plus de place. Le stemma des philologues a aussi subi des remises en cause sous l’effet de divers facteurs, à commencer par la nature même de traditions manuscrites parfois si étendues et si contaminées, notamment pour des textes bibliques et classiques, qu’il était vain d’essayer de reconstruire d’authentiques stemmas. Jouèrent aussi des changements dans les principes des méthodes d’édition, des différences nationales et l’évolution de la discipline, avec la nouvelle philologie des années 1985-1990 qui, donnant le rôle primordial au manuscrit, proclamait que tous les états ont leur intérêt. Toutefois, la contestation ne fut pas radicale comme il ressort des stemmas que l’on peut voir dans les liminaires de bien des éditions critiques tout au long du XXe siècle. Les travaux les plus contemporains donnent à voir des arbres assez impressionnants. C’est que les philologues ont trouvé dans l’ordinateur un outil particulièrement utile dans le cas de traditions très riches ou hautement contaminées ; par ailleurs, la stemmatologie a mis à profit les ressources de la cladistique. Reste que le stemma est présenté non comme un « schéma prescriptif faisant autorité », mais comme un simple « outil-guide, néanmoins nécessaire à l’éditeur pour justifier ses décisions75 ».

Au fil de ces exemples ressort la polyvalence d’une figure qui peut être une mnémonique, un instrument de classement, une mise en ordre et en évidence suivant une théorie, un outil d’aide au raisonnement et à la décision, ou tout cela à la fois. Ce qui vaut pour l’arbre peut être étendu aux graphiques en général, permettant de visualiser des relations entre des éléments divers, de voir dans une masse de données des régularités et des anomalies, de procéder à des simulations. Leur pleine force d’outil ressort de l’impact que leur emploi eut dans certaines disciplines. Ainsi, la physiologie fut profondément transformée par l’emploi de ces instruments enregistreurs que sont le kymographion de Carl Ludwig (1816-1895) et le sphygmograph de Karl von Vierordt (1818-1884) perfectionné par Marey : d’une activité d’abord descriptive et fondée sur la vivisection et l’anatomie, elle devint une science expérimentale quantitative et fit du graphe l’objet de l’étude76.

Les graphiques ont ainsi constitué un outil aux mains des chercheurs. Ici comme ailleurs, le maniement supposait un apprentissage et le respect de règles et de conventions. La confection de graphiques n’a jamais été aisée, hier comme aujourd’hui77. Sans remonter aux époques du dessin à la plume et de l’enregistrement au noir de fumée, on rappellera que la graphique de Bertin impliquait un sérieux apprentissage tout comme l’impose la confection d’un stemma ou d’un cladogramme, et que, de nos jours, l’utilisation, pour en rester à elle, de logiciels de graphiques ne va pas sans une formation, plus ou moins poussée, comme il ressort des tutoriels les accompagnant. Par ailleurs, face aux multiples variétés de graphiques qui existent aujourd’hui, il importe que l’usager en sache un peu sur chaque type afin de déterminer le plus pertinent pour son propos.

Une dimension « pédagogique » est au cœur d’une série d’ouvrages fascinants qu’Edward Tufte a publiés sur la visualisation des données, sur la théorie et la pratique des cartes, graphiques et diagrammes78. Cet auteur, un ancien professeur de sciences politiques et de statistiques à Yale qui s’est spécialisé dans la communication visuelle de l’information scientifique, notamment quantitative, donne des conseils pratiques en la matière. Mobilisant tout à la fois une expérience personnelle et une approche historique qui le porte à examiner de façon critique des représentations graphiques qui ont été produites depuis le XVIIe siècle, il formule un certain nombre de principes simples. Le graphique est un « instrument » qui suppose la maîtrise d’une littératie visuelle (visual literacy). Celle-ci, qui fait souvent défaut chez les lecteurs, permet les manipulations de tous ordres qu’opèrent des graphiques dépourvus d’intégrité (volontairement ou non). La compétence graphique manque tout autant chez bien des auteurs et elle se traduit par une « médiocrité graphique » dont Tufte donne de multiples exemples, tels l’emploi de formes graphiques impertinentes ou, dans des graphiques en réseaux, des traits non orientés reliant des noms ou des concepts, sans compter des graphiques puzzles nécessitant la lecture d’un texte pour y voir clair. L’ordinateur en facilitant le travail a aussi suscité une « inflation de graphiques » et, avec elle, de ce que Tufte appelle le chartjunk, pauvrement traduit en français par « bruit graphique », désignant tous les éléments visuels qui ne sont pas porteurs de sens et qui oblitèrent ou déforment la compréhension. Ce qui est doublement fâcheux en ce que, d’une part, un graphique médiocre au lieu de faciliter la communication du savoir la brouille, d’autre part, en considérant la force persuasive qui s’attache aux images, crée une fausse impression qui peut être durable. D’où des règles et des principes pour que le graphique fonctionne à son meilleur, traduisant sous une forme minime la masse des données, mettant en évidence de façon simple des réalités complexes et parfois cachées.



*

* *

Les quatre objets ici étudiés apportent deux grands enseignements. D’une part, le nombre de leurs actualisations au fil du temps ratifie, si besoin était, l’une des conclusions du chapitre précédent ; il montre la formidable extension des catégories technologiques auxquelles séminaire, fiche, périodique, graphique réfèrent et, avec elle, la grande justesse des « étiquettes » culture orale, culture écrite, culture imprimée, culture de l’image, voire, dans les ultimes occurrences, culture numérique. D’autre part, ces actualisations mêmes donnent lieu à des produits obéissant à des normes, des règles, des conventions. Un processus de « genrification » est ici à l’œuvre qui a pour corollaire chez l’usager une maîtrise desdits genres ou sous-genres passant par un apprentissage, plus ou moins grand, mais toujours réel. Il faut, comme l’écrivaient Langlois et Seignobos, observer des « habitudes matérielles » ou, comme l’énonçait Chavigny, « apprendre la technique pratique de toute production intellectuelle », bref, acquérir le maniement de l’outil. Tout cela ne doit nullement porter à une vision mécaniste qui conclurait des outils utilisés au savoir lui-même. Rien qu’à écrire cela, on mesure ce qu’aurait de simpliste, pour ne pas dire de simplet, un tel déterminisme. Reste que ces outils tout matériels qu’ils sont jouent à plein – et on en a donné bien des exemples – dans les processus de collecte et de transmission de l’information, d’élaboration des données, de formalisation des connaissances. Rien de plus, mais aussi rien de moins.

Un inventaire raisonné montre la part que des produits ordinaires, pour ne pas dire banals, ont, de façon variable selon les moments et les disciplines, dans l’ordre du savoir. Une même conclusion ressortirait de bien d’autres objets. Ainsi, le colloque a suscité depuis la seconde moitié du XIXe siècle une vaste gamme de sous-produits, que l’on considère la dimension des réunions (depuis les grands colloques scientifiques internationaux réunissant plusieurs centaines, voire des milliers de participants jusqu’à des journées d’étude regroupant quelques dizaines de personnes), leur sujet (colloque disciplinaire ou « topique »), les modalités de la parole congressiste (conférence plénière, communication, poster, discussion formelle, interventions d’un président de séance, d’un modérateur, d’un discutant, etc.), sans compter des formes alternatives comme la small conference. Ce monde d’oralité est aussi réglé en de multiples façons qui impliquent le respect de dispositions et la maîtrise d’un savoir-faire afin que la parole soit féconde. Ici encore l’enquête génétique montre comment les usagers ont adapté un outil à leurs besoins, l’ont plié à leurs exigences, en ont corrigé les défauts79. Autre exemple qui, lui, ressortit à l’image : le dessin scientifique. Non seulement, il en est une vaste gamme, du croquis à la reproduction la plus achevée qui soit, mais encore chaque discipline a généré son propre outillage, telle l’archéologie. Des masses de dessins sont faites, et encore de nos jours, dont beaucoup sont des archives de travail qui ne sont jamais publiées ; pour autant, elles entrent dans le processus de recherche. D’où la nécessité pour les archéologues d’un apprentissage, si ce n’est de la technique du dessin, des conventions qui se sont imposées au fil du temps en céramologie, par exemple. Celles-ci constituent, dans une discipline éminemment visuelle, un code partagé qui a pour but d’éviter toute ambiguïté80. On arrêtera là cet inventaire raisonné qui donne suffisamment à voir, je crois, l’énorme outillage que les chercheurs ont inventé en mettant à profit les multiples techniques de l’oralité, de l’écriture, de l’imprimerie, de l’image, du numérique ; encore serait-il incomplet si l’on oubliait « le premier et plus naturel instrument de l’homme81 », l’outil des outils du chercheur : son corps.




CHAPITRE 3


Le corps, outil intellectuel




Le célèbre article de Marcel Mauss sur « les techniques du corps » fut d’abord une conférence présentée à la Société de psychologie le 17 mai 1934. Le texte publié fait d’ailleurs allusion à cette circonstance : « Je n’en finirais plus si je voulais vous montrer tous les faits que nous pourrions énumérer pour faire voir ce concours du corps et des symboles moraux ou intellectuels. Regardons-nous en ce moment nous-mêmes. Tout en nous tous se commande. Je suis conférencier avec vous ; vous le voyez à ma posture assise et à ma voix, et vous m’écoutez assis et en silence. Nous avons un ensemble d’attitudes permises ou non, naturelles ou non. » Cette remarque minime, qui n’a guère attiré l’attention, n’allègue pas moins une éducation du corps qui, dans le monde savant, a été « dressé » à se tenir assis, à parler, à faire silence, à écouter. Elle invite à s’intéresser à cette ressource que les savants apportent avec eux dans leur travail : leur corps, un corps qui doit être éduqué pour produire « un acte efficace », c’est-à-dire pour en rester à une conférence, la construction de l’autorité de l’orateur et la meilleure transmission du savoir qui soit1.

La remarque incidente faite par Mauss amène à penser à ces multiples actes de la vie savante qui, dans leur accomplissement, passent par des postures, des attitudes, des techniques du corps ; on entrevoit déjà un énorme outillage et un outillage parfois très sophistiqué. D’autant que le corps est davantage qu’attitudes, postures et gestes sur lesquels porte la grande majorité des exemples pris par Mauss dans son article. Dans la conférence, il est également, comme la citation le dit, parole et écoute et, comme elle ne le dit pas, regards, voire échanges de regards. Pris dans sa totalité, ce corps offre encore plus de ressources qu’il est parfois appareillé : de façon élémentaire, avec la baguette qui a longtemps prolongé la main du conférencier, de façon bien plus sophistiquée, quand le chercheur utilise un microscope. L’appareillage, quel qu’il soit, ne fait que démultiplier les techniques du corps et, avec elles, les apprentissages, qu’il s’agisse du simple maniement de l’encombrante baguette ou, dans un tout autre registre de difficulté, de la formation à la microscopie avec, au premier chef, une éducation de l’œil.

Des situations de travail prises dans plusieurs disciplines et à plusieurs moments de l’histoire permettront d’objectiver des techniques du corps. Pour autant, il n’est pas question de les documenter toutes : on n’en finirait pas. Il suffit d’établir leur importance quantitative dans les opérations de la production et de la communication du savoir. Ici aussi, « tout se commande ». Le texte de Landolt, qui a été cité en introduction, est éloquent. Portant sur un aspect de l’éducation du chirurgien ophtalmologue, le maniement des instruments, il décrivait et explicitait les multiples gestes à cet effet, autant de gestes qui ne relevaient pas de l’ordinaire. Depuis la pose du corps, du bras et de la main et jusqu’à « une infinité de mouvements combinés et compliqués des doigts », tout était à apprendre. Ainsi, l’opérateur en oculistique devait avoir « les bras libres, écartés du corps, les coudes élevés et arrondis » : le bras formait ainsi levier auquel la main était suspendue. Et Landolt de préciser : « je dis “suspendue” à dessein et non “fixée”. Le secret de la sûreté de la main consiste, en effet, dans sa complète indépendance du bras, qui est possible à un degré beaucoup plus grand qu’on ne se l’imagine. […] On parvient, avec quelque exercice, à tenir la main immobile en l’air, alors qu’on élève et abaisse le coude. Ce mouvement semble absolument impossible à celui qui ne l’a pas exercé simplement parce qu’il n’est pas employé dans la vie usuelle où l’on meut toujours la main avec le bras2. » On a là un exemple, via une leçon universitaire, d’une éducation du bras, de la main. Des exemples divers permettront d’explorer plus avant les modalités d’acquisition des techniques qui font du corps un outil expert. Un focus sera fait sur le corps médical tel qu’il est conformé par une « éducation médicale des sens » que Corvisart distinguait de « l’éducation naturelle et générale3 ». Avec ce mot éducation, on est aux antipodes du registre de l’invisible, de l’incommunicable, du mystère, quand ce n’est pas du génie et du don. Pourtant, les déclarations en ce sens faites par les acteurs ne manquent pas : autant de déclarations qui doivent être intégrées à l’analyse si l’on veut ici, non tant saisir un fait social, que revenir sur l’opposition savoir et savoir-faire et, avec elle, sur le caractère subalterne implicite dans le second terme.





Se servir de son corps


Comment l’homme savant « se sert-il de son corps », pour reprendre l’expression de Marcel Mauss ? D’emblée, cela fait problème pour le passé. L’historien ne dispose pas des ressources que l’ethnologue peut mobiliser : voir et, éventuellement, revoir, écouter et interroger. Il dépend exclusivement de documents, divers, il est vrai : biographiques, prescriptifs, narratifs, iconographiques ou des textes de la pratique. Voir indirectement, à travers la médiation de documents – ab ante ou ex post – ou d’images – qui ne sont pas sans obéir aux lois du genre et à des logiques de représentation –, serait un obstacle majeur pour qui voudrait reconstruire la véracité ou la vérité des gestes. Cela ne l’est pas pour qui vise simplement à rappeler que le monde du savoir est aussi une civilisation du geste4 et, étendant l’agenda aux sens, une culture sensible5. D’ailleurs, à la seule pensée d’une science totalement désincarnée, on touche à l’absurde. Le propos que Mauss tint dans sa conférence passait par une voix qui était, pour ceux qui l’ont entendue, « caverneuse6 ». Le Pr Farabeuf faisait en cours usage de son corps : « je l’ai vu, témoigna un de ses élèves, monter sur la table, s’asseoir en tournant le dos et faire voir le mouvement de la hanche en indiquant le mécanisme. C’était peu digne de la majesté professorale, mais un excellent moyen de fixer le souvenir7. »

Il ne s’agit pas ici de tomber dans un pittoresque de détails : les récits biographiques n’en manquent pas et les textes prescriptifs en offrent à foison, ne serait-ce que dans une pédagogie de l’erreur qui fait voir ce qu’il ne faut pas faire et qui se fait. Bien différemment, on utilisera ces détails, parfois minimes, pour saisir le corps à l’œuvre dans le monde du savoir. Il a donc fallu y prêter attention.

L’approche du monde savant est à forte dominante intellectualiste, privilégiant les idées, les découvertes, les méthodes. On ne sait s’il faut voir là la conséquence d’une formation universitaire qui, apprenant à manier des concepts et à décoder des systèmes de pensée, familiarise avec les textes, voire les promeut, aux dépens des pratiques. Ces dernières années, toutefois, les choses ont quelque peu changé alors que l’on a prêté attention à la science qui se fait. Des sociologues et des ethnologues sont entrés dans les laboratoires ; des historiens des sciences ont recherché dans des publications, des manuscrits, des cahiers de laboratoire la trace des opérations un jour faites, tentant même de répliquer des expériences pour mettre en évidence des savoir-faire. Tout cela a amené à étudier des pratiques et, pour le sujet qui est ici le nôtre, à faire ressortir des gestes8. À ce point, on fera deux remarques. D’une part, les travaux portent principalement sur la science de laboratoire ou sur la mise en œuvre d’instruments. D’autre part, ils explorent essentiellement des gestes, des manipulations, des pratiques manuelles. Otto Sibum fait bien état de l’« ordre sensoriel complexe » (toucher, odorat, goût) du monde des brasseurs auxquels Joule emprunta, mais le gros de son article consacré au savant anglais porte sur le savoir tactile, sur les gestes de la mesure, éventuellement sur l’incidence du regard. Une même focalisation ressort du sous-titre Les mains de l’intellect que Christian Jacob a donné au volume des Lieux de savoir consacré à l’étude des opérations et des pratiques des mondes lettrés : l’introduction générale et les contributions, pour le moins celles référant au monde savant occidental à l’époque moderne et contemporaine, explorent des gestes, des postures, des adresses de la main ; si l’œil apparaît, c’est dans le jeu avec les mains ou dans des signes qui témoignent d’un regard porté sur des réalités.

Si l’on veut véritablement apprécier ce que fut dans l’ordre du savoir « le pouvoir producteur du corps », suivant l’expression d’Otto Sibum, il convient, d’une part, d’élargir la perspective en direction des disciplines relevant des sciences humaines et sociales, d’autre part, de prendre en compte l’outil de production dans sa totalité et non dans ses seules parties même les plus efficientes. On s’en tiendra à quelques situations de travail, d’abord générales en ce sens qu’elles sont communes à plusieurs disciplines, voire à toutes, ensuite, particulières comme se rapportant à un domaine donné.

Le monde savant, dans sa dimension enseignante, fait usage de sa voix, bien sûr, mais il parle aussi de tous les mouvements de son corps, de ses gestes, de ses yeux. C’est ce que disait Michelet du haut de sa chaire du Collège de France le 29 décembre 1842 : « je parle aussi du regard et du geste. » L’avertissement du cours publié de 1847-1848 abondait dans ce sens : « beaucoup de choses, et importantes, sont dites du geste et des yeux. » Un auditeur de 1850 notait : « Les gestes sont multipliés ; ils remplacent souvent les paroles qui ne viennent pas spontanément aux lèvres du savant professeur9. » Des élèves ont laissé des descriptions de professeurs en train d’enseigner ; observant autant qu’ils écoutent, ils ont relevé bien des détails montrant que si le professeur est une voix, il est aussi un regard et des gestes. Tout le corps était à l’œuvre chez Étienne Borne, professeur d’hypokhâgne dans les années 1960. Voici ce qu’écrit un de ses anciens élèves, après avoir tracé un rapide portrait physique : « Nous ne savions pas s’il nous regardait en nous parlant, tellement épais étaient les verres […] D’une voix précise, mais très légèrement hésitante ou bégayante en début de période, il se lançait, comme inspiré […] Inspiré, en effet, non qu’il se prît pour un prophète, mais sa parole accompagnait une respiration ample, qui se faisait entendre quand la syntaxe lui permettait une pause rapide ; ses phrases se modelaient sur son rythme respiratoire, vibrant, chaleureux, vivant, et, si l’expression a un sens, il parlait comme il respirait […] Il parlait toujours debout, loin du tableau, en bas de l’estrade, presque contre les tables du premier rang, sans doute par désir de mieux convaincre. Les fenêtres étaient derrière lui, nous le regardions, à contre-jour, s’agiter. Car il s’agitait […] Sa main droite, la seule mobile, raide comme un tranchoir, découpait l’espace devant lui, un coup en avant, un coup en arrière, comme s’il avait besoin de ce rythme pour avancer sa démonstration. Plus étonnant était le jeu de jambes […] : en début de période, il lançait une jambe en avant, faisait un pas non sans se pencher, puis aussitôt, comme s’il reculait, et tout en continuant sa phrase, il ramenait, en se redressant puissamment, l’autre jambe en arrière pour retrouver sa position première. Et c’était ainsi durant des heures10. » Cette description, vivante, atteste on saurait mieux la mise en jeu d’un matériel corporel dans la production et la communication du savoir.

Bien d’autres citations en ce sens pourraient être faites ne serait-ce qu’en piochant dans les rapports de l’agrégation du second degré. Ainsi, au tournant du XIXe siècle, à la suite du fort intérêt pédagogique qui s’était dessiné quelque trente ans plus tôt, les examinateurs se montraient très attentifs lors des épreuves orales à l’art de faire des candidats, non seulement à la construction de la leçon et au maniement des documents, mais aussi à la mobilisation des ressources du corps, de la voix, du regard, du geste. Et il y avait plus à blâmer qu’à louer. En 1912, le président du jury de l’agrégation de lettres déplorait « des défauts physiques » chez les candidats, « une voix mal posée et mal conduite, une diction confuse, une gaucherie excessive », et il invitait les agrégatifs à se donner « une éducation de la voix, de l’articulation des mots, de la tenue, du regard même, s’ils ne veulent pas être malheureux non seulement à l’examen mais dans la vie universitaire ». D’année en année revient, pour l’agrégation d’histoire et géographie, le constat d’une extrême difficulté de parole, d’un débit en général saccadé et monotone quand ce n’est pas criard et vulgaire, de tics déjà marqués, d’yeux baissés sur les notes ou, au contraire, perdus dans le vague. Pourtant, remarquait l’inspecteur Foncin en 1897, on ne demandait pas plus que savoir « se tenir, regarder en face un auditoire, parler correctement et, s’il se peut, agréablement ». La leçon orale de géographie était l’occasion en 1898 de déplorer le mésusage du tableau et de préciser ce que devait être la posture du professeur. Des candidats, notait le rapporteur, « dessinent tant bien que mal une carte au tableau et vont s’asseoir devant la table, sans plus s’inquiéter de leur dessin. C’est au tableau, debout, la craie à la main, que la leçon de géographie doit être faite11 ».

Le tableau, pour en venir à lui, implique une gestuelle, une tenue du corps, que révèle ce « concurrent » qu’a été le rétroprojecteur. Cet appareil qui permet de projeter des documents réalisés sur des supports transparents a été très employé dans les cours et les colloques pendant les années 1960-1990. Il donne aussi à l’utilisateur la possibilité d’attirer l’attention sur un détail en pointant sur le document, d’écrire sur le transparent pour apporter une précision, de dévoiler progressivement une image grâce à l’emploi d’un cache, etc. Dans l’utilisation de l’appareil et des multiples possibilités qu’il offre, l’orateur fait toujours face à son public. Ce qui n’est pas le cas avec le tableau. Par la force des choses, il lui faut, s’il veut se faire entendre tout en écrivant, adopter une position de trois quarts qui n’est ni commode ni toujours élégante ; et la plus habile gymnastique n’empêche pas que le corps masque à une partie de l’auditoire ce qui s’écrit. Par ailleurs, le rétroprojecteur permet d’écrire sur le document devant soi, confortablement, en employant l’écriture habituelle en petits caractères ; le tableau, lui, impose le recours à de gros, voire très gros caractères bien moins usuels, et il entraîne le geste inconfortable de tenir le bras levé pendant un temps parfois long. L’usage du tableau qui a été courant pour des générations de professeurs et qui le reste, on l’a vu, dans les mathématiques, amène à adapter le corps à une situation mixte d’écriture et de parole, à gérer une posture incommode, à dresser la main à tracer des caractères lisibles d’un grand module, bref, à accomplir des gestes qui ne sont pas « naturels12 ».

La station debout est aussi celle de la présentation des posters, ce mode de la communication orale désormais quantitativement dominant dans les colloques scientifiques13. Les auteurs sont à côté de leur poster tant hors session, du moins à certaines heures, que pendant la session. Cela suppose une certaine tenue du corps. Les auteurs ne doivent pas se placer devant leur poster ni trop près, et ce afin de ne pas bloquer la vue. Dans la discussion interpersonnelle hors session ainsi que dans la discussion de groupe en session, quand ils présentent leur recherche et répondent aux questions, ils doivent faire preuve, outre bien sûr d’une maîtrise scientifique, d’un ensemble de skills comme il ressort de l’un des manuels les plus autorisés. « Durant votre exposé, indiquait Peter Gosling, gardez la tête haute, en promenant le regard sur le public et en établissant un contact visuel pendant deux ou trois secondes quand cela est possible. Bien que votre présentation soit courte [2-5 minutes], essayez de varier votre voix. » Suivaient des recommandations multiples et détaillées afin de projeter une image professionnelle et, d’abord, de la construire par le choix du vêtement mais aussi et, plus encore, par le contrôle du body language. Un « effort conscient » devait être fait pour discipliner le corps et d’abord afin d’opérer un contrôle de l’émoi – ici on est dans la droite ligne de l’article de Mauss –, en maîtrisant tous les signes physiques traduisant la nervosité, comme tordre ses mains ou ne pas regarder. Il était pêle-mêle conseillé de ne pas s’asseoir, de bien se caler sur ses deux pieds, de ne pas agiter les mains, de ne pas gesticuler de tout son corps, de veiller à la pertinence des gestes, de sourire, etc. Ainsi, dans le face-à-face qu’est la présentation du poster joue un savoir parler, regarder, se tenir. Celui-ci passe par « un effort conscient » qui a été fait pour éradiquer tics et gestes de nervosité, ainsi que par l’éducation du corps à une fonction professionnelle, celle de la communication scientifique orale ; la maîtrise se traduit ici, comme l’écrit Gosling, par une image de soi confiante et « naturelle14 ».

On pourrait lire tout le développement qui précède comme une illustration des principes énoncés dans des traités de rhétorique classique, telle l’Institution oratoire de Quintilien, au chapitre de l’actio ou, dans un autre ordre de choses, mis en évidence par les travaux d’interactionnisme, à commencer par ceux de Goffman15. Plus simplement, on y verra des usages du corps lettré, parlant, entendant, montrant, voyant.

Ils sont à additionner à ceux qui résultent de la pratique, aussi courante qu’ordinaire, de l’écriture où une main tient la plume et l’autre maintient la feuille de papier16. Gestes qui, dans leur économie, ont intégré au fil du temps des inventions techniques, la machine à écrire, puis l’ordinateur qui les ont aussi uniformisés17. Gestes qui sont « une discipline du corps et de l’esprit », pour citer une des conclusions de Mathias Millet dans son enquête sur la copie étudiante avec la pratique de la récitation des notes de cours en écrivant et parfois même à plusieurs reprises : le geste de la main qui écrit, et non simplement de l’œil qui lit, est pour certains une technique de concentration18. Des études ont donné à voir le mobilier spécifique de l’écriture et de la lecture depuis l’époque humaniste, avec la fameuse roue à livres, jusqu’à l’époque actuelle, avec les « tables informatiques19 ». Autant de dispositifs matériels du travail intellectuel auxquels on ajoutera les fauteuils écritoires fabriqués par Benjamin Franklin et les bureaux rationalisés ou technologisés qu’imaginèrent Paul Otlet ou Vannevar Bush20. Ces dispositifs de travail révèlent l’usage que fait de son corps celui qui accomplit ces actes très communs de la vie savante, lire et écrire. Il en va de même dans des recommandations d’aménagement du poste de travail qui ont été faites aux chercheurs au moment de la diffusion de l’ordinateur21 ; ou encore dans la présentation de mobiliers de lecture, par exemple, la chaise Lenio des salles de recherche de la BNF qui est ainsi décrite par ses designers : « coquille de forme ergonomique en suspension sur ressorts d’acier. La coquille accompagne le corps quand il se penche en arrière22 », donnant ainsi à voir le mouvement qui a lieu quand le lecteur se détache de la lecture pour un moment de réflexion ou de détente.

L’usage du corps apparaît dans une plus grande complexité lorsque l’on considère, avec des situations particulières de travail, des emplois spécialisés. L’astronome, pour en rester à une étude portant sur le XVIIIe siècle, devait posséder un regard exercé et savoir « se servir indifféremment des deux yeux » ; son travail à l’observatoire impliquait aussi l’accomplissement de gestes délicats pour le maniement des instruments, par exemple, du quart de cercle23. La « géographie de plein vent », telle qu’elle s’instaura au tournant du XIXe siècle, quand le géographe quitta le cabinet pour aller sur le terrain, amena un nouvel usage du corps. Le géographe devint un marcheur, voire un grand marcheur, à l’instar du fondateur de l’école française Paul Vidal de la Blache. Ses descriptions et, d’abord ses carnets, enregistrent « le souvenir, inscrit dans les muscles » des territoires parcourus. Ils livrent une multitude d’impressions visuelles, bien sûr, mais aussi tactiles (avec le toucher d’une roche), auditives (avec les bruits du vent, des oiseaux), olfactives (ainsi « la végétation de fougères et de genêts d’où s’exhale […] une senteur âcre »), gustatives (« le goût salé du paysage de l’Ouest »), autant d’impressions qui attestent des sens en alerte enregistrant une masse d’informations24. L’ingénieur du début du XXe siècle ajoutait à une science livresque non négligeable les multiples ressources que les sens lui apportaient : soit une masse d’informations visuelles, tactiles, auditives acquises dans des fonderies et des usines, quand il avait vu toutes sortes de matériaux et de machines, mais aussi fait l’expérience du toucher et acquis une expertise de l’ouïe25.

L’archéologue moderne fait également un grand usage des ressources de son corps. De son œil, bien sûr, dans une discipline éminemment visuelle, que ce soit pour la lecture du site ou celle d’images parfois très complexes, depuis des représentations figurées jusqu’à des reconstitutions 3D en passant par des photos et des vues aériennes. La main est aussi à l’œuvre, d’abord dans le maniement de cet outil ordinaire qu’est la truelle avec son nécessaire complément, le pinceau, l’une comme l’autre en de multiples variétés. La truelle nécessite une gestuelle différente suivant la nature du terrain et des opérations : elle sera employée « en douceur ou en force » ; on se servira de la seule pointe ou, par exemple, « pour nettoyer une surface horizontale, de son seul bord droit avec une précision millimétrique », comme l’écrivait l’archéologue anglais Philip Barker dont les travaux de méthodologie des fouilles ont fait autorité. À propos du pinceau, il notait que, « comme bien des opérations en apparence simples, nettoyer avec le pinceau n’est pas aussi simple qu’il y paraît ». Et de décrire et d’expliciter un geste : « Les pinceaux rigides doivent être utilisés en un mouvement rotatif suivant l’axe vertical : de cette façon, le mouvement élastique des soies enlève bien la terre de la superficie au lieu de la répandre sur elle. » Travailler à la truelle implique, au-delà de gestes experts, une posture du corps, à genoux et courbé, ainsi qu’une discipline du mouvement, se déplacer toujours à reculons26. La main, c’est aussi le toucher qui permet au céramologue de juger de la qualité d’une pâte ; à la fin d’une journée sur le chantier, le pouce est « comme lissé » à force d’avoir trié des tessons et, ce faisant, d’en avoir apprécié le procédé de fabrication (tourné ou non) et la texture (« douce », « rugueuse », « savonneuse », etc.27). L’oreille est également mise à contribution : le bruit que fait entendre un tesson lorsqu’on le frappe du doigt ou qu’on le jette sur le sol, fournit un indice de la cuisson de la pâte, soit un élément dans une identification de provenance28. Le goût même entrerait en jeu. Jean Perrot qui fouilla au Proche-Orient a laissé un témoignage à première vue pittoresque sur un archéologue de l’École biblique de Jérusalem, le père Vincent (1872-1960) dont la science céramologique était grande. « Il avait manipulé tant de tessons. On disait qu’il les mangeait. De fait, il portait souvent une cassure fraîche à sa bouche ». Et Perrot de citer alors Vincent lui-même expliquant : « Le toucher de la langue […] renseigne fort bien sur la qualité de la pâte, son acidité, son degré de cuisson29. » Ce qui recoupe une pratique similaire dont une céramologue m’a fait part. Lorsqu’elle était étudiante, on lui avait appris à « passer un coup de langue rapide sur la céramique » ; si la langue « faisait éponge », la céramique était calcaire, si elle laissait une simple tâche d’humidité, elle était siliceuse ; la première n’allait pas au feu au contraire de la seconde ; ainsi on pouvait distinguer la vaisselle de table des pots, marmites et plats à cuire30.

Ces quelques exemples relevant d’activités générales ou de savoirs spécialisés montrent la mise en jeu des ressources que le savant tire de son corps pour des opérations de production et de transmission des connaissances. Il y a là des techniques, plus ou moins sophistiquées, qui allèguent nécessairement un apprentissage, quel qu’il soit. D’ailleurs, de rapides mentions ici et là le laissent entendre. C’est à l’éducation du corps qu’il convient maintenant de s’intéresser.





Éduquer le corps


Démarche qui semblerait dans une première approche un exercice un peu vain, si l’on en croit les opinions des acteurs du présent aussi bien que du passé disant que cela relève d’un savoir qui ne s’écrit pas, ne se communique pas. Un chirurgien commentait en 2006 un geste opératoire en ces termes : « Ça, c’est un des plus beaux gestes de la chirurgie thoracique que j’aie appris avec mon patron. Oui, c’est ça, je saurais le refaire, mais je ne saurais plus dire les mots31. » Des archéologues et des historiens d’art que j’ai interrogés sur l’éducation du regard m’ont répondu que cela ne s’enseignait pas et ne s’écrivait pas.

Il est pour le passé des remarques similaires. Charles Patin, l’un des plus grands numismates du XVIIe siècle, rapportait sa science des médailles à l’expérience, à l’observation répétée, et il précisait que cela ne pouvait pas être mis en mots32. Michel Hennin disait la même chose de façon plus détaillée dans son Manuel de numismatique ancienne (1830). Le numismate devait acquérir « le coup d’œil » pour ne pas être abusé par des contrefaçons ; il lui fallait se livrer à l’examen journalier des médailles ; ainsi s’acquérait « le tact […], sentiment intime qui s’éprouve et ne se raisonne pas d’une manière claire pour ceux qui n’en connaissent pas la portée », et ce tact était « incommunicable […] : ces sortes de connaissances s’apprennent mais ne s’enseignent pas33 ». Des médecins londoniens de la seconde moitié du XIXe siècle, praticiens cultivés, présentaient la médecine comme « un art ». Ils refusaient la spécialisation et étaient méfiants envers l’instrumentation, par exemple, envers le sphygmomanomètre : pour mesurer la pression du sang, « le doigt exercé » suffisait. Ils mettaient en avant une longue expérience et, avec elle, un savoir « incommunicable » ou encore « un savoir qui, dans une très large mesure, ne pouvait être communiqué aux autres ni par oral ni par écrit34 ». Autre discipline et même constat dans un manuel de la technique des fouilles archéologiques présentant en 1939, sur la base des expériences les plus récentes, les moyens, méthodes et procédures en la matière. Dès l’introduction, il était précisé que ce qui contribuait au succès des investigations, c’était « avant tout l’esprit d’initiative du fouilleur, son expérience, son savoir-faire, sa faculté d’adaptation […]. Il y a dans la mission du fouilleur une part de génie qu’aucune formation professionnelle ne peut donner35 ».

On se trouve alors devant une situation problématique. D’une part, les preuves ne manquent pas de l’incidence de techniques du corps dans la dynamique scientifique. D’autre part, des acteurs du présent aussi bien que du passé disent que ces techniques relèvent d’un savoir qui ne s’écrit pas, ne se communique pas, quand il n’est pas rapporté à l’expérience personnelle, à l’art, au génie, au mystère. Autant d’opinions référant à ce que depuis Michael Polanyi et ses deux ouvrages Personal Knowledge (1958) et The Tacit Dimension (1967), les épistémologues appellent savoir tacite, soit tout ce qui dans l’ordre du savoir ne s’écrit pas, voire ne peut pas être verbalisé, tout ce qui se donne par l’exemple, l’imitation. Cette catégorie, aussi vague que vaste, a été utilisée par des historiens des sciences pour définir, caractériser une école ou un laboratoire avec ses pratiques, ses trucs, son style36. Implicite plutôt que tacite est l’adjectif utilisé par les anthropologues des savoirs, qui ont des références autres que Polanyi, pour désigner des savoir-faire, des savoirs pratiques, des tours de main, des coups d’œil, autant de gestes, d’actions, d’attitudes qui échappent à l’explicitation et à la pensée, qui s’acquièrent dans l’expérience et se transmettent par le voir faire, le contact personnel, l’exemple37. Ces travaux qui objectivent ce qui ne s’écrit pas et ne se dit pas, seraient pour l’historien une sorte de fin de non-recevoir, l’invitation à en rester au constat. N’y a-t-il pas la possibilité d’aller outre la description d’une image – par exemple, le frontispice de la Fabrica de Vésale, lieu « topique » du décodage de l’illustration scientifique – ou la pure énumération de gestes un jour faits, en suivant les notes portées sur un cahier de laboratoire ? Ne peut-on pas aller au-delà des mots imitation, exemple, expérience ?

Chemin faisant, il est apparu que, dans la sphère savante, des modalités d’acquisition de telle ou telle technique ont été couchées sur le papier, depuis de simples remarques jusqu’à de très longs développements enseignant comment voir, toucher, entendre, etc., et l’expliquant parfois même avec force détails pour que l’éducation se fasse au mieux. Bien sûr, tout n’est pas écrit, mais beaucoup de choses le sont ; et qui plus est, on trouve là, outre le comment, le pourquoi, soit les explications et les raisons données par les usagers mêmes. Cette littérature constitue une source de premier ordre lorsque l’on se porte à des moments de l’histoire des savoirs où des changements majeurs interviennent, quand un instrument ou une technique apparaît, quand un dispositif d’enseignement original est mis en place, quand une évolution méthodologique modifie profondément une discipline, bref, quand s’instaure un nouveau paradigme. Dans ces circonstances, il faut alors non seulement convaincre du bien-fondé de la nouveauté – ce qui, au passage, amène à évoquer la pratique antérieure et la donner à voir –, mais encore expliquer ce qu’il faut faire (et ne pas faire) jusque dans les plus minimes éléments, d’autant que ce qu’il faut faire peut relever d’un ordre parfois fort complexe. De tels documents « pédagogiques » qui peuvent être de haut, voire de très haut niveau ne manquent pas. On trouve également des informations dans des textes liés à la pratique scientifique, depuis des avis dans un débat jusqu’à des traités et des monographies, dans lesquels l’auteur insère un développement, par exemple, sur un geste à faire et d’abord à acquérir. Enfin, on n’oubliera pas que le monde savant a beaucoup parlé de soi tant dans la littérature professionnelle que dans des récits biographiques et autobiographiques retraçant, à l’occasion, des apprentissages autres que livresques. Il est vrai qu’un type de document peut être tantôt loquace tantôt muet. Par ailleurs, les textes ont leurs limites et il ne faut pas nécessairement en déduire l’exacte réalité des faits. Le monde médical a-t-il toujours conduit ses mains comme Henri Mondor le prescrivait dans les pages qu’il consacra à la palpation dans ses Diagnostics urgents. Abdomen (1930) : « des mains réchauffées mises sur la paroi, doucement, et entièrement à plat, les deux mains également douces, également couchées sur le ventre, appuyées lentement de toute leur surface, sans à-coup, sans brusquerie38… » ?

Toutefois, noter des limites des textes ne saurait amener à leur complet rejet. Rappelons que des historiens et des sociologues mettent à profit, de façon critique, des manuels de civilité et autres instructions pour étudier comment les corps des enfants ont été dressés, dans quel but et à quels effets. Ajoutons que les textes, outre les prescriptions qu’ils contiennent, donnent parfois à voir d’autres agents à l’œuvre dans la transmission, soit, pour en rester à l’exemple de l’ouvrage d’Henri Mondor, des photos montrant les gestes à ne pas faire. Enfin, pour une juste appréciation des matériaux sur lesquels on s’appuiera, on rappelle qu’il ne s’agit pas ici de dévoiler des tours de main ni de certifier des gestes tels qu’ils ont été faits. Ce qui intéresse est de montrer comment le corps a été utilisé pour des opérations intellectuelles, comment il a été éduqué à cet effet et ainsi d’estimer le prix qui a été attaché à cette ressource.

On le fera en analysant des exemples empruntés à la géographie ainsi qu’à l’histoire de l’art et de l’archéologie, en se plaçant à la fin du XIXe siècle et au début du XXe siècle, soit à un moment crucial dans l’évolution de ces disciplines. Les changements qui sont alors intervenus tant du point de vue épistémologique qu’institutionnel ont amené à mettre en place des modalités nouvelles d’acquisition des connaissances. Des dispositifs ont alors été instaurés et, par la force des choses, explicités et justifiés. Les descriptions qui ont été données et les argumentaires qui ont été produits révèlent, avec les moyens mis en œuvre pour faire appréhender les objets d’étude, ce que fut dans ces disciplines une éducation du corps, et d’abord de l’œil.

« Savoir regarder » fut un véritable mot d’ordre de la géographie vidalienne ; il fallait acquérir un « regard averti » autre que celui du touriste ou de l’artiste paysager s’attachant au pittoresque, mais aussi saisissant ce qui paraissait à ceux-ci insignifiant ou médiocre. La « géographie moderne » s’institue en France à la fin du XIXe siècle, rompant avec la géographie historique jusqu’alors seule enseignée à l’université et empruntant à des disciplines scientifiques tout en s’en distinguant. Vidal de la Blache et, à sa suite, les représentants de l’École française de géographie, sont sortis du cabinet et allés sur le terrain, quand ils n’ont pas, comme de Martonne, alimenté une véritable mystique du terrain. Cette « géographie de plein vent » ne doit pas faire oublier que ces nouveaux géographes ont aussi été des hommes de réflexion et d’écriture, à l’instar du fondateur39. Elle donne toutefois bien à voir la hiérarchie des moyens désormais en acte : « Avec des livres on ne fait que de la géographie médiocre ; avec les cartes on en fait de la meilleure ; on ne la fait que très bonne sur le terrain », aurait dit Vidal de la Blache lui-même. La géographie moderne se posa comme une « science visuelle » ou une « science du visible », quelles qu’aient été ses orientations vers une géographie générale ou régionale, physique ou humaine. Cette conception impliquait de donner aux élèves une éducation spécifique. Jean Brunhes, qui illustra la géographie humaine qu’il enseigna à partir de 1912 au Collège de France, aimait à répéter : « ne voit pas qui veut […]. Il ne suffit pas de regarder pour voir vraiment un paysage ou tout autre sujet, c’est-à-dire pour l’analyser, pour le comprendre. Une éducation de la vision est donc nécessaire40. »

À cet effet, une panoplie de moyens fut mise en œuvre. Les cours furent accompagnés d’images, de cartes, de projections ou de dessins. Vidal de la Blache utilisait des cartes, des photographies et, à la fin de son exposé, commentait des images projetées41. Jean Brunhes faisait dessiner avant son cours au Collège de France des plans et croquis, et il faisait suivre son propos de projections. Dès avant 1900, quand il enseignait à Fribourg, il utilisa pour des leçons de géographie physique, à côté des projections de photographies, des vues stéréoscopiques ; ainsi les élèves pouvaient bien saisir la perspective et les reliefs, et d’abord apprendre à les voir42. Les cours d’Emmanuel de Martonne se caractérisaient par « le recours permanent au croquis, à la coupe sur le tableau noir, et l’utilisation systématique de projections de photos prises la plupart par lui-même43 ».

Ces dessins, croquis et coupes qui accompagnaient le cours furent aussi les exercices pratiques demandés aux élèves. Voici ceux que de Martonne faisait faire à ses étudiants à l’université de Rennes pour la topographie : « profils longitudinaux de vallées, profils transversaux de vallées et de régions montagneuses, dessin de reliefs vus en perspective, essai de représentation en courbes de niveau figuratives d’un relief vu en perspective, essai de représentation en courbes de niveau figuratives d’une portion de vallée d’après une photographie, essai de mise en perspective d’un panorama d’après une carte topographique, etc.44. » Autant d’exercices sur le papier qui étaient un moyen d’apprentissage d’éléments de la géographie physique mais aussi, et dans le même temps, d’acquisition d’un regard de géographe. Telle était l’opinion du professeur, à en croire un de ses élèves : « Il n’y a pas de moyen plus efficace de voir les choses géographiquement, d’acquérir l’esprit géographique que de s’astreindre à la patiente et efficace construction des cartes, en particulier des cartes synthétiques45. »

Cet apprentissage se faisait dans des instituts (ou « laboratoires ») de géographie qui furent alors créés, à Lille en 1898, à Rennes en 1902, plus tard à Paris, et qui renfermaient de multiples ressources pédagogiques : cartes, atlas, photos et clichés de projection, instruments pour lire et étudier scientifiquement les cartes, plans-reliefs, échantillons minéralogiques46. Il se faisait aussi de façon privilégiée sur le terrain, par des excursions géographiques qui furent alors instaurées à l’imitation des naturalistes. Vidal de la Blache les qualifia de « leçons itinérantes » ou de « l’école de plein air », soulignant ainsi leur caractère pédagogique. Ce furent d’abord des courses collectives courtes et relativement locales groupant un professeur et ses étudiants ; puis, sans que cette modalité disparût, s’instaurèrent les excursions interuniversitaires, la première ayant été organisée en 1905 par de Martonne. Celles-ci, qui devinrent un genre et un rituel de la géographie française, avaient lieu chaque année dans une région différente, duraient une semaine, et regroupaient 30 à 40 personnes – des professeurs qui trouvaient là l’occasion de connaître une région autre que celle de leur université, et des étudiants avancés. Toutes ces excursions, quelles qu’elles soient, étaient pour les élèves une modalité de formation du regard. D’ailleurs, le compte rendu de la quatrième interuniversitaire (1908) notait : « [les étudiants] ont surtout appris à voir les choses47 ».

Au fil de ces multiples procédés que l’enseignement de la géographie moderne mit en œuvre, un regard professionnel s’éduquait, un « regard géographique », différent du regard trivial du touriste ou esthétique de l’artiste. Ce regard expert fut aussi formaté comme il ressort des images produites par les géographes et diffusées dans le grand public et le monde scolaire ; elles obéissent, en effet, à un certain type de cadrage et de point de vue tout à fait caractéristiques, dénotant l’acquisition d’une technique du voir, un paradigme devenu un implicite48.

Une éducation du regard fut au cœur de l’archéologie et de l’histoire de l’art à leur premier moment institutionnel. L’histoire universitaire de ces disciplines commence en France dans le dernier tiers du XIXe siècle. Il existait bien auparavant des enseignements en la matière, à Paris, au Collège de France, à l’École des chartes, à l’École des Beaux-Arts, à l’École du Louvre, mais c’était pour des publics ou des finalités autres. C’est en 1876 que la première chaire d’archéologie fut créée à la Sorbonne. L’histoire de l’art n’obtint un début de reconnaissance qu’en 1893 avec l’ouverture dans cette même université d’un cours complémentaire, la première chaire n’étant instaurée que six ans plus tard. Dans ces mêmes années, des enseignements se mirent en place dans les universités de province suivant le même modèle, l’archéologie primant sur l’histoire de l’art et des charges de cours précédant des chaires49.

Ces nouvelles disciplines universitaires se présentèrent comme des sciences, des sciences positivistes, et marquèrent une double différence, par rapport à l’esthétique et une formation du goût, par rapport à des pratiques d’amateurs. Différence que mettait en relief Théophile Homolle devenu en 1904 directeur des Musées nationaux et de l’École du Louvre. Alors que cette institution créée en 1882 accueillait un public de plus en plus nombreux et, en conséquence, composite, une nouvelle organisation de l’enseignement était à envisager. « L’auditoire mondain et l’auditoire scolaire ont des besoins et intérêts communs ; ils en ont aussi de différents et même de contraires ; le premier peut se contenter d’un enseignement général et théorique, illustré et soutenu par la vue du plus grand nombre possible de reproductions des monuments. Le second réclame, si l’on veut faire avec les élèves, soit des érudits, soit des conservateurs de musées, des leçons plus savantes à la fois et plus pratiques : il y faut la vue, le toucher des originaux mêmes. On doit donc rechercher s’il n’y a pas lieu, à côté de l’enseignement général commun à tous, de créer des conférences pratiques qui se feraient dans les salles des musées, vitrines ouvertes, et qui seraient réservées à un petit nombre d’élèves50. » La même suggestion revenait en 1914 sous la plume de Gaston Brière, professeur dans cette école : il proposait que les leçons du second semestre soient réservées « aux seuls travailleurs [pour] des recherches approfondies et minutieuses, des visites dans les galeries », la modalité étant alors non plus le cours mais des « entretiens familiers51 ». Ces « travailleurs » – on retrouve le mot employé par Langlois et Seignobos dans la distinction avec les historiens amateurs –, c’étaient des étudiants dont il fallait faire des archéologues ou des historiens d’art de profession. En outre, dans le nouveau contexte scientifique, une formation personnelle n’était plus de mise : un enseignement spécifique et méthodique appliqué à des réalités « qui s’adressent aux yeux52 » s’imposait.

Il importait donc, comme l’énonçait Charles Diehl en 1888 dans la leçon d’ouverture de son cours d’archéologie à l’université de Nancy, de procurer à l’élève « la vue directe des monuments » et, avec elle, « une éducation des yeux » par laquelle « il acquiert cette finesse de tact, cette sûreté de goût et de jugement, cette connaissance précise que toute l’érudition du monde est incapable de donner53 ». Cette nouvelle hiérarchie qui s’établissait entre éducation des yeux et érudition amenait à une redéfinition du rôle magistral. Pour François Benoît qui enseigna à Lille à partir de 1899, la mission du professeur était « non de faire double emploi avec les livres et les manuels par des cours généraux d’histoire et de biographie, non de confiner les étudiants et les auditeurs dans le détail d’une étude spéciale et érudite, mais bien d’affiner leur vision54… ». Les procédés qui furent utilisés à cet effet sont les mêmes pour l’archéologie et l’histoire de l’art. Ils s’appuyèrent sur un outillage spécifique mettant à profit de multiples technologies, anciennes et nouvelles, et ils portèrent à la création d’instituts spécialement aménagés pour la formation du futur archéologue ou historien d’art. Ici on emprunta beaucoup à l’Allemagne qui avait une avance considérable et des ressources que les professeurs français regardaient avec envie55.

Dans le dispositif pédagogique, le cours demeure, mais le professeur, outre qu’il parle, fait voir. Ainsi, Robert de Lasteyrie qui occupa la chaire d’archéologie à l’École des chartes de 1880 à 1910, « appuyait ses paroles de dessins au tableau. En effaçant ou en ajoutant quelques traits, il montrait la transformation d’un élément de construction ou d’un édifice, le développement d’une église depuis la période latine jusqu’à l’époque gothique ». Cette description rapportée lors d’une cérémonie d’hommage est assortie du commentaire suivant : « Ce procédé d’exposition était fort utile dans un temps où l’on n’avait pas, comme aujourd’hui, la ressource des projections ; il servait à faire l’éducation des yeux56. »

Dans les salles de cours, celle-ci se fit aussi par des reproductions que le professeur faisait circuler avec l’inconvénient que, non seulement les photos étaient de dimensions restreintes, mais surtout que tous ne voyaient pas dans le temps où le professeur parlait ; parfois même les images étaient montrées après la leçon. Les projections représentèrent un grand progrès : tous voyaient ; grâce à l’agrandissement, ils voyaient mieux que sur une photo ; et dans le cas où il y avait deux lanternes, ils voyaient les détails que la comparaison faisait ressortir. Rappelons toutefois qu’il fallait disposer des plaques de verre correspondant aux monuments ou aux œuvres qui formaient le sujet du cours et d’abord des appareils de projection ; ajoutons que, pour des raisons techniques, des projections se faisaient au terme de la leçon. C’est ainsi que procédait Charles Diehl après avoir fait circuler des photos pendant la séance. La pratique mixte que fait ressortir cet exemple n’était, semble-t-il, pas rare57. Quoi qu’il en soit, et surtout si on compare à ce qui se faisait un demi-siècle plus tôt où le public écoutait des descriptions et ne voyait pas grand-chose si ce n’est rien, les yeux s’éduquaient dans un processus qui joignait les ressources du parler, du faire voir et du montrer, et ils s’éduquaient non au Beau mais à la Science.

La création d’instituts avec des collections de moulages, de photos, de cartes, etc. alla dans le même sens. Le premier fut établi à Bordeaux en 1886, mais il fut éclipsé par ceux de Montpellier (1890), Paris (1891), Lyon (1899), Lille (1900)58. Ce dernier fut organisé par François Benoît, un élève de Lavisse, reçu premier à l’agrégation d’histoire (1893) et auteur de la première thèse faite en France sur un sujet d’histoire de l’art (1897). Le jeune chargé de cours d’archéologie et d’histoire de l’art, qui arriva à la faculté des lettres de Lille en 1899, ne ménagea pas sa peine pour créer un institut ; les descriptions qu’il en donna en 1901, puis en 1914 – il était entre-temps devenu professeur titulaire d’histoire de l’art (1905) – permettent d’en voir l’organisation et l’accroissement rapide59.

À son ouverture, ses 1 000 m2 se répartissaient en quatre sections : le « laboratoire », la salle d’exposition, le musée de moulages et la salle du Nord réservée à l’art septentrional. Le « laboratoire » – le terme est typique de la nouvelle pédagogie et on l’a vu employé pour la géographie – était « le cœur » du dispositif ; c’était là que le professeur enseignait non magistralement mais sous forme de « conférences » recourant au tableau noir et au projecteur, les étudiants étant assis autour d’une table. Ceux-ci avaient libre entrée au laboratoire et pouvaient consulter les collections de livres et de photographies. Il y avait lors de l’ouverture plus de 6 000 images collées sur des cartons et réunies en portefeuilles en un ordre méthodique « de sorte que l’opération mécanique de feuilleter la suite des portefeuilles de gauche à droite équivaut à une revue rationnelle de l’évolution artistique ». La salle, vaste de plus de 300 m2, était décorée de façon « méthodique et démonstrative » : contre ou sur les parois avaient été disposés « des statues, des bustes, des bas-reliefs, des moulages de sculpture décorative, des originaux ou moulages de céramique, orfèvrerie, serrurerie, ivoires, de grandes photographies de monuments, de tableaux, de gravures, etc. ». Ces quelque 200 spécimens avaient été « choisis et placés de façon à développer par séries symétriques, de gauche à droite depuis l’entrée de la salle, la succession chronologique des styles principaux ». Les moulages, au nombre de 612, complétaient pour la sculpture la documentation photographique. Ils étaient présentés en ordre chronologique « pour atteindre au maximum d’effet démonstratif » ; chaque pièce était accompagnée d’une pancarte portant toujours les mêmes rubriques (art, époque, siècle, auteur, etc.) « afin de favoriser l’acquisition inconsciente de la bonne méthode critique » ; quand cela était possible, une photo était annexée au moulage montrant, selon les cas, l’ensemble du monument dont l’original faisait partie, l’édifice dont il était un ornement, le cadre urbain ou naturel pour lequel il avait été conçu, etc. En 1914, Benoît faisait état de notables accroissements. À côté de la bibliothèque, il y avait désormais une iconothèque et un laboratoire photographique ; les collections s’étaient considérablement augmentées avec 60 000 photos et moulages, et 12 000 clichés pour la projection. Le professeur qui enseignait « en face d’originaux ou devant leur image à l’écran » pouvait disposer de deux appareils à projection et aussi « dessiner sur des tableaux illuminés ». Quand on aura ajouté la ressource qu’offraient les visites au musée de Lille, on mesure avec l’énoncé de « cet outillage considérable et spécial » les possibilités qu’il y avait d’une éducation méthodique et scientifique des yeux. D’ailleurs, Benoît concluait son article en ces termes : « [les étudiants] apprennent à voir […] en se référant non à cette chose vague qu’on appelle le goût, mais à des lois physiques et des règles techniques ». Ainsi s’acquéraient à la fois un savoir dans une discipline et un regard expert : l’un n’allait pas sans l’autre.





Le corps médical


« On ne naît pas médecin, on le devient ». Cette remarque en forme d’aphorisme se lit dans la leçon d’ouverture de clinique médicale qu’Hippolyte Bernheim fit en 1873 à la faculté de médecine de Nancy. Le jeune professeur rappelait que la clinique raisonne non sur des abstractions mais sur « des faits d’observation […], des phénomènes matériels, visibles, palpables, sensibles, mais qu’il faut savoir toucher, voir et sentir. Pour le savoir, il faut l’avoir appris ». Il décrivait « l’élève studieux » arrivant à l’hôpital : « il a étudié la pathologie dans les cours et les livres, le tableau des maladies est clair et net dans son esprit […] En vain cherche-t-il aux lits des malades les maladies dont l’idée abstraite existe dans son cerveau ; nulle ne répond à l’image idéale qu’il s’en était faite ; […] il a des yeux qui ne voient pas, des oreilles qui n’entendent pas, des mains qui ne sentent pas ». Il lui faut apprendre à voir, à entendre, à toucher, à percevoir par le sens olfactif. Après avoir rappelé cette nécessaire « éducation [des] sens », il poursuivait : « Que l’on vienne dire maintenant que la médecine clinique est un art ; que le médecin est un artiste qui devine la maladie par je ne sais quel flair médical. Non ! Mille fois non ! La médecine clinique n’est pas un art mais une science ; le diagnostic ne se fait pas par une sorte d’intuition divinatoire donnée par la Providence à certains cerveaux privilégiés ; il se fait par des méthodes scientifiques plus ou moins exactes, d’où découlent des inductions plus ou moins précises relatives à la maladie. Sans doute, on naît avec un jugement plus ou moins parfait, avec des sens plus ou moins aptes à certaines recherches, et, suivant ses aptitudes spéciales, on acquiert plus ou moins rapidement certaines qualités qui font le médecin. » Quelque quarante ans plus tard, très précisément en 1910, Joseph Schmitt lui succédait et, dans sa leçon d’ouverture, il retrouvait les accents de son prédécesseur. Pourtant, les temps avaient changé : le laboratoire et l’imagerie apportaient de nouvelles ressources. La clinique ne conservait pas moins toute sa valeur. Une « éducation des sens » demeurait nécessaire ; le démontraient les ressources qu’avait « une oreille bien exercée » et, a contrario, les limites d’« un œil mal préparé60 ».

L’éducation des sens est un leitmotiv du discours médical du XIXe siècle et d’une bonne partie du XXe. Corvisart dont on a cité le propos de 1808 quant à une « éducation médicale des sens » ajoutait qu’il y avait là « la matière d’un ouvrage d’une grande utilité ». À l’autre extrémité du siècle, les Prs Lasègue et Grancher donnaient dans leur ouvrage sur la palpation et la percussion les règles présidant à « l’éducation des sens du tact et de l’ouïe61 ». Paul Poirier qui, lui, enseignait l’anatomie, recommandait d’emblée : « faites l’éducation de vos mains ; apprenez à vos pulpes à sentir62. » Robert Debré a rappelé dans ses mémoires son premier apprentissage à l’hôpital Trousseau au début du XXe siècle : « L’éducation de notre vue, de notre oreille et celle de nos mains étaient attentivement développées63. » Pour le Pr Chauffard – on est à la fin des années 1920 –, l’étudiant en médecine devait acquérir « une éducation sensorielle », une éducation de tous les sens, vision, odorat, toucher, goût64. Jean-Paul Escande, dans un ouvrage de 1975 qui fut un succès de public, rappelait qu’« aucun discours, aucun manuel ne sauraient remplacer cette éducation de la vue, de la main, de l’oreille qui ne s’apprend ni par double vue, ni de seconde main, ni par ouï-dire65 ».

On n’entrera pas dans le détail des moyens de l’apprentissage : les cours et les livres (et leurs illustrations), les planches anatomiques qui existent toujours, les modèles, les projections, le cinéma et la vidéo jusqu’aux tutoriels que l’on trouve aujourd’hui en nombre sur le Web. La clinique fut à cet endroit, comme J. Schmitt le disait, « la grande école du médecin », école qui fut une réalité européenne émergeant à partir de la seconde moitié du XVIIIe siècle à Vienne, Édimbourg, Pavie, Lausanne66. Ce qui intéresse ici est la formation d’un système sensoriel spécialisé qui amène les yeux du médecin à voir, ses oreilles à entendre, ses mains à sentir, une éducation qui en vient à mobiliser son corps tout entier. À cet effet, on s’arrêtera d’abord aux gestes médicaux de la palpation et de la percussion ; puis, on suivra ce que fut l’éducation spécifique de sens assistés par un instrument, de l’œil appliqué au microscope lorsque cet appareil s’introduisit au XIXe siècle dans le monde médical, de l’oreille dans l’auscultation médiate à la suite de l’invention de Laennec ; enfin, on prendra un exemple contemporain, à partir d’une technique d’imagerie médicale, la tomodensitométrie (le scanner) et de la formation de l’œil qu’elle a entraînée. On complétera cette anthropologie du corps médical en s’arrêtant sur quelques gestes du chirurgien à deux moments majeurs dans l’évolution de la discipline.

La palpation abdominale a été pratiquée au Moyen Âge et à la Renaissance, mais on ne sait si ce fut fréquemment. Au XVIIIe siècle, climax de la médecine prémoderne, le médecin s’appuyait sur quatre techniques pour établir son diagnostic : le récit fait par le malade, l’aspect du malade, la prise de pouls, l’inspection des selles et des urines. À ce dernier égard, il devait acquérir une compétence visuelle : à la fin du XVIIe siècle, il fallait pouvoir distinguer entre vingt-six couleurs et dix-neuf types de sédiments. Si parfois le médecin pratiquait la palpation, il accordait moins d’importance à l’information qu’il obtenait ainsi qu’au récit du malade. On a relevé, comme des exceptions, des médecins pratiquant au XVIIIe siècle la palpation et lui accordant une pleine valeur, tels Gerard van Swieten (1700-1772) à Vienne et Giambattista Morgagni (1682-1771) à Padoue ; on a aussi noté que dans les premiers enseignements cliniques qui se mettent en place, par exemple à Lausanne ou à Vienne, l’étudiant pratiquait l’examen physique du malade. Reste que la palpation ne s’imposa véritablement qu’au XIXe siècle où elle l’emporta sur le récit du malade67.

La Technique de la palpation de Charles Lasègue (1882) montre ce qu’était l’apprentissage du geste de la palpation, l’éducation de la main du praticien, voire le dressage de tout son corps. Cet ouvrage était destiné aux étudiants, et l’on peut penser que, comme un autre du même auteur, sa Technique de l’auscultation pulmonaire (1881), il reprenait des éléments de son enseignement à la faculté de médecine de Paris où, de 1869 à 1883, il fut titulaire de la chaire de clinique médicale.

Les prolégomènes précisaient ce qu’il fallait entendre par palpation, donnaient des indications générales quant à cette méthode d’exploration médicale, indiquaient les apports et les limites du concours des sens autres que le toucher dans cet examen et, outre la position des mains et des doigts, spécifiaient la posture que devait prendre l’observateur. Lasègue remarquait que la palpation vraie, quand l’objet peut être saisi entre le pouce et l’index, n’avait ici lieu que pour une articulation ou une phalange ; cette « tactilité » relevait d’« un manuel opératoire que nous pratiquons tous plus ou moins consciemment » quand il s’agit de reconnaître la forme d’un objet. La palpation du second ordre a lieu par apposition des doigts, sans préhension ; elle donne la notion de surface plutôt que de forme ; pour Lasègue, il valait mieux l’appeler toucher que palper. Dans ce mode, dominant dans l’exploration médicale, il fallait procéder comme pour le palper proprement dit, c’est-à-dire par « une série de secousses imprimées par les doigts de l’observateur à l’objet mobile ou immobile dont il veut tracer les contours » ; et, pour bien faire comprendre le geste à faire, il soulignait que « le frôlement ne donne pas de résultats utiles quand il s’agit de la limitation des organes ». Dans le toucher, le concours des autres sens, de l’ouïe (par la percussion) et de la vue était utile, même s’il convenait, pour la vue, de se méfier d’illusions que pouvait créer l’éclairage. Il ne notait pas moins que l’on obtient le maximum d’acuité d’un appareil sensoriel en le faisant agir exclusivement. D’où la recommandation de « fermer les yeux pendant la palpation quitte ensuite à recourir aux indications que peut ajouter l’examen visuel ». Enfin, la qualité du geste – et donc celle des informations qu’il fournirait – passait par une bonne position du malade mais aussi par une bonne posture du médecin. Celui-ci devait « se placer lui-même, comme on dit vulgairement, au mieux de ses intérêts. Debout, jamais assis, se maintenant par l’écart des jambes sur une base solide, libre de ses mouvements peu étendus, mais d’autant plus délicats ».

Ces recommandations générales, et il en est bien d’autres, étaient suivies d’indications spécifiques pour chaque région anatomique (tête, thorax, abdomen, membres) où la palpation devait être appliquée par des modalités particulières : ce pouvait être par apposition des deux mains, par succussion des doigts ou des mains, par le jeu des différents doigts. Un exemple donnera une idée du détail que Lasègue fournissait. Il est tiré de la rubrique des articulations douloureuses : « on doit procéder au palper à l’aide de la face interne de l’index en promenant le doigt lentement et successivement sur le pourtour de la jointure, en notant les maxima douloureux […]. Chaque point douloureux marqué au crayon ou à l’encre sera facilement limité ». Au fil des pages, Lasègue distinguait des opérations aisées, celles par lesquelles l’apprenti devait commencer son éducation sensorielle, d’autres, plus difficiles, exigeant « une délicatesse de main qui, à la façon de toutes les habiletés manuelles, ne s’acquiert que par une longue expérience68 ».

Cet ouvrage comprenait une seconde partie consacrée à la percussion. Elle était due à Joseph Grancher (1843-1907), alors directeur de l’Hôpital des enfants malades, et connu pour des travaux sur la tuberculose. Contrairement à la palpation dont l’histoire se perd dans la nuit des temps, la percussion date de 1761 quand le médecin viennois Leopold Auenbrugger publia son Inventum novum ex percussione thoracis humani ut signo abstrusos interni pectoris morbos detegendi. Si en France cette technique ne se diffusa qu’avec la traduction-commentaire donnée par Corvisart en 1808, ailleurs elle suscita en son temps de l’intérêt, fut mise en pratique et donna lieu à des travaux69. Ces acquis ainsi que d’autres apports et perfectionnements qui intervinrent au cours du XIXe siècle entrent dans l’ouvrage de Grancher. Comme Corvisart l’avait indiqué dans sa traduction, le procédé, simple, avait « ses difficultés » et il exigeait « un exercice très délicat, très attentif et très répété70 ». Il fallait apprendre à percuter.

Grancher commençait par présenter les méthodes de percussion : immédiate, s’exerçant avec toute la surface de la main ; médiate, « avec un, deux ou trois doigts de la main droite faisant office de marteau, et venant frapper d’un coup sec la seconde phalange de l’index ou du médius de la main gauche étendue et appuyée fortement sur le point à percuter » ; instrumentale, avec l’aide du plessimètre, disque sur lequel frappait un marteau de caoutchouc. La percussion digitale était jugée supérieure, et Grancher indiquait comment placer les doigts et faire en sorte que le geste ne soit pas douloureux pour le malade : la condition était que « tous les mouvements de la partie faisant office de marteau se passent dans le poignet, les doigts de la main étant rigides et le coude immobile ». La position tant du malade que du médecin variait selon la région à examiner et l’orientation du lit. Pour l’examen du thorax, par exemple, « le médecin sera mieux placé debout, à la gauche du malade. Dans cette position, l’index ou le médius de la main gauche s’appliquera plus perpendiculairement sous la clavicule des deux côtés ». À la lecture de ces généralités, se voit l’éducation d’une main qui apprend tant à percuter qu’à sentir, d’un corps qui apprend à se tenir ; se devine aussi l’éducation d’une oreille qui doit savoir distinguer des bruits, leurs quantité et qualité, et les interpréter.

C’était là l’objet de la deuxième section sur les classifications des bruits de percussion et les théories relatives à leur production ; dans des opinions aussi nombreuses que diverses, Grancher indiquait à l’attention des étudiants ce qui suffisait pour la pratique et soulignait que le plus souvent le médecin ne pouvait guère aller au-delà du simple constat. La troisième section dite « pratique » était la plus longue et elle portait sur l’application de la percussion aux divers organes (dans leurs états physiologique et pathologique), notamment aux poumons. Grancher décrivait les gestes à faire et les sons produits. Des développements hautement spécialisés révèlent une expertise auditive assez sophistiquée lorsque, par exemple, les bruits étaient fixés sur la gamme des tons, même si c’était « à titre de curiosité scientifique ». Ainsi, après avoir divisé la région antérieure droite du thorax en trois régions A, pour la clavicule, B, pour la région sous-claviculaire, C, pour la région sus-mammaire, Grancher constatait : « c’est cette dernière qui donne la plus grande quantité de son et la note la plus basse, le do de la quatrième octave. B fournit moins de son et la note la de la quatrième octave. A donne encore moins de son avec le do de la cinquième octave » ; et le commentaire se poursuivait sur trois pages. Autre exemple montrant un geste complexe unissant palpation et percussion afin de distinguer des nuances très délicates de sonorité dans la région du cœur : la percussion digitale palpatoire due à Pierre-Adolphe Piorry (1794-1879), l’inventeur du plessimètre. « En appliquant trois doigts de la main gauche sur la région, et en percutant le doigt du milieu, les deux autres font l’office d’organes de palpation ; ils recueillent les impressions d’élasticité des organes profonds, leurs délicates vibrations en + ou en – et permettent ainsi de reconnaître les submatités les plus légères ». Ce type de geste qui n’était pas infaillible, alléguait une grande virtuosité de la main et de l’oreille. Grancher ne cachait pas les limites de la technique qu’il exposait dans un grand détail ; de façon générale, il rappelait le nécessaire concours de la palpation et de l’auscultation dans l’établissement du diagnostic71.

Cette dernière technique avec l’invention du stéthoscope ressortit à un certain nombre d’idées médicales que l’on ne rapportera pas ici72. On mettra l’accent sur les nouveaux gestes qu’elle entraîna et sur l’éducation auditive qu’elle impliqua. Le stéthoscope fut inventé par Laennec qui, dans son ouvrage De l’auscultation médiate, paru en 1819 (avec une édition augmentée en 1826), en a donné l’historique. Il existait une forme antérieure d’auscultation dite immédiate – le médecin collant son oreille à la région du cœur ; cette technique donnait des résultats insuffisants et était incommode, voire inconvenante tant pour le médecin que pour le malade. Laennec lui-même l’avait utilisée faute de mieux jusqu’à ce jour de 1816 où les circonstances de l’examen ne lui permettant pas d’y recourir, il forma avec un cahier de papier un rouleau, posant une extrémité sur la région précordiale et appliquant son oreille à l’autre bout : il entendit les battements du cœur d’une manière beaucoup plus nette et plus distincte que par l’application directe de l’oreille. Il conduisit alors à l’hôpital Necker où il exerçait des observations nombreuses sur des malades – les autopsies lui permettant de « se convaincre par ses yeux de la certitude des signes donnés par l’ouïe » –, et il étendit ce type d’auscultation de l’exploration du cœur à celle des poumons.

Tant pour répondre à des critiques que pour exposer une technique nouvelle, il donna de nombreuses explications. Tout d’abord quant au maniement de l’instrument qui, dans ses divers perfectionnements, resta alors un cylindre. De façon générale, il devait « être tenu comme une plume à écrire […], et la main [placée] très près de la poitrine du malade, afin de pouvoir s’assurer que l’instrument est bien appliqué ». Plus précisément, il serait appliqué « exactement et perpendiculairement », en évitant de trop presser sur la poitrine du malade qui pouvait rester habillé sauf de vêtements de laine et de soie à cause du bruit que leur froissement produisait contre l’instrument. La nouvelle technique éliminait les fâcheuses conséquences de la posture qui était celle du médecin appliquant son oreille sur la poitrine du malade ; outre qu’elle était malséante ou désagréable, elle portait le sang à la tête – ce qui « rend l’ouïe plus obtuse ». Elle ne commandait pas moins une certaine tenue du corps : « ne pas se mettre dans une position gênante, et ne pas trop baisser la tête, ou la renverser en arrière par une extension forcée du cou. Plutôt que de prendre ces positions, qui font porter le sang à la tête et nuisent en cela à la netteté de l’ouïe, il vaut mieux mettre un genou en terre ». De surcroît, une posture qui amènerait un effort soutenu de la tête ou du cou risquait de faire entendre au médecin le bruit de la contraction de ses propres muscles. Des conditions générales de silence devaient être réunies et le malade placé de façon telle qu’il ne créât pas, par sa position même, des bruits adventices. Selon Laennec, l’habitude d’appliquer le stéthoscope s’acquérait rapidement et, « au bout d’un ou deux mois d’exercice, l’oreille s’accoutum[ait] à distinguer au milieu des bruits qui lui arrivent à la fois, celui qu’elle cherche ». Restait alors à faire apprendre les signes obtenus par l’auscultation ; si certains s’apprenaient très vite – il suffisait de les entendre une fois – pour d’autres, c’était plus difficile. Laennec lui-même s’attacha à faire percevoir à ses élèves à Necker puis à la Charité « les distinctions des diverses nuances des râles crépitants, sec et humide, des phénomènes profonds et superficiels, de la bronchophonie diffuse ou non… ». L’exercice était la voie de l’acquisition, l’hôpital son lieu privilégié par le nombre et la diversité des cas qu’il rassemblait73.

L’auscultation se diffusa assez vite en France et à l’étranger, là où des structures hospitalières importantes permettaient d’acquérir une expertise auditive74. L’instrument connut de rapides perfectionnements, dont le stéthoscope biauriculaire (1851) : il fournissait un son de meilleure qualité ; portant le bruit aux deux oreilles, il permettait au médecin de s’abstraire du bruit ambiant et se concentrer sur le bruit qu’il recherchait ; puis, avec des branches appliquées aux oreilles, il libéra les mains du médecin. Après un peu de pratique afin de maîtriser le bourdonnement qu’il produisait, on l’utilisait sans plus y penser75. Ainsi, le stéthoscope se trouva en quelque sorte incorporé dans l’écoute des sons internes au corps humain.

Au moment où il entrait dans l’usage, un autre instrument, le microscope, commençait à être employé dans les sciences médicales. Introduction tardive, si l’on pense à l’usage que, depuis la seconde moitié du XVIIe siècle, des savants avaient fait de cet appareil76. Ce n’est que dans les années 1830 que des médecins parisiens commencèrent à utiliser le microscope pour leurs recherches, et ce à la suite de la diffusion de nouvelles idées médicales liées au développement de l’anatomie pathologique, ainsi qu’en conséquence des progrès techniques des appareils devenus, de surcroît, moins coûteux. Dans la décennie 1830-1840, une petite communauté de microscopistes se forma autour de quatre professeurs qui n’eurent jamais de poste à plein titre dans l’Université. Bénéficiant de la collaboration de médecins et de chirurgiens leur fournissant des spécimens, ils organisèrent pour des étudiants des cours publics et privés. À la fin des années 1850, ces professeurs avaient quitté Paris définitivement ou temporairement, et le nombre de cours de microscopie diminua. Il est vrai que désormais la microscopie était intégrée à des enseignements universitaires de pathologie et de physiologie, et qu’elle était acceptée, non sans débat, dans la recherche médicale.

L’introduction du microscope s’accompagna de publications décrivant l’appareil et ses possibilités, précisant aussi les compétences dont l’utilisateur devait faire preuve. Comme l’indiquait Alfred Donné, qui organisa un cours public à partir de 1837, on n’utilisait pas le microscope « comme on se sert d’une lorgnette de spectacle », et « il ne suffisait pas de regarder pour voir ». Il fallait apprendre. Des modalités d’enseignement furent mises au point. Ainsi, Donné avait équipé de vingt microscopes un cours privé qu’il instaura : au terme de la leçon, les étudiants allaient à tour de rôle voir les préparations exposées ; dans un enseignement complémentaire en petit effectif, ils apprenaient comment faire les préparations. Il leur revenait ensuite de s’exercer77. Des publications explicitèrent ce que l’apprentissage devait être, tel le Traité pratique du microscope que publia Louis Mandl, un médecin d’origine hongroise établi à Paris en 1836 et chargé à partir de 1846 d’un enseignement à la Faculté de médecine. Huit pages de « remarques générales » s’ouvraient sur un avertissement anthropologique : « ceux qui voudront faire usage du microscope devront être sains de corps et sains d’esprit » – une constitution faible étant susceptible de faire apparaître des images illusoires et une imagination vive de voir des merveilles partout. Suivait une série de recommandations, d’abord quant à la posture de l’observateur : « la tête ne doit pas être inclinée, ou dans une autre position forcée qui ferait monter le sang, et produirait conséquemment un obscurcissement de la vue ». Pour cela, la table serait réglée à une juste hauteur qui permettrait aussi d’appuyer les coudes pour éviter la fatigue lors de longues observations. L’exercice des yeux passait par s’accoutumer à regarder sans fermer un œil et observer indifféremment avec les deux yeux78. Un autre des pionniers de la microscopie médicale à Paris, le médecin allemand Hermann Lebert insistait à son tour sur une nécessaire éducation de l’œil et de la main, et il en montrait toute la valeur. Parmi bien d’autres remarques, on peut lire : « Ce qui distingue l’œil exercé, c’est de comprendre en voyant ». Ou encore, devant le nombre et la sophistication des instruments disponibles pour les préparations : « il faut que l’habileté soit dans les doigts et non dans les instruments de l’observateur ; cette habileté, du reste, ne s’improvise pas, et ne s’acquiert que par l’expérience79 ». Devenir microscopiste passait par une éducation de l’œil, de la main, une tenue du corps tout entier, et cet apprentissage fut alors jugé plus difficile que celui qu’impliquait le stéthoscope80.

Le regard a connu un champ d’exercice immense avec le développement prodigieux de l’imagerie biomédicale. Depuis l’invention de Röntgen (1895), les techniques en la matière se sont multipliées, diversifiées et spécialisées, les progrès déterminants datant des années 1970 avec l’irruption de l’informatique. Elles ont donné accès à des réalités auparavant inaccessibles et rendu l’homme vivant transparent81. L’historiographie qui a insisté sur ce point est passée sur l’étape première : la lecture des images. Un travail ethnographique fait en 1996-1997 dans un service de tomodensitométrie d’un hôpital universitaire américain n’en est que plus précieux82. Rappelons que cette technique utilise les rayons X pour réaliser des images en coupes millimétriques, voire inframillimétriques que le radiologue peut étudier dans tous les plans de l’espace et post-traiter. La lecture de ces images constitue une sous-discipline de la radiologie, dont elle diffère, entre autres, par la nécessité d’intégrer une succession de coupes en un volume.

La formation à l’hôpital associe un enseignement de petit effectif dans la salle de cours et un apprentissage personnel qui passe par la mémorisation d’un savoir codifié dans les livres, les atlas et les protocoles, et par l’examen d’un grand nombre d’images. L’enseignement comporte des conférences quotidiennes orchestrées autour d’images et portant sur un sujet ou sur un (ou des) cas. Dans la seconde formule, joue à plein une modalité interactive ; il arrive que le cas présenté soit choisi à dessein pour dérouter, que l’image soit modifiée, que le cadre clinique ne soit pas précisé, etc. Cet exercice, appelé hotseat, est en quelque sorte la version publique de l’enseignement reçu au négatoscope quand l’apprenti, tout aussi pressé de questions, doit dire ce qu’il voit et où il apprend ce qu’il doit voir ; le maître, lui, montre, pointe sur l’image ce qui doit être vu, parfois – modalité jugée supérieure – le marque au crayon gras. La lecture des images se fait suivant un processus ordonné et l’apprenti, dans un premier temps, récite des listes qui servent tant à mémoriser les opérations qu’à diriger le regard. Il est poussé à dire très précisément ce qu’il voit : une description verbale détaillée sert à affiner le regard, à lui donner acuité, précision et rapidité. Cet apprentissage de la lecture qui s’inscrit dans un processus didactique gradué, hautement sophistiqué et largement fondé sur la comparaison, passe par un travail rigoureux dont on n’a rappelé que quelques aspects. Une technique s’acquiert qui, par la suite, est invisible, tacite. La maîtrise se trouve, avec la part de l’expérience, parfois rapportée à un art. Reste qu’au-delà des croyances, qui ne sont pas sans importance, l’expertise du regard s’apprend dans un processus qui mêle enseignement et autodidaxie, qui, dans l’échange informel, fait aussi passer des méthodes et des principes, qui lie interactivement voir et savoir83.

De l’éducation du corps pour un usage professionnel, la chirurgie – étymologiquement « travail de la main » – offre un parfait exemple. On laissera de côté une approche sociologique situant une forme particulière de « l’usage des mains » sur l’échelle sociale du travail manuel84. Sans entrer ici dans un long historique, on rappellera que la chirurgie qui avait conquis ses lettres de noblesse au cours du XVIIIe siècle85, a connu une évolution majeure à la fin du XIXe siècle : les progrès des techniques d’anesthésie ainsi que la découverte de l’antisepsie et de l’asepsie ont non seulement permis des opérations jusqu’alors impossibles ou infructueuses86 mais encore profondément modifié le geste chirurgical. D’une chirurgie « virtuose » – celle qu’avait pratiquée Larrey sur les champs de bataille de l’Empire, désarticulant une épaule en moins de deux minutes – mais aussi « violente » et « sanglante », on passa progressivement à une chirurgie dite de la douceur. Ce terme revient fréquemment pour décrire l’art de faire de chirurgiens dès le tournant du XIXe siècle et il est au cœur d’une constellation sémantique qui lui associe très souvent lenteur et minutie87. Il est commun dans l’introduction de traités et manuels de chirurgie des années 1930 et suivantes. Ainsi, la préface générale de cette somme qu’est le Traité de technique chirurgicale (1942-1944), traçant une rapide esquisse de la transformation qu’avait connue la chirurgie, concluait : « L’acte opératoire qui gardait de ses origines lointaines certaines habitudes de rudesse et de rapidité s’astreignit aux disciplines de la douceur, de la patience et de la minutie. Le règne du chirurgien brillant était terminé ». L’auteur du tome I – Généralités –, revenant sur cette évolution, constatait tout à la fois « l’accroissement considérable » du domaine de la chirurgie et sa profonde mutation où « la douceur, la minutie, la précision rigoureuse des gestes supplantaient la brillante virtuosité du passé. La technique opératoire moderne était née88 ».

En conséquence, un nouveau mot d’ordre s’imposa : éducation. L’apprenti doit faire « l’éducation de sa main », « l’éducation de ses doigts ». La formule est fréquente ; on la trouve sous la plume de Farabeuf, aussi bien que sous celle de son rival et successeur à la faculté de médecine de Paris Paul Poirier89. Elle sert aussi à dire un temps de la formation, ce « dressage des mains à la douceur et à la minutie » dont François Jacob qui se destina d’abord à la chirurgie a fait état dans ses mémoires90. À la question « Naît-on chirurgien ou devient-on chirurgien ? », la seconde réponse s’impose désormais, du moins pour la masse des apprentis que l’on situe entre les 5 % à 10 % qui ont le geste inné et le même pourcentage des maladroits irrémédiables91. Une main, des doigts s’éduquent, et cette main et ces doigts longuement formés apportent des sensations, des informations. On n’entrera pas dans les modalités multiples et les détails nombreux d’un apprentissage du toucher et du maniement des instruments, portant à l’acquisition d’une dextérité qui se perfectionne dans l’exercice92.

Si « l’éducation de la main a la première place », comme Farabeuf l’écrivait, celle des yeux est tout aussi nécessaire. Et il insistait : « Regarder et toucher beaucoup, telle doit être la pratique éducatrice de l’amphithéâtre [sur le cadavre] car la pratique obligatoire de la clinique est de regarder tant qu’on peut et d’éclairer l’œil au besoin par un doigt exercé93 ». En fait, au-delà de la main et de l’œil, c’est tout le corps du chirurgien qui est éduqué, sa tenue, la position des bras, etc., avec des variations suivant la chirurgie pratiquée94. Il est jusqu’au pied qui intervient dans la commande de ces inventions qu’ont été au cours du XXe siècle le bistouri électrique ou le microscope opératoire, avec un geste qui « libère les mains95 ». De cette éducation du corps chirurgical, on ne donne ici qu’un aperçu ; il ne montre pas moins la mise en place de techniques garantes de l’efficacité des gestes. Gestes coordonnés entre eux et avec autrui – notamment avec l’aide qui a été présenté comme la « troisième et la quatrième main de l’opérateur96 ». Gestes qui, à terme, deviennent incorporés quand est acquis « cet automatisme […] qui laisse l’esprit libre pour conduire au mieux l’opération ou faire face à l’imprévu97 » ; dû à un pionnier de la chirurgie cardiaque, ce propos illustre on ne saurait mieux cette « éducation du sang-froid » dont parle Mauss comme résultat modèle d’une « technique d’adaptation du corps à son usage98 ».

Récemment, le « travail de la main » qu’est la chirurgie a subi une inflexion notable avec le développement de techniques mini-invasives99. Ainsi, la cœliochirurgie qui s’est développée à la fin des années 1980 permet d’accéder à la cavité abdominale en ne pratiquant que de minimes incisions. Le procédé est très schématiquement le suivant : du gaz carbonique est insufflé dans la cavité abdominale créant un espace opératoire entre la paroi et les viscères ; des trocarts sont introduits à travers la paroi ainsi soulevée, par lesquels passent une mini-caméra vidéo et des instruments que le chirurgien, placé près du patient, manie au cours de l’opération en visualisant sur un écran vidéo les images captées par la caméra. Cette technique, qui présente des avantages notables par rapport à « la chirurgie à ventre ouvert », a aussi ses difficultés. Le chirurgien est dans une position non ergonomique, debout, plus ou moins inclinée latéralement selon le type d’intervention ; regardant un écran placé à distance du champ opératoire, il perd la coordination œil-mains ; il doit inverser les mouvements pour réaliser le geste endocorporel ; les mouvements sont limités du fait de la rigidité des extrémités des instruments ; les tremblements naturels sont amplifiés à l’extrémité des instruments ; la vision sur l’écran est en 2D, et l’image n’est pas toujours des meilleures (buée, instabilité). Le chirurgien laparoscopiste a été présenté comme « un handicapé par rapport au chirurgien “ouvert”, puisqu’il n’a qu’une vision 2D (comme s’il ne travaillait qu’avec un seul œil), des instruments rigides (comme si ses poignets étaient ostéosynthésés) ». Un apprentissage jugé long et difficile permet de compenser ces « déficiences100 ».

À partir du début des années 2000, la « chirurgie à ventre fermé » a commencé à utiliser le robot, en fait un télémanipulateur commandé par le chirurgien. Depuis 2007, le robot Da Vinci est le seul disponible ; en 2013, plus de 2 500 Da Vinci avaient été installés dans le monde. On en donnera une description très sommaire, ici suffisante. Le robot comporte des bras télécommandés (d’abord trois, puis quatre) : un bras central portant l’endoscope avec deux caméras pour procurer une vision 3D, et deux (ou trois) bras portant les trocarts dans lesquels passent des instruments miniatures. Bras et instruments sont télécommandés par le chirurgien qui, assis à distance du patient à une console, voit sur un écran des images 3D (et aujourd’hui aussi de l’imagerie préopératoire) ; ses mains manipulent deux manettes commandant les extrémités des instruments ; à ses pieds, plusieurs pédales permettent divers réglages de la caméra et des instruments. Les instruments ont été, dans leur articulation, conçus sur le modèle du poignet humain – d’où le nom Endowrist – tout en leur donnant des possibilités supérieures. Une comparaison avec la cœliochirurgie classique tourne au profit de la robotique. Outre les avantages que procure l’instrumentation Endowrist, le chirurgien qui est dans une position confortable a une vision 3D ; l’axe yeux-mains est rétabli : « le regard du chirurgien est orienté vers ses mains […] il a l’impression de plonger dans le champ opératoire » ; les mouvements ne sont plus inversés : ceux qui sont réalisés à la console correspondent à ceux qui se produisent à l’intérieur du corps. D’où un transfert aisé de l’habileté acquise en chirurgie ouverte à l’approche mini-invasive qui permet grâce à l’interface informatique de réaliser des gestes plus fins101, gestes auxquels la main du chirurgien en robotique ne s’éduque pas moins102.



Des quelques situations de travail analysées dans ce chapitre, où angles de vue, chronologique et disciplinaire, ont été multipliés, il résulte que le corps est, dans l’ordre du savoir, une ressource non négligeable, voire essentielle, une ressource d’un grand, voire d’un très grand usage. Que ce soit pour des actes élémentaires ou pour des opérations hautement sophistiquées, il a bien, pour reprendre l’expression d’Otto Sibum, un « pouvoir productif », et l’on ajoutera : pas seulement dans la science de laboratoire.

Encore faut-il qu’il ait été dressé pour des usages spécialisés, qu’il ait appris à se tenir, que la main ait été formée à toucher et à sentir, l’œil à voir, l’oreille à entendre ; et l’on soulignera que le « regard géographique » qui prend le point de vue n’est pas le regard millimétriquement réglé du radiologue qui lit un scanner. Une éducation – on a noté l’insistance placée sur ce mot – est nécessaire, et les apprentissages, quels qu’ils soient, ne sont ni immédiats ni aisés quand ils ne sont pas longs et difficiles. Sont ainsi acquises des techniques du corps, parfois d’une grande sophistication. Le mot bricolage que l’on trouve employé par des anthropologues des savoirs ne vaudrait ici qu’accompagné de l’adjectif expert. De surcroît, dans les cas que nous avons étudiés, il n’est pas aisé de tracer une ligne de partage nette entre savoir-faire et savoir. L’excursion géographique que promut Vidal de la Blache était à la fois formation d’un regard et inculcation de connaissances disciplinaires ; l’étudiant qui feuilletait les portefeuilles d’images de l’Institut d’art de Lille apprenait à regarder tout en acquérant des bases érudites dans sa discipline.

Cette éducation du corps porte en soi aux antipodes du don ; une « habileté », un coup d’œil, un tour de main ne seraient que le couronnement de l’apprentissage. Pensons à l’exégèse qu’Hyppolite Bernheim faisait de la notion de « flair médical » ; quant à son aphorisme « on ne naît pas médecin, on le devient », non seulement il ne prendrait aujourd’hui que plus de vérité alors que la médecine s’est depuis les années 1870 hautement technologisée, mais il est susceptible d’applications dans d’autres domaines.

Tout cela se trouve comme en résumé dans un propos de Raymond Chevallier, latiniste et archéologue, qui donna dans les années 1960-1970 à l’École pratique des hautes études un enseignement de topographie et de photo-interprétation. Lire des photographies aériennes n’allait pas de soi ; la photo-interprétation était « un outil » qu’il fallait apprendre à maîtriser. Le photo-interprète devait unir des aptitudes physiques (une acuité visuelle et une bonne résistance à la fatigue oculaire), des qualités de patience, de jugement et d’imagination, de solides connaissances professionnelles dans une ou plusieurs disciplines ainsi qu’une forte culture générale ; il lui fallait se livrer à un « grand entraînement à l’examen des photographies […], voir de nombreux documents et dans tous les ordres de disciplines et par de multiples comparaisons entre les aspects au sol et les apparences aériennes à différentes échelles pour “se faire l’œil” et élargir ses idées. À un certain degré, l’interprétation devient question de réflexe ou d’intuition ; mais ce stade est acquis, non donné103 ».

Au terme de ce chapitre, on reviendra à Marcel Mauss et à une citation qu’il fit de Maurice Halbwachs : « l’homme est un animal qui pense avec ses doigts104 », interprétant ainsi le texte d’Aristote : « ce n’est pas parce qu’il a des mains que l’homme est le plus intelligent des êtres, mais c’est parce qu’il est le plus intelligent des êtres qu’il a des mains105. » Ce texte a été abondamment glosé, et la main a été présentée comme « pensante106 ». C’est ce qui ressort très simplement du texte d’Henri Mondor sur la palpation : « les deux mains douces, intelligemment dirigées, adroites », celles du médecin qui sait palper, progressant « à la recherche d’une vérité si grave et parvenant à la découvrir, à force de patiente exploration et de talent tactile107 ». Ce geste efficace que décrit Mondor révèle encore, avec la douceur des mains, la dimension sensible qui est aussi celle du corps, outil intellectuel. On ne la négligera pas.


DEUXIÈME PARTIE.


UN ORDRE MIXTE




* * *





* * *





Introduction




* * *





On ne prête guère d’attention au curseur qui s’affiche sur l’écran de l’ordinateur, tant ce signe est devenu banal. On ne s’arrête pas davantage à ses changements d’apparence en fonction des situations : quand cette flèche, ordinairement inclinée vers la gauche, se transforme, en passant sur un lien hypertexte, en une petite main dont tous les doigts sont repliés sauf l’index qui pointe sur le lien ; ou, quand passant sur un élément qui peut être déplacé, par exemple, dans une feuille de calcul, elle devient une petite main ouverte, tous les doigts tendus, puis se change en une main fermée comme saisissant ledit élément. Cette petite main numérique est la descendante de la manicule, signe en forme de main à l’index pointé, qui, dans les manuscrits médiévaux, associait dans la page une annotation et le passage que celle-ci commentait. L’imprimerie ne l’a pas fait disparaître : des publications imprimées en contiennent et des lecteurs, pour marquer leurs propres lectures, en ont tracé tant dans leurs manuscrits – à l’instar de Malpighi dans son « journal » – que dans les livres qu’ils lisaient, parfois indépendamment de celles que l’imprimeur avait placées. La fonction la plus courante de la manicule serait, d’après W. H. Sherman qui en a retracé l’histoire, de signaler un passage pour autrui ou pour soi. De fait, Martin Dominique Fertel notait dans sa Science pratique de l’imprimerie (1723) : « les mains signifient qu’on doit faire attention aux choses devant lesquelles elles sont posées. » À cette date, leur emploi aurait commencé à décliner ; il est revenu, massivement, avec la nouvelle technologie de l’informatique1. Ces petites mains, hier dans les manuscrits et les livres, aujourd’hui dans les documents numériques, sont comme le symbole de cette deuxième partie qui porte sur l’ordre mixte du savoir.

Les inventaires, sommaire et raisonné, qui ont été dressés montrent la masse considérable de l’outillage dont les savants ont disposé entre XVIe et XXIe siècle. Tout au long de cette période, on a vu des outils s’inventer, se démultiplier, se perfectionner, se régler ; on a aussi pris la mesure de leur sophistication, souvent plus grande qu’il ne semble – pensons à la fiche – et, en conséquence, de la nécessité pour leur bon maniement d’un apprentissage, même minime. Encore à ces ressources s’ajoutent celles, considérables par leur nombre et leur valeur, que les savants tirent de leur corps dont « le pouvoir productif » est d’autant plus grand qu’il a été éduqué à des usages. À ce point, on n’apprécierait que mieux la justesse des étiquettes usuelles culture ou civilisation du geste, de l’écrit, de l’imprimé, de l’image, du numérique ; on renchérirait même.

Toutefois, l’observation du travail scientifique amène à une conclusion autre. Elle montre un usage conjoint d’outils de nature diverse, ceux que l’on a vus dans le capharnaüm des bureaux. Ces outils, d’ailleurs, intègrent, pour nombre d’entre eux, des éléments d’ordre différent : pour donner un exemple simple et rapide, ces images que sont les graphiques portent un titre, des légendes, des données numériques sans lesquels ils seraient inintelligibles. De sorte que les catégories susdites volent en éclats ou plutôt se mêlent ou mieux se subsument en une autre que l’on qualifiera de composite. Ces remarques sont au cœur du chapitre 4. Prenant pour objet des outils usuels de la vie scientifique, il explorera une multimodalité faite d’addition ou de juxtaposition, mais aussi de combinaison ou d’interaction.

La manicule qui, dans un document désigne un élément et le saisit, rappelle le corps à l’œuvre dans le travail intellectuel. Elle invite à prendre en compte la dimension sensible qui est aussi celle de l’ordre matériel du savoir, à explorer le sensorium de la culture savante. Ce sera l’objet du chapitre 5 qui, centré sur les discours de la pratique, sur les expériences des usagers, examinera le rôle que ceux-ci ont dévolu aux sens dans des opérations de production et de communication des connaissances, les atouts qu’ils leur ont reconnus, les limites qu’ils y ont vues.

À considérer les multiples éléments de nature fort diverse qui entrent en composition, on mesurera la complexité extrême de l’ordre du savoir. Ce qui n’est pas sans expliquer routines, conservatismes et réticences devant la nouveauté ; ce qui, dans le même temps, porte à redimensionner l’amplitude et la radicalité des révolutions technologiques.





* * *



1. William H. Sherman, Used Books : Marking Readers in Renaissance England, Philadelphia, University of Pennsylvania Press, 2008 ; Alain Cariou, « Manicule », dans Pascal Fouché et al. (dir.), Dictionnaire encyclopédique du livre, Paris, Éditions du Cercle de la librairie, 2005, p. 856 (cit.) ; Domenico Bertoloni Meli, « The Archive and Consulti of Marcello Malpighi : some preliminary reflections », dans Michael Hunter (éd.), Archives of the Scientific Revolution : the Formation and Exchange of Ideas in Seventeenth-Century Europe, Woodbridge, Boydell Press, 1998, p. 111.





CHAPITRE 4


Un règne composite




* * *





On lit dans le Trésor de la langue française au mot composite la définition suivante : « A. Architecture. [En parlant d’un ordre d’architecture] Qui est composé d’éléments de l’ordre corinthien et de l’ordre ionique […]. Par analogie, autres emplois techniques. Caractérisé par l’hétérogénéité des éléments d’un tout. Souvent synonyme de composé. B. Par extension. Un arrangement, un ensemble, un milieu composite ; le caractère, la structure composite de quelque chose. Synonymes : disparate, hétérogène, mélangé, mêlé, bigarré, hybride. »

Ces adjectifs s’appliquent à bien des outils que l’on a inventoriés. Ceux-ci ont été rapportés, comme il l’est fait usuellement, à une technologie donnée. Toutefois, à y regarder de près, ils sont souvent moins « purs » qu’il ne semble. À une technologie dominante, elle-même intégrant parfois des éléments divers, ils en mêlent une autre, voire plusieurs autres, suivant des combinaisons variables en nature et en proportion, quand ils n’impliquent pas, pour leur parfaite efficience, l’addition d’une autre technologie. Prenons des notes de cours. Les cahiers d’étudiants de l’université de Louvain au XVIe siècle intégraient à la copie manuscrite des éléments graphiques faits a posteriori pour les titres et initiales ; ces repères étaient parfois tracés dans des couleurs et des caractères différents de ceux du texte comme pour bien remplir leur fonction, quand ils n’étaient pas l’objet d’un travail quasi pictural. Dans certaines matières – physique et logique –, l’étudiant accompagnait le texte de dessins qui facilitaient la compréhension : carré logique en philosophie, schémas visualisant l’action de forces en physique, figures anatomiques. À la fin du XVIIe siècle, des planches gravées, ornementales ou scientifiques, remplacèrent les dessins tracés par les étudiants ; ceux-ci les achetaient auprès des libraires-imprimeurs et les inséraient dans leurs cahiers1. Ainsi, des écritures de divers types, des dessins faits par les étudiants, des images de provenance extérieure étaient assemblés en un tout interactif et performatif : plusieurs éléments de nature et d’ordre différents servaient et servaient ensemble dans l’apprentissage des connaissances. Tout aussi composites peuvent être les notes du maître, à l’instar de celles que Jules Quicherat utilisa dans son enseignement d’archéologie médiévale à l’École des chartes à partir de 1847. Il s’appuyait sur un cours rédigé, écrit à l’encre brune avec, à l’encre rouge, des passages de rédaction particulièrement soignée et, de temps en temps, les capitales DEV pour un développement oral. Les notes étaient portées sur des feuilles doubles 27 × 28 formant des chemises, à l’intérieur desquelles se trouvaient des dessins, des calques, des citations, des notes complémentaires, parfois même de petits dossiers sur des questions d’onomastique ou d’étymologie, ainsi que des éléments de provenance externe avec des gravures découpées dans des périodiques ; bref, il y avait dans les chemises le matériel divers qui avait servi à l’élaboration du cours écrit mais qui était aussi à la base des développements que Quicherat prévoyait de faire et des dessins que, tout en parlant, il tracerait au tableau2.

L’usage conjoint de techniques en une même entité que montre cet exemple rapide sera exploré à partir de trois outils : le livre, le cahier de laboratoire, le poster. Ils ont été choisis comme référant à des modalités diverses dans les activités du monde savant : lire, écrire, parler. Les développements seront résolument descriptifs afin de faire ressortir le caractère multimédia de ces produits qui n’ont généralement pas été approchés sous cet aspect-là. Des aperçus historiques seront donnés pour montrer comment des composants hétérogènes se sont sédimentés en des touts homogènes. La description externe sera appréciée en y rapportant les raisons que les usagers ont fournies quand ils ont présenté un outil dans son emploi ou ont prescrit des aménagements. Realia et discours permettront de définir un ensemble, un règne, pourrait-on dire à la manière des naturalistes, qui a son principe commun dans la notion de composite.





Le livre : texte et images


Des images sont entrées très tôt dans les livres imprimés et y ont pris une place « naturelle ». Elles sont d’une grande variété que l’on considère leurs techniques de production et de reproduction ou leur nature, de la planche de zoologie à la photo aérienne en passant par la représentation graphique ou tabulaire, sans compter que des figures d’ordre divers peuvent se trouver dans un même ouvrage. Le livre scientifique est le plus souvent un ouvrage dit illustré.

Rares sont les savants qui ont expressément marginalisé ou refusé les images. Robert Boyle dans sa Continuation of New Experiments concerning Respiration (1670) jugeait que les gens qui sont « versés dans ce genre d’étude ou ont une grande facilité d’imagination concevraient assez bien ma pensée par des mots » ; ils n’avaient pas besoin d’images, qui étaient « pour les autres ». De façon générale, il a été noté que dans les ouvrages de Boyle les images sont peu nombreuses mais alors riches de détails3. Linné utilisa bien des illustrations contenues dans la littérature botanique antérieure pour l’élaboration de son système ; mais celui-ci l’amena si ce n’est à une totale exclusion de l’image, à sa dévaluation cognitive – elle « n’offrait quelque chose qu’aux ignorants4 ». Bichat dans son Anatomie descriptive (1801) marqua son opposition aux planches, « moyen illusoire » n’offrant « les objets que sous un seul point de vue. Il faut ou les multiplier dispendieusement ou se borner à des connaissances incomplètes ». Après avoir développé ces arguments, il concluait son réquisitoire ainsi : « Ajoutez à cela l’inconvénient de ne pas tout embrasser du même coup d’œil, de ne se former que des idées isolées, de n’étudier, pour ainsi dire, un organe que par parties, et vous verrez que les planches ne sont que des monuments de luxe où de brillants dehors cachent un vide réel. » Une véritable connaissance de l’anatomie s’acquérait sur le cadavre5. Le chirurgien Pierre Jourdan, désireux de rompre avec « le langage assez enfantin des images » qu’il voyait proliférer, donna en 1953 un ouvrage volontairement sans images pour publier une nouvelle technique opératoire. Il s’était « précisément efforcé d’écrire un texte qui n’ait besoin d’aucune image pour être compris et que nulle suite d’images ne puisse remplacer », d’autant qu’il y avait « trop de précisions, trop de détails, voire même de subtilités pour qu’une série de planches soit apte à les traduire ». Son « long discours » ne fut pas sans effet ni succès : la technique qu’il promouvait fut adoptée ; partout dans le monde des chirurgiens se mirent à faire « un Jourdan6 ».

Ces quelques opinions ne soulignent que mieux le point de vue inverse qui est dominant. Il se traduit concrètement par un recours important à l’image comme l’atteste le nombre croissant des figures dans les articles scientifiques7. Il reconnaît à l’image un statut de document riche de contenu, donc bien autre que d’illustration8. Ainsi, le livre scientifique est très généralement un produit mixte fait de texte et d’image, plus exactement de documents relevant de deux ordres différents – textuel et iconographique. Reste à voir comment.

La question n’est pas ici d’esthétique du livre, d’objectivité de l’image ou de stratégie de l’illustration, aspects d’ailleurs bien étudiés. Elle porte sur les modalités que des auteurs ont mises en place pour solidariser texte et image ou vice-versa, pour construire des liens entre des éléments hétérogènes : ce qui amène à analyser les raisons qu’ils ont données à cet aspect de la composition matérielle de leurs livres. Les évolutions technologiques ne furent pas ici sans incidence, à commencer par le passage de la gravure sur bois à la gravure sur cuivre. Celle-ci qui, associée à la technique de la taille-douce, permet d’obtenir un trait d’une plus grande finesse s’est trouvée privilégiée dans l’illustration scientifique à partir du XVIIe siècle. Ce procédé qui nécessitait une presse et une encre différentes a entraîné la disjonction, et pour longtemps, du texte et de l’image. En conséquence, les planches ont été reliées séparément, ou regroupées à la fin du volume, ou insérées plus ou moins heureusement dans le corps de l’ouvrage. Une solution bien peu économique a été de monter les planches en dépliants de sorte que le lecteur puisse avoir sous les yeux la gravure correspondant au texte9.

Un exemple analysé sur le long terme par Edward Tufte permet de prendre la mesure de la question : l’Opticks (1704) de Newton. À la différence des Principia (1687) où les nombreux schémas – des gravures sur bois – étaient intégrés dans la page au fil des démonstrations, voire à l’occasion répétés, et ce suivant les mots de l’auteur comme chose « beaucoup plus commode pour le lecteur », les 55 figures dessinées par Newton furent gravées sur 12 planches qui furent insérées à quatre endroits de l’ouvrage en dépliants. Alors que chaque planche portait plusieurs figures, le renvoi texte-image enchaînait plusieurs éléments – par exemple, « Book 1. Part II. Plate IV. Fig. 16 » ; la tâche du lecteur n’aurait pas été trop ardue s’il n’avait été affronté à la masse des références alphabétiques – 6 300 dans les 80 pages du premier livre – renvoyant dans le texte à des parties de telle ou telle figure. Lire, et comprendre, l’Opticks amenait à des allers-retours continuels entre « un livre de mots » et « quatre livrets parallèles d’illustrations », outre le fait que le lecteur devait replier un dépliant pour en voir un autre. Mots, chiffres et images n’allaient plus ensemble. C’est à la fin du XIXe siècle seulement dans l’édition de 1898 que grâce à la lithographie texte et image furent intégrés. Cette unité fut mise à mal dans l’édition de Bruxelles, 1996 : les planches sont bien placées dans le texte même, au plus près des développements qui s’y rapportent, mais elles ne sont plus en dépliants de sorte que, dès que l’on tourne la page, on ne peut plus voir ensemble texte et figure. Le numérique marque une régression ; une édition électronique de 1998 fige l’édition originale qu’elle reproduit : le lecteur ne peut plus déplier les dépliants en parallèle à la lecture du texte10.

L’histoire éditoriale de l’Opticks montre la difficulté qu’il y a à lier ensemble texte et images. Quelques ouvrages, pris entre les XVIIIe et XXe siècles, permettront de voir comment des auteurs ont essayé de surmonter des obstacles technologiques et physiques (la matérialité même du livre) afin de construire un outil bimodal des plus efficaces ; la diversification de l’image au fil du temps compliqua le problème.

Le premier exemple est celui d’un ouvrage des plus fameux et des plus étudiés : l’Encyclopédie de d’Alembert et Diderot. Dans le Prospectus écrit par Diderot et paru en octobre 1750, il était annoncé, outre les huit volumes de discours, au moins 600 planches qui seraient regroupées en deux volumes. Le « besoin de figures » pour rendre compte des arts y était justifié. « Le peu d’habitude qu’on a et d’écrire et de lire des écrits sur les arts rend les choses difficiles à expliquer d’une manière intelligible […] un Dictionnaire pur et simple de langue, quelque bien qu’il soit fait, ne peut se passer de figures, sans tomber dans des définitions obscures ou vagues ». Et Diderot de préciser : « Un coup d’œil sur l’objet ou sur sa représentation en dit plus qu’une page de discours. » Des dessinateurs avaient été envoyés dans les ateliers pour reproduire des machines et le travail des ouvriers. « Un juste milieu » avait été observé. « Nous nous en sommes tenus aux circonstances essentielles, à celles dont la représentation, quand elle est bien faite, entraîne nécessairement la connaissance de celles qu’on ne voit pas ». Les mêmes principes avaient été suivis pour les planches relatives aux sciences. La mise en page prévue pour les deux volumes de planches visait à faciliter la lecture d’images dont la valeur cognitive était grande – supérieure à la description, voire permettant de saisir ce qui ne se voit pas –, en plaçant « au verso d’une planche l’explication de celle qui sera vis-à-vis, avec des renvois aux endroits du Dictionnaire auxquels chaque figure sera relative11 ».

Cette solution fut vite abandonnée, comme il ressort de la conclusion de l’article Anatomie du tome I publié en 1751 : « Il ne nous reste plus pour achever cet article & offrir en même temps au lecteur un traité d’Anatomie aussi complet qu’il puisse le désirer, que d’ajouter ici l’explication de nos planches. Cette explication, formant proprement l’Anatomie, serait trop étendue pour pouvoir être placée vis-à-vis de nos figures ; & nous ne lui trouverons aucun lieu plus convenable que celui-ci12. » Et le texte se poursuivait : « Planche première. Fig. 1. de Vésale, représente le squelette vu en devant : a L’os du front, ou le coronal. b la suture coronale. c le pariétal gauche. d la suture écailleuse. e f g l’os temporal. f l’apophyse mastoïde… », etc. Alors que le premier volume de planches ne parut qu’en 1762, restait au lecteur à imaginer les réalités anatomiques indiquées ou à se reporter à d’autres ouvrages d’où des planches avaient été tirées – les lettres de rappel n’avaient alors plus de sens. L’historiographie, pourtant prolixe sur l’Encyclopédie et ses planches, ne dit rien sur la « stratégie » du lecteur de l’article Anatomie avant 1762. Dans le recueil qui parut alors, les planches d’anatomie, qui auraient été augmentées d’un tiers, étaient précédées de vingt et une pages d’explication. Texte et image étaient bien réunis dans un même volume, mais sans la facilité de lecture promise dans le Prospectus : le lecteur était contraint à des allers-retours fastidieux entre planches et explications. Il avait, il est vrai, la possibilité pour les planches d’anatomie décrites aussi dans le volume de 1751 d’ouvrir deux in-folio devant lui : ce n’était pas le gage d’une lecture commode sans compter que des planches publiées en 1762 ne coïncidaient plus totalement avec la description initiale ; enfin, restaient les cas où il n’y avait pas de correspondance entre les images et leurs descriptions ni dans le volume de discours ni dans le recueil de planches13. L’Encyclopédie, telle qu’elle fut publiée, se trouva donc composée de volumes de discours et de recueils de planches : la circulation entre verbe et image n’était pas aussi aisée qu’il l’avait été prévu, quand elle n’était pas inexistante. À peine aujourd’hui, les éléments textuel et iconographique peuvent être saisis d’un seul regard ; et encore n’est-ce que partiellement. Aucune des éditions électroniques ne permet d’aller des articles aux planches et vice-versa ; toutefois, celle de Chicago donne la possibilité de voir enfin ensemble une planche du recueil suivie de son explication14 ; toutefois, cette possibilité diminue quand la description étant longue (par exemple, pour Anatomie, les pl. VI, VII, X), le défilement vertical du texte sur l’écran amène sa dissociation progressive avec l’image.

Louis Hubert Farabeuf fut, on l’a vu, un professeur de talent, multipliant les moyens pour transmettre à ses élèves sa science de l’anatomie, enseignant, comme il l’a lui-même écrit, « par la parole, le scalpel, la plume et le crayon15 ». Formule qui réfère à ses cours, à ses démonstrations sur le cadavre, aux dessins au tableau qu’il faisait pendant ses leçons, à ses « cent très grandes planches murales » placardées à l’École pratique de chirurgie et, enfin, à ses publications. Son ouvrage majeur, sur lequel se sont formées des générations de chirurgiens, est le Précis de manuel opératoire, manuel signifiant ici technique ; la première section correspondant aux ligatures parut en 1872, et le Précis connut plusieurs éditions avec des révisions et des augmentations jusqu’en 1939, la dernière publiée du vivant de l’auteur datant de 1905.

Farabeuf soulignait d’emblée la prééminence de l’enseignement « pratique et mimique de l’atelier » sur « l’enseignement écrit » ; celui-ci n’en était pas moins utile : « la tradition peut se perdre si on ne la couche sur le papier. » Son ouvrage qui « venait en aide à l’enseignement » et qui se voulait « un guide clair et précis […] ouvert sous les yeux de l’élève » revendiquait une « forme toute nouvelle » : des « descriptions imprimées en gros caractères afin que l’élève saisisse vite l’ensemble de l’opération », précédées et suivies « de notes en petit texte, tant sur l’anatomie que sur certaines opérations et manœuvres opératoires ». La partie iconographique était son œuvre quant aux dessins – « la gravure ne les a toujours pas améliorés16 » ! Ces figures avaient été placées dans le texte aux endroits correspondants et elles étaient munies de légendes fournies reprenant l’essentiel du texte en une rédaction télégraphique. Au besoin, afin que le lecteur comprît parfaitement un geste, un détail essentiel était représenté séparément dans le dessin ; ainsi, la fig. 140 « compression de l’artère fémorale sur le pubis » était assortie d’un petit dessin montrant « dd le doigt index croisant l’artère aa et l’os pubis oo », soit dans le texte comment « le dos des deux dernières phalanges de l’index [devait être] appliqué de manière à croiser à angle aigu à la fois la direction de l’artère et celle du pubis sur lesquelles elles sont à cheval17 ». Les figures furent augmentées au fil des éditions : la page de titre de celle de 1881 annonçait 403 figures dans le texte, celle de 1893, 532. Le but resta toujours celui qui avait été énoncé dès la préface de 1872 : non « figurer le résultat d’une opération », mais représenter « les principales manœuvres indiquées dans le texte » afin que le lecteur pût les reproduire.

Dans l’édition de 1905, Farabeuf revenait sur ces différents points de l’enseignement par le livre et de l’iconographie, précisant le lien entre texte et image, tel qu’il avait voulu l’établir. La supériorité du maître qui parle et montre ne faisait pas de doute ; le livre n’en avait pas moins sa raison d’être en raison de sa permanence ; encore devait-il répondre à une certaine composition. Farabeuf rappelait le choix typographique fait pour le texte : « des descriptions […] courtes, rapides, continues et imprimées en gros caractères afin que l’élève opérateur pût les lire en les tenant sous les yeux, sur la table même où il s’exerce. » Les figures se voulaient « démonstratives des attitudes à prendre, point capital » ; d’où le parti adopté : « montrer autant que possible des mains en action », mains désormais placées dans le discours et entourées des mots du texte et de la légende écrite en phrases plus brèves18.

Dans le dernier livre qu’il publia, un ouvrage de recherche, Les Vaisseaux sanguins des organes génito-urinaires du périnée et du pelvis. Amplification de la thèse du Dr Léon Cerf (Paris, Masson, 1905), il intégra plus fortement encore texte et image. Dans cette publication, il reprenait la thèse d’un de ses élèves (1895), elle-même étant « le produit de notes prises au cours de M. Farabeuf, et rédigées avec le secours des documents écrits et dessinés du professeur ». Il avait augmenté ce travail par de nouvelles recherches et y avait ajouté trente-trois figures inédites « toutes établies à l’aide de multiples croquis relevés [par moi] sur la nature ». À leur endroit, il avait eu pour but principal « de les faire démonstratives et claires sans les rendre inexactes, et de les expliquer en des légendes très développées ». De fait, chaque figure qui porte un titre est accompagnée d’une légende qui reprend des éléments du texte ou les détaille : elle est placée sous l’image ou, fréquemment, quand elle est très longue, en face. D’où une mise en page qui vise non à l’élégance mais à l’utile. « L’image prime le texte dans l’enseignement des sciences objectives, énonçait Farabeuf. C’est pour cela que je n’ai pas craint de rompre celui-ci, de laisser des pages vides, d’imprimer toutes les figures sur dos blanc, afin qu’elles ne soient pas obscurcies par le foulage des caractères19. » Je ne sais si cette solution fit des émules. Reste qu’elle inviterait à pousser la recherche dans le livre médical dont on ne peut plus dire, après avoir lu Farabeuf, qu’il est « illustré ».

Les thèses de science soutenues en France dans les années 1880-1910 montrent les efforts des candidats pour lier texte et image, une image nombreuse et diverse. Ces travaux sont alors imprimés et contiennent pour 70 % de l’illustration (photos, dessins, graphiques), la part étant plus ou moins grande suivant les disciplines. La structuration usuelle dans les années 1880 est un texte suivi de planches hors texte dont la compréhension est parfois facilitée par des figures schématiques placées dans le texte, l’usage se répandant progressivement de placer des figures dans le texte, sans toutefois faire disparaître les planches hors texte. Un renvoi quasi systématique du texte vers l’image est fait. Le rapport entre les deux est renforcé par le déplacement des légendes : initialement regroupées en un bloc de pages placé entre la fin du texte et le début des planches, elles sont, dans les années 1890, imprimées sur des pages intercalées entre chaque planche et lui faisant face, avant de s’intégrer parfois à la planche. Ceci vaut tant pour les dessins que pour les photos, le texte des légendes étant plus descriptif pour les secondes alors qu’il faut guider l’œil du lecteur dans des éléments enchevêtrés. Avec cette nouvelle composition, le lecteur voit sa tâche simplifiée : il n’a plus à considérer trois pages (texte et renvoi vers la planche, la planche, la page de légendes), mais deux et, s’il s’en tient à l’image et à la légende, il a le tout devant les yeux. Les rapporteurs, premiers lecteurs, ont noté cette évolution avec satisfaction20.

On a mentionné cet outil textuel ou paratextuel que sont les légendes. Elles introduisent un élément supplémentaire de complexité d’autant qu’elles ne sont pas dans un rapport univoque de relation à l’image comme il ressort de l’exemple suivant : le Traité de zoologie : anatomie, systématique, biologie dirigé par le Pr Pierre-Paul Grassé, un éminent zoologiste qui promut des méthodes expérimentales de recherche. Cette publication monumentale – 47 fascicules ont été publiés entre 1948 et 1999 (principalement dans les années 1950-1970) – est au XXe siècle la seule tentative aboutie, moins un fascicule, d’un traité exhaustif en la matière. Ses 44 500 pages furent accompagnées de plus de 28 000 figures (outre des tableaux et planches hors-texte). Cette somme fut, typographiquement parlant, fabriquée de façon traditionnelle dans une collaboration étroite entre directeur-auteurs (il y en eut plus de trois cents pour des contributions de longueur inégale)-dessinateurs (avec leurs spécialités)-imprimeur.

L’illustration fut, dans son élaboration, une affaire complexe tant par son volume que par sa nature. Elle est de deux types. Le premier, de zoologie systématique (apparence extérieure des animaux) et d’anatomie (figuration des divers organes du corps tels qu’ils apparaissent à la dissection), consista principalement en des dessins au trait, technique ayant l’avantage sur la photo de permettre la mise en relief des éléments les plus discriminants et de minimiser le recours à la description. Le second type d’illustration, ressortissant lui à l’expérimentation (l’objet étudié ayant été soumis à des traitements physiques ou biochimiques afin d’en révéler des caractères observables au moyen d’instruments de plus en plus sophistiqués), est représenté par des photos noir et blanc fournies par la microscopie optique et électronique (dont l’importance croît dans la dernière décennie de la publication) ; il correspond à des résultats de biologie expérimentale et il apparaît comme une preuve de l’énoncé verbal, un aménagement visuel au moyen de flèches attirant l’attention sur ce qu’il faut voir. Une légende accompagne chaque figure (ou ensemble de figures – 4 au maximum) : dans le premier cas, elle se compose d’une série de désignations nominales développant les abréviations (lettre ou ensemble de lettres placées au bout des filets de rappel) ; dans le second, elle consiste en un commentaire détaillé décrivant l’image, énoncé qui, fait de phrases, est de même statut linguistique que le texte de l’ouvrage. Un spécialiste peut lire à vue le premier type de figure sans recourir à la légende ; il ne le peut pas dans le second.

Dans la fabrication de l’ouvrage, ce n’est qu’en fin du processus que s’opéra l’ancrage de la figure dans le texte. Prenons le volume consacré aux muscles des mammifères. Le choix de l’emplacement de la figure n’était pas toujours simple alors qu’une figure pouvait comporter plus d’une cinquantaine de muscles et qu’un muscle traité en un groupe de pages limité pouvait être figuré dans un très grand nombre d’illustrations. Le choix éditorial fut celui de la plus grande cohérence ainsi que d’une égale répartition tout au long des volumes. Par la force des choses, figures et texte se trouvèrent disjoints. D’où la mise en place de références croisées : du texte vers les figures par des renvois entre parenthèses ; des figures vers le texte via l’index. Le Traité de zoologie avait été conçu par le Pr Grassé comme une encyclopédie iconographique autant que textuelle, et il le fut : par la masse des figures et les milliers de pages de texte qu’il contient, ainsi que par les liens réciproques qui furent établis entre des éléments relevant non seulement de techniques diverses mais, possédant chacun, une variété de statuts cognitifs21.

L’archéologie est, sans nul doute, une science visuelle ; déjà les antiquaires des XVIIe et XVIIIe siècles publiaient dans leurs ouvrages des gravures des « monuments » qu’ils commentaient. La discipline a fait un usage précoce de la photo, sans pour autant jamais renoncer au dessin ni à aucune autre technique22, de sorte que, plus on avance dans le temps, plus de sortes d’images sont produites. Les publications d’Antoine Poidebard montrent comment des figures de nature diverse furent combinées. Ce père jésuite de l’université Saint-Joseph de Beyrouth avait été chargé, en raison de sa compétence d’aviateur, de rechercher les points d’eau et canalisations perdus de Haute-Syrie ; en 1925, lors de ses vols au-dessus du désert syrien, il découvrit, grâce aux ombres portées au sol par la lumière rasante, d’infimes reliefs qui révélaient des ruines enfouies. Il les photographia, fondant ainsi l’archéologie aérienne à laquelle il consacra, outre des écrits de vulgarisation, plusieurs ouvrages et articles scientifiques. Les photos sont ici non des illustrations mais des objets d’étude et des outils de travail mis à disposition des chercheurs. D’où un soin particulier dans la qualité de la reproduction, le choix du format, la mise en page, la légende. Discours écrit et visuel se complètent tout comme des images d’ordre divers, cartes, relevés et photographies qui dans la publication « se succèdent suivant un ordre défini, photographie d’abord, puis plan, jusqu’à se superposer ou presque, les légendes renvoyant d’une image à l’autre ». Cette présentation nouvelle fut très appréciée tant elle contrastait heureusement avec l’usage existant. Ce que notait un recenseur du premier grand livre du père Poidebard, La Trace de Rome dans le désert de Syrie. Le limes de Trajan à la conquête arabe. Recherches aériennes, 1925-1932 (1934) : « Jusqu’ici, l’archéologue ne disposait que des ressources distinctes de son intelligence ou de son œil ; plan d’un côté, photographies de l’autre se présentent comme deux réalités séparées entre lesquelles le lecteur fait effort pour établir un lien : l’un est net, mais d’un schématisme trop intellectuel, les autres sont vivantes, mais découvrent mal la logique de leur disposition ; comme il est souvent malaisé de raccorder une ruine à son plan abstrait23. »

Le développement des fouilles programmées et préventives, l’intérêt accordé aux vestiges les plus humbles ont amené une croissance considérable du matériel collecté, par exemple de la vaisselle céramique. D’où la nécessité aussi de mettre une masse d’objets à la disposition de la communauté des chercheurs en en donnant des représentations permettant la comparaison. Ces questions qui ont été au cœur de réflexions menées dans les années 1970 ont amené à considérer les publications qui étaient faites. L’illustration était mal utilisée ; elle était parfois fautive ; et son lien avec le texte, avec le raisonnement développé, était ténu : « [elle] se borne dans le meilleur des cas à doubler les descriptions qu’il renferme, alors qu’elle devrait permettre de comprendre le sens d’un article, sans l’avoir lu, dans ses grandes lignes, tout au moins. Elle devrait inciter à supprimer des descriptions, réduites à quelques remarques sur les points principaux24. » En 1979, lors d’une table ronde sur la normalisation du dessin en céramologie, on rappela que les dessins étaient « des documents indispensables – puisque descriptifs – et non […] de simples illustrations » et qu’en conséquence il fallait « pouvoir publier intégralement la documentation au trait, quitte à réduire la partie écrite à laquelle notre culture fait encore la place trop belle mais inutilement ». Ce qui ressortait du rapport entre dessin et texte : « On a cité plusieurs exemples de publications, par ailleurs fort sérieuses, qui ont perdu beaucoup de leur intérêt à cause de l’absence de liaison entre ces deux moyens descriptifs complémentaires. Si le texte renvoie fréquemment aux dessins au long du discours, l’inverse est rare. Pour faciliter la tâche du lecteur, qui consulte souvent la documentation graphique, planches et figures devraient comporter un ou plusieurs renvois au texte25. »

Quelque vingt ans plus tard, alors que l’on déplorait l’insuffisance des produits papier pour publier de façon satisfaisante la masse croissante d’objets livrés par les fouilles et que l’archéologie se trouvait affrontée à une crise éditoriale, on envisagea une solution mixte : papier-cédérom. On publierait sur cédérom l’information primaire ; le volume papier traditionnel au nombre de pages réduit contiendrait la part synthétique du propos, « la pensée et les idées ». Livre et cédérom seraient vendus ensemble. Des liens étaient prévus par « des appels visuels (sous la forme de logos par exemple) indiquant au lecteur l’existence d’un développement analytique ou au contraire synthétique sur son complément26 ». De grosses quantités d’objets pouvaient ainsi être publiées, les photos multipliées, la couleur utilisée, sans compter qu’à la lecture on pouvait zoomer : avec le cédérom, les possibilités étaient notablement accrues pour qui voulait consulter la documentation. La liaison avec le texte du livre était une autre affaire. Les renvois réciproques n’empêchaient pas que le lecteur se trouvât avec deux produits distincts dont l’un nécessitait le recours à un ordinateur. On ne sait ce qu’il en fut de cette possibilité bimodale. À vrai dire, elle ne faisait que moderniser une situation de lecture écartelée entre texte et image, qui d’ailleurs n’a pas disparu du travail de l’archéologue. Il n’est que de lire le compte-rendu d’un ouvrage publié en 2010 sur le temple d’Apollon du IVe siècle à Delphes. Le livre se signalait par « une illustration aussi parlante qu’abondante et esthétiquement très réussie » ; cette documentation était « répartie dans trois volumes mesurant 25 × 33 cm : le premier comprend le texte et de très nombreuses figures (photographies et dessins), le deuxième offre principalement des dessins de blocs, sur soixante-quatre planches précédées d’une planche d’explication des symboles utilisés pour les relevés et le dessin […], le troisième renferme les dépliants de plans et d’élévations qu’il est souhaitable de pouvoir consulter tout en lisant le vol. I (liste et explication des dix-huit premiers dépliants dans ce volume, p. 139-144) ». Et l’auteur du compte-rendu de commenter : « Les lecteurs sérieux devront donc disposer de place sur leur table, afin de pouvoir déployer ces trois volumes et si possible quelques autres27… »

La liaison texte-image a été envisagée par Jacques Bertin en rapport étroit avec la méthode de traitement graphique de l’information qu’il conçut : la sémiologie graphique, dite la graphique. Dans son ouvrage La Graphique et le traitement graphique de l’information (1977), il consacra un développement, bref mais significatif, à la publication d’un traitement graphique dans un livre ou dans un article, ce qui amenait à poser « le problème de l’intégration verbe-image ». Il insistait sur le lien consubstantiel des deux éléments, tout en soulignant le caractère fondamental de l’image dans sa méthode. « Dans la graphique l’image n’existe pas sans le verbe, mais le verbe est sans signification hors de l’image. Ici le dessin n’est pas une illustration, une prime publicitaire. C’est le corps du discours. » Cela entraînait une mise en page qui donnait la prime à l’image : « le discours doit figurer en face de l’image : l’image sur une page, le discours sur la page vis-à-vis. Le discours est dactylographié en simple interligne. Si le discours dépasse la page, l’image doit figurer une nouvelle fois sur la page suivante. Si le discours ne couvre pas toute la page, il faut laisser en blanc le bas de la page. Et l’on recommence pour l’image suivante. » Dans le cas d’images complexes, le discours justifierait les choix opérés pour construire la matrice d’interprétation. Pour les images moins complexes, Bertin recommandait la mise en œuvre d’un procédé liant verbe et image : « encercler sur l’image les groupes que l’on cite et les désigner par une lettre. Le discours devient beaucoup plus simple. Il fait corps avec l’image et la démonstration est précise et concise28 ».

Serge Bonin qui travailla dans le laboratoire que dirigeait Bertin à l’EHESS dressait en 1997, lors du colloque « 30 ans de sémiologie graphique », un bilan mitigé : les traitements matriciels étaient « peu appliqués » ; de la sémiologie graphique, seule sa partie la plus facile à comprendre – les problèmes cartographiques – avait retenu l’attention ; le poids des habitudes demeurait fort : « la carte et le diagramme sont encore une illustration pour beaucoup : on n’est pas habitué à considérer une image comme un support de la réflexion. » Ce qui expliquerait que même dans des ouvrages d’histoire qui ont pourtant bénéficié du concours du Laboratoire de graphique les images aient été reléguées en fin de volume29. À moins que ne soient intervenus les éditeurs face à un procédé qui mettait à mal l’élégance de la composition typographique et consommait du papier à un moment où la réduction des coûts amenait le rejet des notes en fin du texte.

Ces quelques exemples pris au fil du temps montrent des solutions mises en œuvre pour intégrer ces deux documents que sont le texte et l’image ; les résultats, quels qu’ils soient, allèguent le souci de construire dans la matérialité du livre un outil authentiquement bimodal qui, plus commode pour le lecteur, comme l’avait dit Newton, servirait au mieux l’appropriation de l’information.





Le cahier de laboratoire :

« document multimédia »


Le cahier de laboratoire est un objet que les historiens des sciences ont privilégié. Ils y ont d’abord cherché la généalogie d’une découverte, si ce n’est l’étincelle ; plus récemment, sans que pour autant l’objectif premier ait totalement disparu, ils l’étudient comme modalité du travail scientifique, comme « archive » des opérations accomplies et des gestes faits dans le laboratoire30. On s’attachera ici à l’aspect matériel de cet outil d’inscription que l’on étudiera dans une approche d’ordre codicologique.

Des travaux faits sur les cahiers, carnets ou registres tenus par de grands savants du passé – fin XVIIIe-XIXe siècles – fournissent quelques éléments descriptifs, souvent rapides et pas toujours aussi précis qu’on le souhaiterait. Il est difficile d’en tirer une vue générale, d’autant que ces documents offrent bien des variantes suivant la personnalité du chercheur – Luigi Galvani (1737-1798) tint ses cahiers de façon soigneuse et systématique – et la nature des recherches – le cahier de laboratoire de Joule pour les années 1843-1858 est surtout rempli de chiffres, la part du texte étant réduite au minimum31.

Le Diary de Michael Faraday constitue un exemple privilégié, avec ses dix volumes (deux in-quarto et huit in-folio) qui contiennent l’enregistrement des expériences et des observations faites de 1820 à 1862. Les pages sont numérotées et datées, la date étant méthodiquement répétée en tête de chaque page. On ne sait si Faraday s’appliqua le conseil qu’il donna à des étudiants en 1827 : noter les résultats « au moment où les expériences sont faites, tandis que les choses elles-mêmes sont sous les yeux et peuvent être réexaminées en cas de doute ou de difficulté ». Des chercheurs pensent plutôt que le Diary serait une mise au net, effectuée, probablement le soir même, sur la base de notes provisionnelles qui auraient disparu. Faraday utilisa dans un premier temps (1820-1832) des registres de format in-quarto ; ce qui n’alla pas sans inconvénient comme il ressort de chevauchements et d’irrégularités dans les dates. Il n’a d’ailleurs pas totalement rempli le second registre et il procéda alors différemment, se servant de feuilles volantes in-folio ensuite reliées en volumes. Les informations enregistrées se composent de texte et de dessins. Le texte, d’une écriture lisible, reste hautement personnel en ce que la structure de la phrase n’est pas des plus grammaticales, que la ponctuation est généralement absente, qu’il est fait usage d’abréviations parfois abondantes, que des fins de mots ne sont pas toujours écrites. Les dessins, parfois très nombreux, sont placés près du texte auquel ils se rapportent, souvent vers la marge droite ; ce sont généralement de rapides croquis tracés avec la même plume que pour le texte ; des dessins plus achevés à la règle et au compas sont rares. À partir de 1832, les paragraphes sont numérotés en un ordre unique de 1 à 16 041 ; auparavant, Faraday portait en marge des sortes de mots-clefs, essayant dès 1831 deux systèmes de numérotation. La séquence unique des numéros qui fut adoptée va de pair avec la mise en place d’aides externes permettant de retrouver l’information enregistrée dans les volumes, soit un ensemble divers de bandelettes, fiches et feuilles annotées renvoyant aux numéros du Diary, prenant parfois même la forme d’index. Ces aides externes fonctionnaient aussi autrement : groupées ensemble de telle ou telle façon – et les archives de Faraday conservent des collages –, elles organisaient différemment la matière du cahier en vue d’articles mais aussi pour tester des idées. Ainsi, le Diary, enregistrement bimodal où texte et images sont liés, s’inscrivait tout aussi étroitement par le biais d’outils annexes dans un dispositif de travail plus vaste32.

Autre exemple : les cahiers de Pierre Potier, élaborés un grand siècle plus tard dans le contexte d’un laboratoire public avec des travaux de recherche en équipe. Ce pharmacien et chimiste fit toute sa carrière au CNRS à l’Institut de chimie des substances naturelles dont il devint directeur ; il est notamment l’inventeur de deux anticancéreux, la Navelbine et le Taxotère, distribués dans le monde entier. Les archives considérables qu’il a laissées contiennent la série de ses cahiers de laboratoire depuis ses débuts dans la recherche.

Tous sont écrits à l’encre ou au stylo à bille, rarement au crayon. L’un des premiers, datant du début des années 1960, se présente sous la forme d’un cahier d’écolier, à couverture souple. Les pages à gros carreaux et à réglures Seyes ne sont pas numérotées, mais datées. Pierre Potier ne changeait pas de page à chaque jour ; quelquefois une ligne sépare une page en deux – par exemple, pour distinguer le résultat d’une manipulation (« Après quatre heures… »). L’écriture est serrée et donne parfois à voir un jeu des couleurs : le bleu est réservé à la description de l’expérience, le noir à un commentaire et le rouge à ce qui est le plus important. La page de gauche semble avoir été laissée systématiquement vierge : y ont été ensuite collés ou agrafés des morceaux de papier (note complémentaire, schéma explicatif, version plus propre, plus précise ou plus définitive d’une formule chimique) ou portés des commentaires, des développements. L’écriture est celle d’un document personnel ; si elle est lisible, elle comporte parfois des abréviations compréhensibles de leur seul auteur. Au texte proprement dit s’ajoutent des formules chimiques, des dessins de molécules et de plantes. Les premiers cahiers de Pierre Potier sont des journaux personnels de recherche où sont notés au fur et à mesure les résultats des manipulations, des observations, des expériences en cours. Des marques d’usage montrent qu’ils ont été lus et relus. Tout autres sont les derniers cahiers : la tenue n’est plus quotidienne ; l’écriture est plus espacée et moins abrégée ; par contre, les papiers collés et agrafés augmentent. Alors que le chercheur passe moins de temps à la paillasse et est pris, et de plus en plus, par des activités d’administration, il ne note, semble-t-il, que l’essentiel ; le nombre de cahiers diminue en fin de carrière.

Les cahiers de laboratoire de Pierre Potier ont un complément dans les cahiers de substances naturelles qu’il a tenus pendant toute sa carrière, y compris dans les dernières années ; il y a noté toutes les mesures de substances qu’il a extraites, fabriquées, manipulées, traitées, données à des collègues ou envoyées à un industriel. Un autre complément est constitué par des cahiers de notes et bibliographie, cahiers à spirales, moins solides que les cahiers cousus du travail de laboratoire, mais plus pratiques ; ils contiennent notamment ses dépouillements de revues qui se bornent parfois, sous une référence abrégée, à des dessins de molécules ; on y trouve aussi des feuilles volantes et des morceaux de papier collés ou agrafés. Cet ensemble personnel s’inscrit dans une configuration plus ample dans laquelle entrent les cahiers de ses collaborateurs qui, lors que Pierre Potier montant dans la hiérarchie dirigea des recherches, effectuaient des manipulations pour lui.

À cette évolution du cahier au fil de la carrière, s’en ajouta une autre consécutive aux liens que le chercheur développa avec le monde industriel ; le cahier devint un mémoire scientifique à valeur juridique afin d’authentifier un résultat, d’en déterminer la date, d’en attester l’antériorité et la propriété intellectuelle. En conséquence sa tenue se fit plus formelle ; à cet effet, Pierre Potier imposa dans son laboratoire des règles33.

La tendance à la formalisation n’est pas, dans ces années 1970-1990, générale. Des cahiers de laboratoire, tout en respectant des règles dans leur tenue, sont restés des produits personnels, comme il ressort d’entretiens avec des physiciennes du CNRS en 199734. Celles-ci ont fortement insisté sur ce point que ratifie la preuve documentaire. Tri dans l’information à noter, présence massive de l’implicite et de raccourcis, emploi d’un vocabulaire « maison » ou d’expressions propres à une expérience et à l’inventivité langagière d’une équipe, investissement affectif constituent le cahier en un objet unique. Jouent encore le support de la notation, l’instrument scripturaire et l’utilisation de la page. Les cahiers de grand format sont les plus employés, ne serait-ce que parce que leur taille est une garantie contre la perte. Il est deux modèles dominants, le cahier dit « traditionnel », cahier de toile noire aux pages numérotées à l’avance, et le cahier « à l’anglaise » dont les pages numérotées présentent d’office un emplacement, en haut, pour la date, en bas, pour la signature de l’auteur et pour le paraphe du témoin (read and understood by…). Cela n’empêche pas certaines de choisir d’autres modèles, par exemple, à lignes et non à carreaux. Les carnets sont rares ; mais des conditions d’expérimentation peuvent amener à en utiliser – par exemple, quand il faut écrire devant des appareils. La notation sur le cahier est quotidienne, immédiate ou a posteriori alors à partir de notes prises sur des blocs ou des feuilles volantes qui sont ensuite jetées. Les instruments scripturaires – crayon, stylo, feutre, bic – sont de choix personnel ; leur utilisation est parfois combinée avec un système de couleurs au surligneur, intelligible de son seul auteur : « la 1re série, c’est bleu, la 2e c’est rouge. En vert, c’est ce qui était à refaire. » La page est généralement remplie dans son entier. Dans les cahiers les plus anciens qui font une large part aux courbes sur papier millimétré, les notes écrites sont portées autour du papier collé. Autre utilisation des pages : écrire à droite, coller courbes et listings à gauche. La tenue chronologique des cahiers dans des recherches qui portent forcément à des retours en arrière amène à constituer des pochettes de documents annexes. Ces remarques générales sont à assortir de bien des nuances suivant les sous-disciplines, le statut et les habitudes des personnes, les usages d’un laboratoire, etc. Elles ne montrent pas moins le caractère personnel du cahier de laboratoire – « un peu le reflet de soi-même » – et, ceci expliquant en partie cela, sa nature complexe combinant en bien des façons des éléments de nature et de provenance diverses, jusque dans l’écriture ou plutôt les écritures : le jeu des couleurs, les bouts de listings collés ou encore la présence minime mais réelle d’une autre main que celle de l’auteur quand le témoin appose son paraphe dans le modèle dit « à l’anglaise ».

Ce modèle ressortit à un processus de codification qui, en France, s’est institutionnalisé avec la mise en place en 2006 dans la recherche publique du « cahier de laboratoire national35 ». Les attendus de cette initiative ont été les suivants. Le cahier de laboratoire est « un des outils quotidiens du chercheur » : il est, la plupart du temps, personnel, même s’il en est pour des projets ou pour un équipement. Dans le même temps, il doit être « d’abord et avant tout un moyen d’assurer la traçabilité des travaux de recherche ». Un produit normé a été élaboré qui ne laisse pas moins chacun libre de ses usages pourvu qu’ils ne contreviennent pas à la norme, que l’on ne détaillera pas ici. On s’en tiendra aux quelques éléments qui entérinent un dispositif multimodal. D’abord un mixte d’écritures : celle de l’auteur écrivant à l’encre indélébile sans passer de ligne, signalant d’un trait oblique tout espace ou saut de page intentionnels, datant et signant au pied de chaque page, référençant les travaux dans un sommaire pré-imprimé ; celle du témoin qui appose sa signature sur chaque page face à celle de l’auteur après avoir indiqué ses prénom et nom ainsi que la date. Des éléments annexes, manuscrits ou non, peuvent être intégrés au cahier ; ainsi, comme on l’a vu précédemment, le chercheur peut y coller des résultats sous forme de photos, de données informatiques, graphiques ou autres ; seule différence : désormais, il signe à cheval sur ces documents et sur la feuille du cahier. Des documents, données ou fichiers externes liés aux expérimentations mais qui, en raison de leur nature même, ne peuvent être insérés dans le cahier sont associés par un référencement qui peut être manuscrit ou prendre la forme d’une photocopie du document collée, datée, signée. Ainsi, ce simple registre A4 qu’est « le cahier de laboratoire national » devient à l’usage un ensemble composite réglé.

Cela ne fait que ratifier le constat de « document multimédia » qui a été fait pour le cahier de laboratoire au tout début des années 2000. Aux écritures, dessins et collages usuels, s’ajoutaient les données de plus en plus nombreuses fournies par l’ordinateur qui prenait une place croissante dans l’activité quotidienne36. Transcrire des données, les retrouver sur le papier, travailler sur deux supports parut une perte de temps et une source d’erreurs ; de surcroît, dans l’industrie pharmaceutique et chimique, on vit rapidement l’avantage qu’il y aurait à passer au tout numérique : la réunion des énormes dossiers pour les autorisations de mises sur le marché serait grandement facilitée, sans compter que les données seraient automatiquement datées. Dès les années 1980-1990, on se mit à penser à des cahiers de laboratoire électroniques ; toutefois, le véritable point de départ des Electronic Laboratory Notebooks (eLN), en fait des logiciels, date de 2004-2005. Leur première adoption en 2006 fut le fait de grandes compagnies, les petites en restant à des systèmes hybrides – électronique-papier. Le secteur public n’a que peu adopté l’eLN : en 2011, le taux de pénétration en France était estimé à 5 %37. Aux États-Unis, là où il est utilisé dans l’université, s’est développé un mouvement appelé Open Notebook Science qui, à la différence de l’open access classique, vise à la libre communication des données brutes. Cette initiative a suscité des réticences et elle reste, semble-t-il, marginale ; on ne notera pas moins la diversité d’accès envisagée : intégral, partiel, immédiat, après un temps donné38.

Dans la recherche universitaire, le cahier de laboratoire reste largement aujourd’hui le produit multimédia que l’on a précédemment décrit – normalisé ou non, personnel ou moins. Dans un espace physique coexistent des inscriptions relevant de divers modes sémiotiques, qu’elles soient directement portées sur les pages ou bien collées : de l’écriture alphanumérique, des dessins, des graphiques, des diagrammes, des photos, des photocopies, etc., jusqu’à des lames portant les préparations observées39. Ainsi, des ressources de nature diverse sont mises en œuvre, se complétant pour documenter et garantir les résultats d’une recherche. Le cahier apparaît comme « un ensemble dont le sens ressort de la somme de ses parties, tout en étant plus grand que la pure somme ». Encore convient-il de penser qu’il s’inscrit dans une gamme d’outils – textuels et non (on n’oubliera pas les conversations formelles et informelles dans le laboratoire) – qui sont, dans le travail du chercheur, interreliés40.

Des remarques similaires pourraient être faites à propos des carnets et journaux que naturalistes, géologues, géographes, ethnologues, archéologues ont tenus et tiennent sur le terrain41. Ils donnent à voir la mise en œuvre d’un même mixte de ressources et allèguent une même inscription dans un processus plus vaste. Comme les cahiers de laboratoire, ils se révèlent dans leur matérialité des produits d’une grande, voire très grande complexité, bien plus que ne le laisse entendre l’appellation générique qui est la leur.





Le poster : une affiche pour parler


Le poster est majoritairement aujourd’hui une affiche imprimée de grand format (soit, pour un ordre d’idées, c. 1 × 1,20 m) qui, faite de texte et d’images (photos, graphiques, diagrammes, etc.), présente les résultats d’une recherche. Lors d’un colloque42, les posters groupés, souvent de façon thématique, sont exposés à l’avance dans des salles, placardés sur des panneaux. Les chercheurs peuvent ainsi les voir, commencer à en discuter informellement avec l’auteur (ou les auteurs) ou avec un collègue, avant d’aller à la présentation publique qui en est faite par l’auteur (ou les auteurs) lors de la session poster.

Le poster est une écriture exposée, suivant la définition qu’en a donnée Armando Petrucci : « Par écriture exposée, on entend n’importe quel type d’écriture conçu pour être utilisé dans des espaces ouverts, voire dans des espaces fermés, de façon à permettre la lecture, à plusieurs (de groupe ou de masse) et à distance, d’un texte écrit sur une surface exposée ; la condition nécessaire pour qu’il puisse être saisi est que l’écriture exposée soit de taille suffisante et qu’elle présente d’une manière suffisamment évidente et claire le message (des mots et/ou des images) dont elle est porteuse43. » Ces traits distinctifs se trouvent dans le poster : il se lit à distance et il est fait de mots et d’images. Deux autres caractères connexes, implicites dans la définition donnée par Petrucci et plus encore dans des écritures monumentales qu’il a étudiées, doivent être ajoutés. La lecture se fait à distance et debout : cette modalité n’est pas négligeable non seulement parce qu’elle conditionne la réception du message mais aussi et surtout parce qu’elle en informe la présentation – taille des caractères et clarté de la disposition ne sont que deux éléments dans un composé autrement complexe. La lecture à plusieurs n’est pas toujours silencieuse : le but principal du poster est de susciter un échange de paroles. L’affiche papier, mixte de textes et d’images, est aussi un hybride croisant communication visuelle et communication orale.

Le poster, tel qu’il se présente aujourd’hui, résulte d’un processus de sédimentations, de corrections, de mises au point diverses qui en sont venues à constituer un format accepté par la communauté. Les « premiers » posters ou des produits fort proches furent présentés en 1967 au Medical Research Center (Carshalton), institut majeur de la recherche britannique. C’étaient des « feuilles préparées » (prepared cards) sur lesquelles des chercheurs avaient porté des résultats, surtout des graphiques et des tableaux, à vrai dire des produits similaires aux static displays usuels dans le monde médical. Ces feuilles étaient placées sur des panneaux et les auteurs se tenaient à leurs côtés pour apporter un commentaire ou répondre à des questions. Ce type de présentation, né dans le domaine de la biochimie, gagna toute la discipline, puis dans les années 1975 et suivantes, fut progressivement introduit dans les congrès internationaux et nationaux des sciences de la vie et de la matière. Dans le même temps, le format évolua vers le produit actuel. Une fois adoptés, les posters ne furent presque jamais remis en question44. Précisons que le monde scientifique n’est pas passé dans son entier au poster. Il est dans les sciences dures des secteurs qui ne s’y prêtent pas ou s’y prêtent moins : c’est le cas des travaux théoriques. Les sciences humaines et sociales l’ont diversement accueilli : il s’est introduit assez rapidement dans la géographie, la linguistique, les sciences de l’information, la psychologie, les sciences économiques, plus lentement, voire pas du tout ailleurs ou bien de façon quelque peu aberrante : l’auteur fait un exposé traditionnel devant une affiche sur laquelle il a placé les éléments graphiques ou iconographiques de sa recherche.

Le succès du poster s’explique par de multiples raisons. À partir des années 1960, les colloques durent faire face à une augmentation considérable du nombre des communications liée à la forte croissance de la population scientifique. Alors qu’il n’était pas possible pour des raisons économiques et matérielles d’augmenter la durée des colloques ni de louer des locaux supplémentaires, les organisateurs s’efforcèrent de contenir la masse croissante des communications en les sélectionnant, en réduisant le temps de parole octroyé à chacun (à 10, voire 5 minutes), ou encore en multipliant les sessions parallèles. Ces dispositions n’emportèrent pas plus l’adhésion des participants qu’elles ne réglèrent le problème. Les posters furent la solution. Les organisateurs pouvaient placer dans une même salle et en un même créneau horaire bien plus de posters que de communications, jusqu’à dix fois plus, a-t-on estimé. Les communicants et l’auditoire n’étaient pas non plus satisfaits de la forme usuelle de présentation : la communication avec diapositives. Le temps dévolu à chacun était limité ; il était en moyenne de 15 minutes (10-12 pour la présentation et 3-5 pour la discussion), mais parfois moindre. Il était encore réduit à cause d’incidents qui ne manquaient pas de survenir, par exemple dans la projection des diapositives. L’auditoire avait à supporter de longues suites d’exposés, parfois prononcés à la hâte et rendus peu intelligibles par des accents étrangers dans une science qui se disait déjà largement en anglais. Il recevait une masse considérable de données originales – les exposés de 10-12 minutes étaient hautement concentrés – sans avoir la possibilité d’en assimiler toute la substance ni a fortiori de faire la moindre vérification. La discussion durait souvent moins des 3-5 minutes prévues à cause du retard qui avait été pris et elle ne donnait lieu qu’à une ou deux questions qui débouchaient rarement sur un véritable échange. Quand une discussion finale était programmée, elle n’était pas toujours très fructueuse, car trop générale, et elle était parfois abrégée par manque de temps. Enfin, le nombre croissant des sessions parallèles était une source supplémentaire d’insatisfaction.

Bien de ces défauts pouvaient être corrigés et les organisateurs s’employèrent à améliorer le format traditionnel. Mais les posters l’emportèrent sur ce qui était au centre des doléances : l’échange scientifique. De l’avis général, la fonction des colloques n’était pas seulement la présentation publique de résultats mais aussi et surtout l’échange personnel d’informations. Sur ce point, la supériorité des posters fut d’emblée manifeste. Ils ne permettaient pas seulement davantage d’échanges, mais encore de meilleurs échanges. Les posters étaient affichés pendant un certain temps. Les participants allaient voir ceux que la lecture du volume d’abstracts leur avait suggérés et, chemin faisant, en voyaient d’autres qui attiraient leur attention. Ils pouvaient juger rapidement de leur intérêt et avaient davantage d’information pour se former une opinion : ce qu’ils voyaient sur le panneau, ce n’était plus, comme dans la communication traditionnelle, la présentation linéaire d’une recherche accompagnée d’un défilé de diapositives mais toute la recherche à la fois. Les auteurs étaient aussi plus détendus : ils n’étaient plus pressés par le temps et ils avaient devant eux des auditoires moins impressionnants que de vastes assemblées anonymes. Ils pouvaient présenter toute leur recherche ou un seul aspect, et adapter leur présentation et leurs explications à leur public. Ce public, il est vrai, était limité, parfois même très réduit, mais il était composé de personnes intéressées. L’auteur et le public pouvaient encore discuter hors séance autant qu’ils le voulaient devant le document lui-même ; il était aisé de poser des questions, tant sur le sujet de la recherche que sur des points particuliers. L’auteur pouvait ainsi obtenir davantage de retour ; les participants pouvaient retirer plus de profit de leurs échanges avec l’auteur ou entre eux quand, se trouvant devant un poster, ils engageaient une discussion.

Ces avantages multiples expliquent le succès des posters. Ils contrebalancèrent largement les réticences (pour une part liées à la routine – il fallut s’habituer à ne plus présenter une recherche du haut de la tribune mais en face-à-face) et les quelques inconvénients qu’avait le nouveau format. Les unes et les autres se sont réduits au fil du temps, quand les posters sont entrés dans les habitudes et quand de nouvelles techniques de reproduction ont permis d’imprimer des affiches de façon économique et esthétique. Le seul « stigmate » qui est demeuré est leur statut dans la communication scientifique : le poster fut d’emblée jugé moins prestigieux qu’une présentation à la tribune dans une vaste salle, et les sessions poster tendirent à être largement composées de doctorants, de post-doctorants, de chercheurs en début de carrière ou présentant une recherche marginale. Dans les congrès scientifiques, le poster est au point bas d’une architecture du prestige qui a pour sommet la conférence inaugurale (keynote lecture).

Alors que les posters devenaient partie intégrante des colloques, la question se posa vite non plus de leur présence mais de leur qualité. Bien des efforts ont été faits en ce sens. Les « premiers » posters ne contenaient pas de texte (mis à part des légendes) mais seulement des données chiffrées, des graphiques, des tableaux, des figures, des photos. Du texte n’était pas nécessaire alors que les auteurs se tenaient à côté de leur présentation. Il est cependant apparu très tôt : ainsi, des photos de posters illustrant les comptes rendus des énormes meetings de la FASEB (Fédération américaine des sociétés de biologie) des années 1974-1977 montrent déjà quelques lignes de texte, des légendes développées, peut-être un résumé45. En fait, l’organisation même des réunions rendit le texte nécessaire : les posters devaient être parfaitement intelligibles alors qu’ils étaient exposés pendant plusieurs heures, mais que leur auteur n’était présent qu’une petite partie de ce temps. Le texte entra donc dans le poster, mais avec un tel succès que le problème se posa vite de le contenir. Son abondance, voire sa surabondance devint un défaut majeur qui n’a d’ailleurs pas disparu.

Les posters restèrent un temps des produits modestes, ce qui rend remarquables leur succès initial et l’enthousiasme qu’ils suscitèrent. C’étaient des feuilles de papier (manuscrites ou dactylographiées), des photos, des représentations graphiques, plus ou moins artistiquement disposées sur un panneau, directement ou indirectement en intercalant une grande feuille de bristol servant de fond. Avec le temps, le poster initialement fait de pièces et de morceaux a évolué vers une affiche de grand format sur laquelle texte et images sont imprimés. Ce produit fut, d’abord, l’apanage de laboratoires riches ; la diffusion des techniques de reproduction et la baisse de leur coût l’ont démocratisé. Le poster papier est majoritairement aujourd’hui une affiche imprimée en couleurs, et il en est qui sont de véritables chefs-d’œuvre graphiques ; ce qui ne veut pas dire que l’on ne voit plus de produits médiocres.

Le poster s’est construit sur la base de la pratique. Dans les premiers temps, des sociétés scientifiques ont donné dans leurs journaux et newsletters des explications et des instructions, et les organisateurs de colloques ont précisé dans les appels à communications ce qu’était un poster, ce qu’il devait être. Très vite, une littérature spécifique s’est mise en place, principalement due à des personnes qui avaient présenté des posters et qui formalisaient leur expérience46. Jouèrent aussi l’imitation et la transmission orale : bien des chercheurs firent des posters, surtout dans les débuts, sur la base de ce que des « pionniers » avaient fait, reproduisant des « modèles », reprenant un aspect qui avait plu, en éliminant un autre qui semblait moins réussi ; ceux qui avaient vu ou fait un poster expliquèrent à des collègues comment procéder. Par la suite, des départements scientifiques ou pédagogiques des universités ont aussi organisé des formations sur l’art et la manière de confectionner et de présenter un poster. Aujourd’hui encore, alors que le genre va de soi, imitation et transmission personnelle conservent un rôle dans la confection des posters, tout simplement parce que dans les laboratoires les aînés initient les cadets.

La composition et la présentation matérielle du poster doivent répondre à quelques principes de base, sans cesse répétés. Le poster doit se suffire à lui-même, c’est-à-dire qu’il doit, par lui seul, transmettre un message clair qui puisse être rapidement saisi. Le poster est un médium qui sert un message scientifique ; un poster trop artistique n’est pas un substitut pour une recherche médiocre, et il peut même être contre-productif. Le poster n’est pas une fin en soi ; il présente les résultats d’une recherche afin de susciter une discussion : texte et image sont au service de la parole.

Ces principes sont à rapporter à un type de lecture particulier : la lecture debout, une lecture qui, déjà fatigante d’un point de vue physique, se conjugue avec l’opération intellectuelle tout aussi exigeante de la saisie de contenus scientifiques originaux. Voir les posters, c’est marcher beaucoup et, quand on ne marche pas, piétiner sur place. Après bien du temps passé à marcher et à rester debout, la fatigue joue ; et elle joue d’autant plus que les salles d’exposition des posters sont souvent bondées et bruyantes. Les posters ne sont visibles que pendant une journée, une demi-journée, quelques heures, rarement pendant toute la durée du colloque. Il faut alors les lire ou plutôt les scanner rapidement pour faire un premier tri et discerner ceux qui méritent d’être vus de façon plus approfondie. Il a été établi qu’un lecteur typique s’approche d’un poster, s’arrête, lit, comprend et poursuit – tout cela en 90 secondes, voire moins.

Ces conditions de lecture jouent dans la présentation de l’information sur l’affiche. Un format visuel s’est rapidement imposé : un bandeau comprenant le titre du poster et les noms des auteurs avec leur affiliation surmonte des blocs de textes et d’illustrations présentés en colonnes verticales47. Cet agencement est préférable à une disposition horizontale courant sur toute la largeur, qui ferait que les lecteurs se heurteraient en suivant de longues lignes quand ils ne perdraient pas le fil du texte.

Le contenu doit être présenté suivant un ordre clair, logique et facile à suivre. Celui-ci tendit à adopter un format existant, c’est-à-dire familier aux chercheurs et, pour cela même, aisé à parcourir de façon rapide, soit le format IMRAD qui est celui de leurs articles. Ce format fut introduit dans les posters dans les années 1980-1990. La conséquence fut que les posters tendirent à devenir des articles miniatures affichés. Les guides et autres documents prescriptifs se sont élevés contre cette dérive. Ils ont montré que, contrairement à ce que des auteurs pensaient, une masse de texte n’était point nécessaire pour dire la qualité d’une recherche, et que de tels pavés repoussaient en quelque sorte le lecteur ; quant aux détails, ils distrayaient l’attention et empêchaient d’aller à l’essentiel. Plus positivement, ils ont expliqué comment adapter le format IMRAD au poster : mettre l’accent sur l’introduction et la conclusion ; abréger la section matériel et méthodes ; omettre les détails. Cet IMRAD modifié correspond à l’acte de lecture qu’implique le poster : d’une part, alors qu’il est scanné en un temps très bref, l’introduction et la conclusion sont les éléments essentiels pour décider d’une lecture plus approfondie ; d’autre part, le public debout ne peut pas parcourir des textes longs et regorgeant de détails. Cette présentation est aussi dictée par la fonction du poster qui ne livre pas une recherche en son entier mais en présente l’essentiel de façon à susciter une discussion.

En second lieu, un poster doit être équilibré entre texte et images (photos, graphiques, diagrammes, etc.) ; il contient donc proportionnellement plus d’images qu’un article scientifique. Toutefois, les illustrations d’un poster ne doivent pas être celles qui sont publiées dans un article ni reproduire telles quelles des images déjà publiées dans un document imprimé. Elles doivent être plus simples et illustrer un seul point de façon concise. Ce conseil a pris plus d’importance avec le temps alors que les programmes d’ordinateur permettent d’obtenir aisément des représentations graphiques très élaborées. Dans un ordre d’idées analogue, les auteurs doivent aussi éviter de mettre dans leurs posters des tableaux comportant de nombreuses lignes et colonnes ; ce qui est un excellent mode de présentation des données dans un article ne convient pas pour qui lit debout.

Fait de texte et d’images, le poster est une présentation visuelle qui obéit à une grammaire visuelle. La littérature pratique donne des techniques et des astuces empruntées à la communication visuelle, tout particulièrement à la visualisation à distance. Deux principes de base, valables tant pour le texte que pour les images, reviennent sans cesse : less is more et the bigger the better. D’où des recommandations visant à éviter deux travers fréquents : le poster est surchargé ; il est difficilement lisible. Les conseils portent notamment sur la juste proportion de blancs à laisser, comme une sorte de respiration, entre les blocs d’images et de textes, sur le choix des caractères (taille, style, police), sur les couleurs et leurs effets, en évitant ici un défaut que la diffusion des nouvelles techniques a favorisé : le bariolage ; on conseille aussi de placer le gros de l’information dans la zone que l’œil peut balayer aisément et d’éviter de mettre du texte en partie basse de l’affiche.

Enfin, en tant que produit visuel, le poster demande une écriture différente de celle de l’article. Le texte, réduit au minimum indispensable, sera présenté en énoncés distincts ; la prose sera claire, concise et dépourvue de tout jargon, le style direct ; les paragraphes seront courts, les phrases brèves ; des mots-clefs ou bien des puces (bullets) et des numéros seront utilisés pour mettre en évidence des points importants. Toutes ces instructions – et on ne peut pas les suivre dans l’infinité des détails – ont pour but d’assurer une parfaite lecture d’un message affiché, ce qui veut dire d’abord, sa lisibilité. Un poster encombré, confus et qui se lit mal n’incite pas à s’arrêter, à entrer en discussion avec l’auteur ni à aller à la présentation publique.

Une nouvelle forme de poster est apparue au début des années 2000, qui n’a pas chassé l’affiche papier : le poster électronique qui se consulte sur un écran. Il est moins coûteux en temps et en argent (les données sont entrées dans un format électronique préétabli) et il évite les problèmes liés au transport de l’affiche et à sa mise en place ; il peut intégrer d’autres ressources (audiovisuelles, vidéos et images en trois dimensions) et permet l’interactivité. Il est né dans le monde médical où l’imagerie a connu un développement fulgurant ; dans un premier temps, du moins, l’adoption de ce type de poster s’est accompagnée du maintien en parallèle de l’affichage des posters papier.

Le poster numérique se consulte assis : il se lit sur écran, à une distance désormais rapprochée. Une réflexion sur ce nouveau produit a été amorcée lorsque l’on a décidé de placer des posters papier sur Internet pour maximiser leur diffusion : le changement de support rendait nécessaire une adaptation. Les indications qui en ressortent valent aussi pour des posters nés numériques. Si les principes généraux de simplicité, de cohérence, de lisibilité demeurent, des modifications sont indispensables à la mesure des différences que la nouvelle technologie entraîne. Le poster n’est plus vu dans son entier mais dans le défilé vertical des pages Web qui désormais le composent : l’ordre de la présentation doit être explicitement indiqué dans une page listant les divers éléments et leur relation ou dans une carte de navigation ; un rappel du titre général peut s’imposer en tête de chacune des pages Web. Le choix des polices de caractères doit être déterminé en fonction de la lisibilité sur écran qui n’est pas la même que sur un imprimé papier. L’utilisation des couleurs sera limitée (pas plus de quatre, noir et blanc inclus) et l’on évitera des combinaisons qui, passant mal sur écran, sont source de confusion. L’emploi des caractères et des couleurs sera uniforme afin de maintenir la cohérence visuelle d’un document que l’on ne voit plus que par pages successives. Enfin, si des images et des graphiques sont réduits pour être adaptés à la taille moyenne d’un écran, on veillera à ce qu’ils demeurent parfaitement lisibles48.

Le poster qui est un outil mixte fait de texte et d’images (elles-mêmes diverses) peut encore s’accompagner de produits annexes placés sur une table près du poster ou attachés au panneau : des handouts contenant des indications détaillées ; des listes bibliographiques ; des tirés à part ; plus rarement, un tirage en format réduit du poster ou d’une de ses sections. Dans sa version électronique, le poster intègre de nouvelles ressources, par exemple des images animées ou de brèves vidéos. Quelle que soit sa matérialité, il a pour but de susciter des échanges de parole. Cette parole peut à l’occasion prendre appui sur un tableau, et les organisateurs ne manquent pas d’en placer dans les rangées de posters. Pour les posters électroniques, des services de messagerie sont mis en place permettant à celui qui lit sur l’écran de contacter l’auteur qui doit être présent au colloque, sans quoi la réunion deviendrait virtuelle.

Le poster, texte et image, est au service de la parole, d’une oralité informelle, hors des sessions, ou formelle, lors des sessions. M’en tenant à de grands congrès (plusieurs centaines de participants – ce qui est courant dans le monde scientifique pour des réunions internationales), je rappelle que les posters sont exposés à l’avance pendant un certain temps. Les congressistes regardent les posters qu’ils ont sélectionnés à partir du volume d’abstracts ; ils peuvent aussi, suivant une expression commune, « faire leur marché » parmi les posters (souvent nombreux, voire très nombreux) qui sont exposés. Ils peuvent alors s’entretenir avec leurs auteurs ou avec des collègues de façon informelle. Ensuite, ils vont aux sessions poster qui les intéressent, où les posters sont publiquement présentés et discutés. Une session poster dure deux-trois heures environ. Elle peut être générale (rassemblant des posters sur différents sujets) ou, le plus souvent, thématique (tous les posters sont sur le même sujet). Un format de base s’est rapidement dégagé : une visite des posters guidée par un président de session qui peut aussi animer une discussion générale. Il a amené bien des variantes et des adaptations afin de tirer le meilleur parti de la session poster, c’est-à-dire de faire fonctionner au mieux l’échange d’informations. Je prendrai des exemples à deux moments, dans les débuts49 et aujourd’hui.

L’ASA (Acoustical Society of America) a organisé des sessions poster dès 1975. L’année suivante, il y eut une innovation avec, à côté de la session poster conventionnelle, la precis poster session. Et les organisateurs d’expliquer : « dans ce format, chaque auteur a trois minutes pour faire un résumé (precis) oral incluant la présentation de trois diapositives au maximum. À la suite de toutes les présentations orales d’une session, les auteurs seront auprès de leur poster pour le reste de la session afin de discuter [avec qui le souhaitera]. » Ce format permettait à l’auteur de présenter les principaux points de son travail, lui évitait de répéter sa présentation à chaque interlocuteur, et laissait plus de temps pour la discussion interpersonnelle. Elle « combinait le meilleur des deux systèmes de présentation [c’est-à-dire la communication orale traditionnelle et le poster] » ; on y voit aussi l’adjonction d’un autre produit, les diapositives, en fait celui qui se maniait dans les communications traditionnelles. En 1979, on ajouta le « format de discussion » (poster-discussion format) : dans la première partie de la session, les auteurs étaient auprès de leur poster ; ensuite une discussion générale avait lieu. Je n’ai plus trouvé mention de ce format, qui n’eut peut-être pas grand succès. Les deux autres formats continuèrent à régler les sessions poster de l’ASA. Lors d’une enquête faite à la suite du 98e meeting (1979), des membres jugèrent le résumé « une perte de temps » et demandèrent sa suppression. Il n’en fut rien ; bien plus, en 1998, le temps qui lui était dévolu passa à 5-7 minutes et le nombre de diapositives à cinq50.

La PCSI-6 Conference [6e Conference on Physics and Chemistry of Surfaces and Interfaces] de 1979 conçut un nouveau format afin de conserver l’esprit original d’un workshop dans un colloque de 250 personnes tout en rassemblant la large gamme d’intérêts qui émergeaient dans la discipline. « De simples sessions poster étaient jugées inacceptables puisque les avantages de la discussion ouverte et des questions directes qui étaient les leurs ne seraient pas incorporés dans l’ensemble de la réunion. » D’où l’invention d’un format combinant plusieurs types de présentations afin de réunir leurs avantages respectifs. « Durant la première partie de la session, un tiers des communications environ (en moyenne cinq) fut présenté oralement par les auteurs ; le reste fut résumé […] par des rapporteurs […]. La seconde partie de la session fut consacrée à des discussions individuelles et de groupes […]. Tous les auteurs […] avaient une place fixée le long du périmètre de la salle. Les auteurs qui n’avaient pas fait de présentation orale avaient un poster détaillant leur travail [L’ensemble des posters avait été exposé dans le hall du bâtiment le jour de la session et il le fut dans d’autres salles pendant tout le colloque]. La session reprit sous la présidence d’un modérateur pendant une demi-heure environ pour une discussion générale de toutes les communications de la session. Les rapporteurs conduisirent souvent la discussion en posant des questions d’intérêt général. » Cette innovation fut considérée comme un succès51.

L’AGU [American Geological Union] fit, en 1989, l’expérience de deux nouveaux formats, alors que les posters étaient devenus une partie importante de ses meetings. L’un consista à faire reprendre l’après-midi la session poster qui s’était tenue le matin pour une discussion animée par deux modérateurs ; cela « offrait plus de possibilités de discussion que les sessions classiques, orale ou poster ». La seconde innovation fut une session hybride communications orales-posters : deux communications orales précédèrent l’examen de douze posters sur le même sujet. La première initiative fut à nouveau programmée au meeting de printemps de 199052.

Ces trois exemples pris dans des débuts de l’histoire des posters montrent aussi les essais qui furent tentés pour conserver les avantages des présentations orales traditionnelles. Peut-être était-ce là un moyen de répondre à ceux qui, pour des raisons diverses, notamment de prestige, préféraient la présentation classique depuis la tribune. On ne notera pas moins la pluralité des formats et leurs combinaisons.

Les technologies modernes ont été mises à profit pour développer le poster et la session poster comme instruments de la communication scientifique. La projection de posters à partir d’ordinateurs portables ne suscita pas l’enthousiasme : « on perdait ainsi le contact personnel qui est une des forces majeures des présentations poster »53. Il en alla bien différemment d’innovations qui gardaient le meilleur des posters tout en leur ajoutant de nouvelles possibilités. Je m’en tiendrai à quelques exemples tirés du monde médical. Le 14e meeting de l’European Association of Cardio-Thoracic Surgery [EACTS] (Francfort, 7-11 octobre 2000) introduisit un format original : la présentation poster numérique interactive (Digital Interactive Poster Presentation). L’idée de base était que les « posters traditionnels » étaient des « instruments de communication inadéquats car ils n’atteignaient qu’un public limité ». Le nouveau système permettait, lui, la participation d’un public plus vaste, une présentation interactive et une discussion plus fructueuse. Voici comment il fonctionna. 251 propositions de communications furent sélectionnées parmi les 1 079 qui avaient été soumises, et 121 furent programmées en sessions poster. On demanda aux auteurs de posters d’envoyer aussi leurs données à l’avance dans un format numérique ou analogique. Quinze sessions poster furent organisées ; dans chacune, les auteurs donnèrent une brève présentation orale (2 minutes) de leur poster, puis, il y eut une discussion animée par un président de session. Durant la présentation et la discussion, le poster était projeté sur un écran de grande dimension et l’auteur pouvait agrandir un détail. En outre, les posters papier furent, tous, affichés dans l’aire d’exposition et ils y restèrent durant tout le congrès ; ainsi, les participants pouvaient voir et revoir les posters à leur gré. Cette expérience reçut un accueil très favorable54.

L’étape suivante est la suppression du poster papier, qui amena la mise en place de nouvelles modalités de communication. Lors du congrès de 2006 de l’European Respiratory Society [ERS], 1 300 posters furent présentés sous la seule forme numérique. Ils restèrent en accès libre sur 200 ordinateurs pendant la durée du congrès. On programma deux types de session poster : des « sessions électroniques » – l’auteur se tint pendant 30 minutes près d’un ordinateur et il discuta de son poster avec les personnes intéressées ; des « sessions de discussion » – pendant une heure, 20 posters électroniques furent présentés, à tour de rôle, par leurs auteurs (chacun disposant d’un ordinateur), puis il y eut une heure de discussion générale. De surcroît, les posters pouvaient être commentés dans un forum en ligne, forum qui resta accessible pendant le mois suivant le congrès. Enfin, les participants eurent la possibilité de rencontrer les auteurs pour une discussion face à face durant les sessions, au besoin, en prenant rendez-vous par un service de messagerie55.

Ces variantes, et il y en a bien d’autres, montrent d’une part, la flexibilité d’un format, d’autre part, l’intégration de ressources supplémentaires. Le poster (et la session poster avec lui) n’est un concept simple qu’en apparence. C’est, en fait, un produit d’une grande complexité puisqu’il unit ou mieux combine nombre de techniques, chacune d’entre elles comprenant de multiples éléments. Papier ou électronique, il est une expression originale d’une culture multimédia qui défie les partages classiques de l’oral, de l’écrit, de l’image, du numérique ; des technologies diverses se trouvent imbriquées en un tout fonctionnel et homogène au service d’une communication interactive des connaissances.



*

* *

Livre, cahier de laboratoire, poster sont des composites. Comme le sont de multiples autres outils de travail du monde scientifique, à commencer par les revues, en cela similaires aux livres. Les moulages qui furent, on l’a vu, un instrument essentiel dans l’acquisition du savoir dermatologique se complétaient de dessins, d’aquarelles et de photos utilisés simultanément jusque dans les années 1950-196056. Il en va de même pour bien d’autres représentations en trois dimensions – modèles et maquettes de tous ordres – dont on a vanté, et vante encore, la supériorité cognitive sur les textes et les images, avec lesquelles elles sont néanmoins utilisées de concert57. Les diapositives et les transparents projetés dans les cours et les colloques ne contenaient pas seulement des représentations figurées ; ils étaient aussi faits de texte, comme aujourd’hui les slides du PowerPoint qui donnent à voir une profusion d’images et à lire des lignes, pour ne pas dire, des blocs de texte. L’inventaire de ces composites pourrait être poursuivi, par exemple, du côté des instruments et des machines qui ne vont pas sans une documentation papier. Même la simple fiche descriptive, sur laquelle on s’arrêtera, se présente dans les instructions données par Mauss dans le Manuel d’ethnographie comme un produit mixte : ce bristol manuscrit sur lequel seraient portés à l’encre les renseignements relatifs à l’usage et la fabrication de l’objet, serait « accompagné de plusieurs annexes, en particulier, une annexe photographique et si possible cinématographique. Un dessin sera joint à chaque fois qu’il faudra montrer le maniement de l’objet, un mouvement de la main ou du pied » ; à défaut, le métier à tisser, pour prendre l’exemple donné par Mauss, serait « incompréhensible58 ».

Ces combinaisons sont encore plus frappantes quand, déplaçant le regard des objets à leurs usages, on observe de multiples interactions, ainsi celles de la parole avec le handout qui est distribué, avec le croquis qui est tracé, avec le PowerPoint qui est projeté59. À vrai dire, pour faire un même constat, il suffit de jeter les yeux sur sa table de travail : s’entassent dans la plus grande proximité des produits relevant de technologies diverses. Le manuscrit et la high-tech y coexistent. Ceci n’a pas tué cela. Pour preuve évidente : les post it collés sur l’ordinateur.





CHAPITRE 5


Une dimension sensorielle




* * *





Le corps entre dans l’outillage scientifique ; dressé à des usages, il acquiert dans les activités savantes un réel « pouvoir productif ». Cela, on l’a vu au chapitre 3. Les techniques du corps sont également éducation des sens qui sont ainsi développés et potentialisés. La main apprend à toucher, l’oreille à entendre, l’œil à voir, le nez à sentir, la langue à goûter, autant d’apprentissages qui ressortissent aux rôles qui leur sont ensuite dévolus. Ces usages allèguent la dimension sensorielle qui est aussi celle de l’ordre du savoir. On la mettra ici en relief. On ne parlera donc plus dans ce chapitre de dressage ni de discipline ; on constatera l’évidence des sens dans le travail et ses productions ; ce qui ne doit pas laisser entendre que l’on minorerait la part qu’ont les idées et que l’on ferait bon marché des contenus de savoir. Simplement, l’agenda est autre : décrire des pratiques sensorielles dans différents domaines de la transmission et de la production des connaissances. Des situations concrètes et variées montreront ce qu’il en est de la mise en jeu des sens dans un monde hautement intellectualisé.

Les sens sont un moyen d’appréhender, de saisir – à l’instar de la manicule – des objets qui peuvent être extrêmement complexes. De surcroît, la réalité des pratiques montre qu’ils entrent en des combinaisons diverses d’intersensorialité, quand ils ne donnent pas lieu à des hybridations extraordinaires. Ces observations s’accordent mal avec les distinctions par sens séparés qu’opèrent des théories philosophiques ou les représentations hiérarchisées des sens généralisant pour une époque1. Ici, comme ailleurs, les savants utilisent suivant leurs besoins toutes les ressources que leurs sens leur offrent. Un exemple ancrera concrètement le propos. Les vases peints en Étrurie, écrivait François Villard, sont, pour la plupart, « faits d’une argile jaunâtre tendant parfois au brun, d’une teinte froide, granuleuse, très dure, sonore lorsqu’on la heurte avec un objet métallique, se cassant avec des éclats vifs2 ». Au fil de cette brève citation, on saisit un pan du travail expert de l’archéologue, mobilisant et combinant la vue qui distingue les couleurs, le toucher qui perçoit la qualité d’une surface, l’ouïe qui entend un son. L’ordre du savoir que l’on a caractérisé comme multimodal est aussi multisensoriel. Cela ne veut pas dire que tous les sens soient également sollicités dans des dispositifs invariables et qu’une même valeur cognitive leur soit toujours reconnue. Dans la sphère scientifique, l’ouïe, la vue, le toucher ont une fréquence d’utilisation plus grande, ce qui ne veut pas dire que l’odorat et le goût n’ont pas servi3. Le sensorium de la culture savante dans le temps où nous l’étudions est assurément complexe, et il l’est d’autant plus qu’en cinq siècles d’histoire bien des changements sont intervenus. On s’arrêtera sur ce phénomène majeur et directement pertinent pour notre sujet qu’a été l’appareillage des sens, quand, par exemple, dès le XVIIe siècle, l’œil est devenu « armé » et a acquis – le qualificatif le dit bien – une puissance nouvelle. Une telle magnification ne ratifie que mieux la dimension sensible qui est aussi celle des activités scientifiques. On en prendra la mesure à partir des discours que les usagers ont tenus dans l’emploi de la panoplie des instruments qui a crû au fil du temps ; on n’analysera pas des traités scientifiques ou des écrits techniques, mais les remarques – le plus souvent de brèves réflexions en passant – suscitées par l’emploi du microscope ou du robot Da Vinci, pour donner deux exemples aux bornes de la période considérée.





Le jeu des sens


Alors que l’objet de l’étude est immatériel, pour ne pas dire évanescent, il est apparu nécessaire de relever d’abord des marques tangibles montrant les sens à l’œuvre. À cet effet, on s’est portée sur des lieux mêmes de la transmission et de la production des connaissances, décrivant un certain nombre de pratiques et de produits ou, plus précisément, mettant en évidence leur composante sensorielle, les considérant non dans leur contenu de savoir mais dans leurs aspects les plus directement liés à l’expérience des sens.

La lecture a une dimension sensible qui joue dans l’appropriation de l’information, ne serait-ce que du fait des caractéristiques matérielles de cette interface entre le texte et le lecteur, qu’est le livre. L’avènement du livre électronique a donné un nouveau cours à des arguments anciens d’ordre sensoriel, voire sensuel à l’appui du livre imprimé, alléguant sa « douce volupté » (Benedetto Croce) faite de l’odeur du papier et de l’encre ainsi que du rapport tactile avec la page. Ces opinions, quelle que soit la valeur qu’on leur accorde, mettent en évidence un élément physique implicite dans la lecture. On ne parle plus de volupté mais de désagrément à propos d’ouvrages d’art ou d’archéologie imprimés sur papier glacé – une invention du XIXe siècle – quand les reflets empêcheraient presque de voir. L’œil est tout aussi gêné par une composition trop serrée qui transforme des pages en blocs quasi impénétrables. Bien des principes de la typographie réfèrent à un œil sensible. Le bon caractère d’imprimerie « doit se présenter amicalement à la vue » ; la couleur du papier doit être « agréable à l’œil » ; le blanc pur lui inflige une véritable « douleur », produisant non seulement « un effet froid et inamical », mais une profonde gêne : « l’œil en est ébloui comme par la neige » ; un gris « livide » ne vaut pas mieux : il est « laid » et « repoussant ». Ces notations que l’on a tirées, parmi bien d’autres, d’écrits de cette sommité de la typographie que fut Jan Tschichold attestent la dimension sensible qui est présente dans l’acte de la lecture4.

Paul Ricœur par sa remarque : « Qu’est-ce que je fais quand j’enseigne ? Je parle5 », objectivait la modalité coutumière de la transmission des connaissances : la parole. Pensant à Michelet que j’ai cité au chapitre 3, j’ajoute immédiatement : le regard, un regard qui établit parfois plus qu’un contact, mais « convoque ». Parole et regard sont dirigés vers ces « êtres sensibles » qui, dans la salle de cours ou l’amphi, écoutent ou, pour le moins, entendent, et aussi voient. Leur vue est, en effet, également à l’œuvre : ils voient une personne parler, une personne physique avec son corps et ses gestes qui ont à l’occasion, une dimension sonore quand, par exemple, la main martèle le propos. De multiples interactions se produisent entre orateur et auditeurs-spectateurs, et réciproquement. On pourrait ici appliquer les analyses faites par Erving Goffman dans la Conférence. Plus que sur le processus théâtral du cours comme « prose animée », on mettra l’accent sur l’élément sensoriel et volontiers émotionnel. Les récits que des élèves ont laissés de maîtres dans le travail de l’enseignement révèlent par des notations très détaillées sur la voix qui s’est fait entendre ainsi que sur le jeu des regards un monde sensoriel composite, à la fois oral-aural et visuel. Ce même constat apparaît dans des liminaires de publications de cours quand l’éditeur, un ancien élève, expose ce qu’ont un jour été « des pages […] devenues muettes », dit ce qui désormais manque – par exemple, « la séduction de tout son être, le don pénétrant de sa voix » ; l’énoncé même des transformations alors opérées, qui vont dans le sens d’une désincarnation, d’une intellectualisation, d’une littérarisation du propos, révèle en creux l’ensemble des données comportementales mais aussi émotionnelles qui, un jour, ont été partie prenante dans la communication d’une pensée6. On mesure l’écart entre oral et écrit, voire leur altérité, ce qu’avait dit Michelet du haut de sa chaire, opposant aux « paroles gelées » du livre, les « paroles ailées » de ses cours avec tous leurs effets. Effets qui sont aussi ceux des silences. L’historien d’art Heinrich Wölfflin (1864-1945) avait coutume de commencer son cours en regardant longuement, sans rien dire, l’image de l’œuvre qui était projetée dans l’obscurité ; ce maniérisme ou cette méthode – laisser parler l’œuvre – fit une forte impression sur ses étudiants et fut imité, comme les longues pauses qu’il faisait dans ses propos7.

Cela rappelle que souvent dans la salle de cours l’auditeur-spectateur voit une personne qui non seulement parle, mais aussi qui montre, qui utilise des moyens divers afin de faire visualiser les réalités dont elle traite. On s’en tiendra à quelques exemples pris au fil du temps. Dans l’École normale de l’An III, des professeurs écrivirent au tableau, montrèrent des planches, présentèrent une expérience, apportèrent une machine ; Sicard amena à plusieurs reprises des sourds-muets dont il s’était fait l’instituteur et il les fit travailler en public pour preuve du bien-fondé de ses théories sur la parole8. Sous l’Ancien Régime, des enseignements s’étaient accompagnés de monstration. Giovanni Poleni qui occupa à Padoue les chaires d’astronomie (1710), de physique (1715), de mathématiques (1719), de physique expérimentale (1739), utilisa le tableau – la « pierre noire » – et distribua à ses élèves des feuilles sur lesquelles il avait reproduit des figures de physique. En 1719, il réclama aux autorités de l’Université un laboratoire pour l’enseignement mais dut se replier sur une requête plus modeste : l’acquisition, pour ses démonstrations mathématiques, d’un ensemble de carrés, cercles et triangles en cuivre qui pouvaient s’imbriquer. En 1738, le laboratoire fut finalement créé, et il s’accrut rapidement, comptant en 1758 plus de 250 machines. Poleni dut alors dans un même temps « dire et faire, de manière à ce que le résultat de l’une et l’autre chose soit aussi plaisant que clair9 ». Même pour des réalités abstraites, certains ont combiné à la parole une aide visuelle, tel ce professeur de philosophie que Muratori eut à l’université de Modène au début des années 1690 : « avec son seul chapeau ou sa seule tabatière, il savait expliquer tout ce qu’il voulait, rendant pour ainsi dire visibles et palpables les choses les plus obscures10. »

Parler et montrer ont constitué un binôme de plus en plus usuel dans l’enseignement universitaire aux XIXe-XXe siècles. Dans le domaine particulier des sciences, des instruments et des expériences font désormais partie du cours : pour Faraday, ils en étaient même, avec des tables et des diagrammes, « la partie essentielle11 ». Tous les moyens sont alors bons : Pasteur, dans un de ses cours de chimie à Strasbourg (1850), ne dessina pas au tableau, mais utilisa « des balles de liège coloré » pour faire voir des molécules à ses 86 élèves qui l’écoutèrent « avec beaucoup d’attention12 ». De façon générale, l’emploi d’aides visuelles se fait de plus en plus commun : schémas tracés au tableau, cartes géographiques, planches (de production personnelle, puis commerciale13), maquettes et modèles, projections lumineuses (plaques, puis diapositives, puis transparents, aujourd’hui Powerpoint), etc. Cette énumération, que l’on pourrait détailler et assortir d’exemples multiples, montre on ne saurait mieux que le professeur s’adresse tant à l’ouïe qu’à la vue des étudiants. Cela fut pris en compte dans la construction des amphis, par exemple, dans la Nouvelle Sorbonne à la fin du XIXe siècle : on évita les colonnes qui, dans les anciennes salles, barraient la vue ; on adopta un éclairage zénithal afin que le public ne fût pas aveuglé par la lumière du jour comme c’était le cas dans le grand amphi du vieux bâtiment ; la disposition des gradins fut minutieusement calculée et la courbe de visibilité fut plus accentuée dans les amphis de sciences afin que de tous les rangs on vît parfaitement les expériences14.

La communication de résultats de recherche passe largement par les colloques qui ont connu, tout au long du XXe siècle, une croissance et une diversification considérables dans les domaines scientifiques. Ces réunions emportent les mêmes remarques que précédemment, d’autant que dans bien des cas l’exposé de l’orateur à la tribune s’accompagne de projections. Le poster qui a plus que concurrencé la présentation traditionnelle est un produit aussi multimodal – on l’a montré au chapitre précédent – que multisensoriel. Les personnes qui voient l’affiche et qui parlent devant elle mobilisent les ressources de la vue et de l’ouïe ; entre encore en ligne de compte dans une communication scientifique en face-à-face une dimension sensible qui ressort des conseils donnés aux auteurs de posters pour contrôler un body language15.

On s’arrêtera à une forme originale de la communication scientifique orale, la small conference, que deux anthropologues, Margaret Mead et Paul Byers, ont explicitement caractérisée comme multisensorielle16. Les premières small conferences datent de la fin des années 1930 et elles furent organisées aux États-Unis dans le cadre des activités de la Fondation Macy qui finançait des recherches en sciences médicales ainsi qu’en biologie et sciences sociales considérées comme sciences auxiliaires. Ces réunions rompirent avec le schéma classique des colloques ; elles adoptèrent la forme de tables rondes, sans communications ni présentations formelles. La Fondation Macy organisa ainsi dans les années 1940-1950 un nombre important de rencontres de ce type regroupant, autour d’un thème donné pour cinq ans, quinze à vingt-cinq chercheurs éminents relevant de disciplines diverses ; ces rencontres étaient résidentielles et fermées. Ce modèle eut une belle postérité. Jouèrent dans son succès l’insatisfaction liée aux colloques traditionnels ainsi qu’une exigence scientifique nouvelle. Il était alors apparu que le savoir ne progresserait plus au sein des disciplines elles-mêmes, mais dans l’interdiscipline ou, mieux encore, « sur la frontière ». Si l’avalanche des publications dans les différents domaines était décourageante, la small conference offrait la possibilité aux participants de s’informer l’un l’autre rapidement, succinctement et sûrement de ce qui dans chaque spécialité importait pour le sujet étudié.

La définition que Margaret Mead donna de la small conference, et en connaissance de cause – elle avait participé à un grand nombre de réunions de ce genre –, mettait en évidence son caractère multisensoriel. C’était « un groupe suffisamment petit pour s’asseoir autour d’une grande table, réuni dans un but précis, dans un endroit précis, pour une durée limitée, une seule fois ou à des intervalles définis dans une série, afin de considérer de nouveaux aspects d’un sujet défini. Tous les membres de ce colloque reçoivent le statut de participants ; la méthode de communication est l’“interéchange” multisensoriel avec la parole comme médium principal ; l’attitude, les changements d’attention, les gestes et les types d’expressivité qui ne peuvent pas être représentés par l’écrit jouent une place importante17 ». M. Mead revenait sur ce point dans les prescriptions qu’elle donnait pour une bonne small conference. Elle n’excluait ni l’écrit, ni les images et autres représentations visuelles, fixant simplement une hiérarchie, avec au point bas l’écrit (la lecture de communications était totalement déconseillée, celle de background papers qui circuleraient avant la réunion était admise) ; il était possible d’utiliser des diapositives et des films pendant la rencontre, mais la préférence allait aux schémas et autres croquis que l’on trace alors que l’on parle. Si le médium principal était la parole, la « méthode de communication » dans cette réunion où tous se voyaient et s’entendaient était d’ordre multisensoriel. M. Mead soulignait l’importance des attitudes, des gestes et des expressions des participants : chacun, par ses mots mais aussi par son silence, par ses mouvements, par ses réactions ou par leur absence, contribuait à la création ou au développement d’idées qui se trouvent « quelque part au milieu de la table ». Paul Byers, dans la seconde partie de l’ouvrage, développait ce point en analysant des photos prises lors de small conferences. Il mettait en évidence un processus d’interaction particulier, une « grammaire interactionnelle » spécifique à ce type de rencontres, faite de postures, d’expressions du visage, de regards, de gestes, parfois minimes, parfois plus importants quand quelqu’un se levait et allait au tableau. Cette communication non verbale, dont les participants n’étaient probablement pas conscients, n’entrait pas moins dans le processus de la réunion et dans son efficacité. P. Byers montrait « les petites relations » qui se nouaient ainsi entre les participants, tout en soulignant que la production du savoir était davantage que la résultante d’interactions personnelles, de l’un avec l’autre, mais de tous avec une idée, celle que M. Mead plaçait au milieu de la table et, lui, quelque part au-dessus, « à une certaine hauteur ». D’où l’air un peu rêveur ou absent qu’avaient parfois certains participants, pourtant parmi les plus actifs18. La small conference était donc un format complexe, mobilisant divers modes d’expression, en fait les intégrant dans un système global visant à la construction du savoir à son plus haut niveau. De mêmes remarques sur une mixité sensorielle ressortent d’analyses faites à propos de séminaires fermés, de workshops et autres réunions en face-à-face, y compris à distance avec le cas de visioconférences19.

Un troisième cas de figure qui donne à voir les sens à l’œuvre est le terrain, celui du botaniste, du géographe, de l’archéologue, du sociologue, de l’ethnologue, de l’anthropologue. La vue est grandement sollicitée ; mais, comme on l’a noté à propos de l’excursion géographique, le toucher, l’ouïe, l’odorat, le goût le sont également. Prenons de nouveaux exemples dans l’ethnologie. Les Instructions d’enquête linguistique que Marcel Cohen rédigea en 1928 précisaient la collaboration des sens dans un travail dont l’objet était la notation du langage parlé. Une bonne audition était nécessaire. L’enquêteur y joindrait les ressources de la vue : il lui fallait remarquer les articulations visibles ; la vue humaine se compléterait, le cas échéant, par la photographie, le cinéma (ralenti), la radioscopie ou la radiographie. Le toucher entrait également en jeu quand, par exemple, l’enquêteur poserait le doigt sur la pomme d’Adam de l’informateur20. Le terrain des ethnologues a été défini comme une « expérience du partage du sensible », c’est-à-dire « des perceptions, des sons, des odeurs, des goûts ainsi que des sensations tactiles avec ceux qui nous accueillent. C’est la totalité de l’intelligence du chercheur qui se trouve mobilisée, et notamment l’ouïe (nous menons des entretiens) et la vue (nous effectuons des observations), écrit François Laplantine. La connaissance ethnographique est une connaissance par l’écoute, mais plus encore par le regard21 ». Une totalité sensible a été méthodologiquement revendiquée par l’anthropologue américain Paul Stoller. À l’encontre d’une approche dominante dans sa discipline qu’il jugeait intellectualiste, il opéra « un retour aux sens » – c’est là le titre de l’introduction de son ouvrage, The Taste of Ethnographic Things qui porte sur les Songhaï du Niger. Plus qu’à la vue et à l’ouïe, habituellement privilégiées – et la citation de Laplantine l’atteste –, il recourut au toucher, à l’odorat, au goût afin de rendre compte des réalités étudiées22.

Le dernier cas de figure que l’on prendra porte sur le monde médical. Il était obligé : on a vu ce qu’était l’éducation du corps du médecin et du chirurgien. Elle emportait une mobilisation des sens qui commençait avec les premiers enseignements. La leçon d’anatomie fut assurément l’exercice d’un regard23, probablement plus celui du maître que de l’élève dont on peut se demander ce qu’il voyait précisément depuis le haut du théâtre anatomique. La plus courante monstration de préparations anatomiques sèches était certainement plus efficace, comme le faisait à Padoue Michelangelo Molinetti (1652-1712) qui faisait aussi voir à ses étudiants des planches d’anatomie et un fameux modèle d’œil artificiel en ivoire et en verre24. Dès le XVIIIe siècle, une éducation était donnée à l’hôpital, qui s’ajoutait à une formation livresque et à l’enseignement ex cathedra : à Leyde, les étudiants de Boerhaave suivaient leur maître à l’hôpital où ils le voyaient observer le malade, éventuellement regarder avec une loupe sa langue et ses yeux, écouter sa respiration, prendre son pouls, sentir l’odeur de son urine, mettre en œuvre les ressources de ses sens pour établir diagnostic et thérapeutique. Un tel enseignement au lit du malade se donna aussi à Édimbourg, Vienne, Pavie, Lausanne25. Othmar Keel dans un travail d’ampleur européenne qui l’a porté à réviser la chronologie et la géographie de l’innovation clinique donne bien des exemples de l’expérience multisensorielle que faisaient les étudiants à l’hôpital26. Un enseignement spécialisé, comme celui de l’obstétrique à Göttingen au tournant du XVIIIe siècle, comprenait une bonne part d’exercices pratiques où le futur médecin était guidé dans les gestes à faire par le discours et l’exemple du professeur : l’ouïe, la vue, le toucher étaient ici également convoqués ; s’ajoutaient des aides visuelles : des dessins et des estampes ainsi que des préparations anatomiques étaient montrés27.

Les techniques de l’auscultation, de la palpation, de la percussion, telles qu’enseignées, c’est-à-dire quand est distingué chaque élément composant par la suite un ensemble implicite, révèlent l’imbrication en de multiples façons de ressources sensorielles diverses : elles ne sollicitent pas que le seul toucher ou la seule ouïe. Reprenons les leçons de Lasègue et de Grancher. Les données fournies par l’auscultation pulmonaire seraient d’autant plus instructives que la vue se combinerait à l’ouïe. En effet, les bruits que l’auscultation pulmonaire permettait d’entendre étaient « fugaces », expliquait Lasègue : pour comparer les deux côtés de la poitrine, le médecin devait s’y reprendre à plusieurs reprises ; même le praticien le plus expérimenté ne se souvenait pas des nuances huit jours plus tard. Il importait donc de noter, suivant certaines conventions, sur une carte muette de la cage thoracique les bruits entendus ; en donnant ainsi « une valeur visuelle aux phénomènes auditifs », l’interprétation serait plus sûre ; de surcroît, « l’histoire graphique » d’une maladie qui résulterait de la succession des notations serait de lecture plus aisée qu’un dossier d’observations écrites28. Le même Lasègue, dans l’introduction de ses leçons sur la palpation, rappelait le concours que se prêtaient palper et percuter. « La percussion prend son point d’appui sur [des] données auditives, mais elle profite des indications secondaires que lui fournit le palper. Il est impossible, en effet, de percuter sans noter, en même temps que le son obtenu, la consistance, l’élasticité, la résistance des parties sonores, ne fût-ce qu’à titre de notion complémentaire. Le palper met en œuvre un seul sens, celui du toucher, mais il utilise accessoirement les données fournies par la percussion. » À propos du palper abdominal, jugé d’une grande importance, il soulignait qu’il comporte « au plus haut degré la combinaison des trois sens de la vue (graphique), de l’ouïe (percussion) et du toucher (palpation) » ; par graphique, il entendait « un dessin schématique » que le médecin traçait sur l’abdomen du malade et qui lui permettait de déterminer « exactement » foie, rate, vessie, utérus. Le cas particulier du palper du genou « auquel on imprime des mouvements de flexion, d’extension, d’adduction et d’abduction » montrait « l’aide » que se prêtaient les sens associés : « l’observateur doit, au lieu de se borner à percevoir la sensation de craquement par la main, approcher l’oreille le plus près possible de la jointure afin d’entendre les bruits qui s’y produisent : craquements, bruits de cuir neuf, frôlement, crépitation analogue à celle des étoffes de soie, etc.29. » Grancher, dans son cours sur la percussion, soulignait la supériorité de la percussion digitale sur la percussion instrumentale pratiquée avec le marteau de caoutchouc frappant sur le plessimètre : la seconde qui, il est vrai, donnait une note plus claire, et donc « plus démonstrative pour l’élève », faisait perdre des « sensations complémentaires quelquefois très utiles, telles que l’élasticité, le frémissement, les vibrations ou ondulations profondes » que percevaient les doigts percutés30.

Les trois volumes de Clinique médicale que fit paraître en 1837 Jean-Baptiste Bouillaud, publiant ses observations à l’hôpital de la Charité d’avril à novembre 1836, fournissent des exemples multiples de la collaboration des sens dans l’examen des patients. À « la trinité vue-toucher-audition » qu’a pointée Michel Foucault31, s’ajoutent les ressources de l’odorat qui perçoit l’odeur de l’haleine et de l’urine et en distingue mille nuances. De façon générale, on est frappée à la lecture de ces observations par le détail de la notation d’impressions tactiles et de la description des couleurs, des odeurs, des bruits, ce qui veut dire d’abord la finesse de leur perception32. Cet art de la sémiologie, perfectionné au long du XIXe siècle, sollicitait tous les sens du praticien et il en allait encore ainsi dans les années 1950. Le Pr Jean-Paul Lévy a rappelé qu’alors « les médecins travaillaient avec leurs oreilles. Ils savaient percevoir des choses extraordinaires à la percussion […] ou à l’auscultation33 ». Désormais, l’imagerie, de plus en plus sophistiquée, et les examens biologiques, de plus en plus nombreux, apportent leurs informations. Il n’en reste pas moins que les sens du praticien sont à l’œuvre dans l’examen clinique : l’anamnèse, l’inspection, la palpation, la percussion et l’auscultation impliquent la mise en jeu d’un sensorium où entrent en composition l’ouïe, la vue, le toucher.

Il y a là une série de mixtes dont le stéthoscope – observer dans la poitrine pour entendre des sons34 – pourrait être l’emblème comme il l’est d’ailleurs du monde médical. La chirurgie n’est pas en reste ; on se rappellera la recommandation de Farabeuf à l’adresse de ses étudiants : regarder et toucher beaucoup. Cela amène parfois plus qu’à une collaboration des sens à une sorte d’hybridation. L’expression, aussi ramassée qu’imagée, les mains oculaires, que le médecin et anatomiste Jean Riolan avait utilisée en cette lointaine année 1626 pour dire la double aptitude sensorielle, tactile et visuelle, de la main du chirurgien35 en est la plus belle expression. Cette formule dut avoir un certain succès dans le monde chirurgical, puisqu’on la trouve encore citée au début du XXIe siècle36. Elle est sous-jacente dans le propos du Pr Okinczyc : « le chirurgien doit avoir des yeux au bout des doigts37 » ; et Farabeuf lui-même en avait donné une variante quand il écrivait à propos du doigt dans l’acte opératoire : « lui seul voit clair au fond des plaies inondées de sang38. »

S’il fallait encore étayer de preuves cette dimension sensorielle, voire multisensorielle des activités scientifiques, on pourrait rappeler la simple écriture : elle mobilise la vue (de la page, aujourd’hui de l’écran), le toucher (tenir la page, l’instrument scripturaire, taper sur le clavier), et s’appuie parfois aussi sur les ressources auditives quand les phrases du texte qui s’écrit se composent « oralement (de tête39) ». On pourrait ajouter les arguments à l’appui du dessin archéologique : la main et la vue se prêtent leur concours et s’instruisent réciproquement. De l’historien d’art et archéologue John Beazley (1885-1970), qui a joué un rôle majeur dans l’étude de la céramique grecque classique, on a célébré l’œil extraordinaire ; or, son expertise était le fruit à la fois d’une expérience visuelle et d’une production massive de dessins faits suivant une méthode rigoureuse, bref, d’une discipline coordonnée de l’œil et de la main40. On pourrait aussi rappeler que les modèles en 3D dont les sciences biologiques, physiques et chimiques ont fait un grand usage sont plus que des aides purement visuelles ; ce sont des objets qui non seulement peuvent être regardés de tous côtés, mais encore touchés, montés et démontés, que ce soit dans un but pédagogique ou dans une démarche de recherche. Cela ressort plus fortement avec la possibilité que l’ordinateur a offerte de visualiser sur l’écran des modèles interactifs de molécules. Les modèles traditionnels n’ont pas ipso facto disparu : dans un premier temps parce que les chercheurs sentaient le besoin de « poser leurs mains sur quelque chose, quelque chose de physique, afin de pouvoir le comprendre » ; ensuite parce que la représentation figurée ne donnait pas la sensation haptique. Les essais faits pour introduire dans les systèmes graphiques interactifs un retour de force permettant à l’utilisateur de sentir les forces d’attraction ou de répulsion entre deux molécules simulées (ce que le modèle traditionnel ne pouvait d’ailleurs pas faire) disent bien la dimension visuelle et tactile de ces outils de la science41.

Le travail même du laboratoire avec les discussions informelles qu’ont des chercheurs fournira une conclusion sur ce point. François Jacob a décrit dans ses mémoires les recherches qu’il effectua en collaboration avec Jacques Monod à l’Institut Pasteur : des heures passées dans l’euphorie, l’excitation et les fausses joies à discuter des expériences, à en concocter de nouvelles, à dessiner au tableau, à esquisser des schémas, à tracer des formules, à essayer des idées, à faire l’épreuve des réactions de l’autre (« À mesure que la discussion avançait, Jacques s’animait. Il se levait. Marchait de long en large. S’arrêtait devant le tableau noir. Dessinait un schéma. Restait à méditer quelques instants. Se prenait le menton entre deux doigts. Revenait s’asseoir. Gardait un temps le silence. Se mettait à penser tout haut […] Ce genre d’objection… »). Et cela, pendant trois ans, jusqu’à d’autres discussions devant le tableau noir, alors pour rédiger, pour faire « le procès-verbal officiel de cette recherche », désormais épurée de « toute scorie affective ou irrationnelle ». À l’évocation de ce temps ultime consacré à écrire, à « immobiliser » les idées sur le papier, à « les figer » – Michelet aurait dit à les « geler » –, on mesure la dimension multimodale, multisensorielle et profondément sensible qui est celle de la science en train de se faire42.





Des « organes artificiels »


L’utilisation des sens dans le monde scientifique est réelle ; pour autant, elle n’en est pas moins implicite comme Margaret Mead et Paul Byers l’ont noté à propos de la small conference. Une même remarque pourrait être faite au sujet de bien des situations qui ont été décrites. L’outillage sensoriel apparaîtrait comme un en-soi. Il est pourtant des circonstances où il est discuté, où est mise noir sur blanc la valeur qui lui est reconnue. Ces moments privilégiés – pour l’historien – sont ceux de l’apparition d’instruments et, plus précisément, de l’appropriation qui s’en fait. Une large gamme de réactions, qui va du refus déterminé au plus vif enthousiasme, dit la valeur dévolue aux sens, mais aussi leurs limites puisqu’ils ont besoin d’être appareillés, puis alors, avec la magnification qui en résulte, la nouvelle confiance mise en eux. On étudiera ici, sur la base de quelques exemples, l’apport des instruments aux sens tel que les usagers en rendirent compte. Le propos n’est pas d’entrer dans les agendas des sciences cognitives ou de la sociologie des techniques ni même dans ceux de domaines spécialisés, par exemple, de l’optique. Il est très simplement de préciser la dimension sensorielle du travail scientifique dans un monde qui s’est de plus en plus « matérialisé ».

L’époque moderne et contemporaine a vu la multiplication des machines et des instruments de tous ordres au point que chaque sous-secteur des sciences s’est trouvé doté de panoplies quasiment impossibles à inventorier43. Un très grand nombre d’appareils a été inventé pour visualiser des réalités infimes, éloignées, cachées, bref inaccessibles au regard humain, à commencer par les deux instruments qui en sont venus à symboliser la Révolution scientifique : le télescope et le microscope.

Le télescope a été célébré en son temps comme transcendant les limites de l’œil humain. « Le secours de l’artifice », « l’aide de la lunette d’approche » avaient pour corollaire « la faiblesse » des yeux. Ou pour le dire de façon plus positive, les « merveilleuses lunettes » augmentaient la puissance du sens « le plus universel et le plus noble » qu’était la vue. Ces opinions, de Pascal et de Descartes, s’opposaient à des préjugés anciens, et qui n’avaient pas totalement disparu, contre les lentilles de verre accusées de déformer la réalité et de créer des illusions. Même les banales bésicles, pourtant courantes depuis le XIVe siècle, étaient accusées d’endommager la vue et d’abord de la brouiller ; c’est ce qu’écrivait en 1583 Georg Bartisch, un chirurgien oculiste de bonne réputation : « Il est naturel qu’un homme doit mieux voir et distinguer lorsqu’il n’a rien devant ses yeux que lorsqu’il y a quelque chose, quelque subtil, transparent et mince que ce soit. » Dans les années où Galilée dirigeait le télescope vers les étoiles, l’idée demeurait que « toute instrumentation du regard à l’aide de lentilles conduisait à voir ce qui n’était pas ou à voir les choses autrement qu’elles étaient ». Lorsqu’il publia le Sidereus Nuncius (1610), il eut à affronter, entre autres, des objections qui tenaient à l’instrument lui-même : ses découvertes ne seraient qu’une illusion due aux lentilles – et la qualité de celles que l’on utilisait alors entrait dans l’objection. Des oppositions, plus fortes, reposaient sur le fait que la plupart des savants du temps pensaient que, seule, la vision directe pouvait faire appréhender le réel. Elles étaient dictées, écrit Ludovico Geymonat, « non par un manque de confiance en l’expérience, mais par un excès de confiance en nos sens ». La réponse fut pour Galilée de faire admettre « qu’il pouvait exister une perception visuelle plus aigüe que celle de l’homme » et alors « qu’un instrument comme la lunette pouvait non pas déformer, mais augmenter notre capacité de perception ». Il est inutile ici de suivre tout le détail du raisonnement de Galilée ; on s’arrêtera à l’attitude méthodologique qui en découla et que Geymonat a résumée en ces termes : « face à l’imperfection des sens, le savant a le devoir, non de se limiter à condamner la connaissance sensible, mais de rechercher les moyens de rendre cette connaissance sensible de plus en plus parfaite44. »

La lunette entra dans les instruments de la science moderne et une importante activité astronomique se développa qui, à côté des grands noms, compta nombre d’amateurs distingués. Des remarques concrètes sur leur travail – « l’œil à la lunette » – sont un exemple de l’actualisation de la nouvelle attitude. Ainsi, les astronomes toulousains du XVIIIe siècle considéraient l’organe de la vue comme un outil « très en deçà des instruments optiques ». Ils insistaient sur l’exercice qui développe la qualité de la perception, qui évite que l’œil ne soit la proie d’illusions d’optique ou la dupe de l’imagination ; ils indiquaient les précautions à prendre pour éviter tout ce qui serait nuisible à l’œil ou pourrait entraver une bonne vue, comme « laisser, par distraction, aller sa respiration sur les oculaires45 ». Dans les mêmes années, un astronome, lui, des plus éminents, William Herschel, soulignait la puissance accrue que la pratique de l’instrument donnait à l’œil, qualifié de « plus extraordinaire des organes46 ».

Le microscope a été associé par les contemporains au télescope comme amenant un double élargissement du monde sensible. « De même que le télescope aide l’œil à voir les objets qui, quoique grands, ne se peuvent clairement discerner à cause de leur éloignement, de même on a inventé le microscope qui fait que l’œil peut voir dans des objets proches bien des choses qui, par leur petitesse, échappent à la vue ordinaire », écrivait Vallisneri dans son Saggio alfabetico, résumant des motifs alors courants. L’instrument « moderne » qu’était le microscope découvrait « un monde nouveau dans le vieux monde » ; d’ailleurs, dans une lettre de 1705, Vallisneri avait noté que désormais la limite de l’acarien fixée par Aristote à la vue humaine était franchie : on voyait des animaux plus petits ; et si « on arme l’œil » de verres plus parfaits, on en verrait « autant de plus petits que le plus menu, et à nouveau d’autres archimenus, et d’autres, dirais-je, encore au-delà des archiminimes ». La définition du Saggio était l’occasion de liquider une objection, elle aussi courante : le microscope ne trompait pas « quand celui qui l’utilise a du jugement et une bonne technique47 ».

Dans les années où Vallisneri écrivait ces lignes et aussi poursuivait, « l’œil armé », ses recherches, le microscope était depuis un bon demi-siècle un outil d’investigation. Outil sommaire – c’était souvent le microscope simple –, dont l’emploi posait un certain nombre de difficultés liées à la fois à la qualité des lentilles, aux conditions d’observation, au manque de standardisation, à la confection des préparations sans compter le problème de la verbalisation des résultats. D’où après un fort engouement initial dans le monde scientifique, un certain reflux48. On ne sait quelle fut l’incidence d’une opposition d’ordre théologique qui s’exprima en Angleterre où dans certains milieux on jugea sacrilège d’utiliser le microscope et ainsi de percer des secrets que Dieu n’avait pas voulu révéler aux hommes49. Si à la fin du XVIIIe siècle il y avait des médecins et des anatomistes qui refusaient d’utiliser le microscope, c’était pour une tout autre raison. Bichat qui classait les tissus à l’œil nu le bannit du laboratoire de pathologie comme donnant des résultats entièrement subjectifs. Il préférait l’expérience directe du regard50. Alfred Donné qui fut l’un des introducteurs du microscope dans le monde médical, avait noté dans sa thèse « l’indifférence » des médecins à l’égard de cet instrument. Il y voyait deux causes. La première était que les observations microscopiques donnent « peu de confiance aux anatomistes ; cet instrument leur paraît plus propre à procurer des illusions fâcheuses qu’à retracer nettement la vérité. Ils se méfient de tout ce qu’ils ne peuvent voir de leurs yeux et toucher du doigt ». La seconde cause tenait à la difficulté qu’éprouvaient des médecins à se servir de l’instrument : contrairement à ce que ces personnes peu exercées pensaient, il ne suffisait pas de « regarder pour voir51 ».

Cette défiance, alors marginale envers le microscope, contraste en tous points avec la confiance de l’un des premiers fameux usagers, Robert Hooke. Dans la préface de sa Micrographia (1665), il soulignait l’apport des instruments « pour suppléer aux défauts des sens et élargir leur empire ». C’était « ajouter des organes artificiels aux organes naturels ». Le télescope et le microscope avaient amené de grandes découvertes qui étaient impossibles à l’œil nu. Et le savant anglais pensait à d’autres « aides » visuelles qui permettraient peut-être de « découvrir des créatures vivant sur la lune ou d’autres planètes, les configurations des particules composant la matière, et les dispositions et compositions particulières des corps ». De l’augmentation considérable de la vue que fournissaient les verres, il tirait la probabilité « d’autres inventions mécaniques pour améliorer nos autres sens de l’ouïe, de l’odorat, du goût, du toucher ».

« L’invention mécanique » du microscope augmentait la vue. Elle n’en exigeait pas moins une habileté de main. Pour en rester à des pionniers célèbres, Leeuwenhoek et Swammerdam, les contemporains (et aussi les historiens) ont été frappés tant par leur acuité visuelle que par leur adresse manuelle dans leurs préparations et leurs coupes d’une extrême finesse. Les remarques de Vallisneri sur son travail au microscope portent tant sur l’instrument lui-même – et c’est pour déplorer « la pauvreté » de ses microscopes ou pour s’en procurer de meilleurs – que sur la « grossièreté » de sa vue et aussi de sa main52. C’est que l’instrument impliquait une dextérité visuelle et manuelle ainsi que la coordination œil-main53. Lorsqu’au XIXe siècle des cours de microscopie furent organisés, « l’éducation de l’œil » qui se mit en place s’accompagna d’une discipline de la main : « rien ne peut suppléer le tact et la délicatesse intelligente des doigts pour des observations minutieuses », écrivait Donné dans son Cours de microscopie54.

Le XIXe siècle de la médecine et de la physiologie est caractérisé par l’apparition de multiples instruments destinés à accroître la portée des sens. Il n’est que de lire l’article observation du Dechambre – le monumental Dictionnaire encyclopédique des sciences médicales (1864-1889) : « Plus de diagnostic exact de maladie du larynx sans laryngoscope, de maladie profonde de l’œil sans ophtalmoscope, de maladie de poitrine sans stéthoscope, de maladie de l’utérus sans spéculum, de variations du pouls sans sphygmographe et sans tracés de courbes, de variations de la température du corps sans thermomètre55. » Ces instruments augmentaient les capacités sensorielles de l’observateur en les conjuguant, tel le stéthoscope qui, on l’a vu, mobilisait les ressources de l’ouïe, de la vue et du tact. D’autres permettaient d’explorer l’intérieur du corps humain, tel l’ophtalmoscope inventé par Helmholtz dans les années 1850-1851 qui permettait d’examiner le fonds de l’œil et, pour la première fois, de voir chez un individu vivant la rétine avec ses vaisseaux et les images qui s’y formaient. Ils faisaient pénétrer dans ce qui était caché à l’observateur, rendant l’invisible visible. De plus, ils disciplinaient les sens tant par l’exercice que la maîtrise de l’instrument impliquait, que par la traduction graphique des informations obtenues : les « tracés de courbes » que mentionne Dechambre effaçaient la personnalité de l’observateur. On ne s’arrêtera pas ici sur la transformation que le simple acte d’enregistrer opéra dans la physiologie qui, d’une activité avant tout descriptive, devint une science expérimentale. On soulignera, par contre, l’importance que prit la présentation visuelle des données et, avec elle, l’élaboration de méthodes graphiques donnant à voir des phénomènes cachés, lents ou rapides, fugaces, imperceptibles.

Ce fut là l’objet des travaux de Marey sa vie durant. Depuis ses premières recherches sur la circulation du sang (1857), il construisit et perfectionna de multiples machines et enregistreurs pour saisir la trace de mouvements sur une feuille de papier, puis, sur une plaque de verre et, enfin, sur un film avec la chronophotographie. D’abord étudiant des phénomènes physiologiques, il étendit ensuite ses recherches à la locomotion animale, puis humaine. Ses travaux lui suscitèrent des polémiques. Le sphygmographe qui permettait de mesurer le pouls ou, pour citer Marey, « de reculer la limite de nos sens, en révélant à la vue ce qui échappe au toucher », lui avait valu en 1866 une objection qui semble remonter à la préhistoire de la science moderne : « ce respectable confrère déclara que, pour lui, c’était une mauvaise tendance que celle qui violentait la nature et voulait donner à nos sens plus de portée qu’ils en ont. » Dans les années 1874-1878, on lui opposa jusque dans l’Académie de médecine, « l’observation directe », l’enseignement des sens exercés « par des observations multipliées56 ». La Méthode graphique (1878), son plus célèbre ouvrage, reposait sur un point de vue contraire. Dès les premières lignes de l’introduction, il faisait état des deux obstacles qui entravaient la marche de la science : « la défectuosité de nos sens », à la fois limite à la connaissance et source d’erreurs ; « l’insuffisance du langage » pour exprimer et transmettre le savoir acquis. La Méthode graphique écartait ces obstacles. D’abord, par l’application des instruments de précision dans le domaine d’investigation, ici les « mouvements, courants électriques, variations de la pesanteur et de la température […] Dans cette nouvelle entreprise, nos sens, à perceptions trop lentes et trop confuses, ne peuvent plus nous guider, mais la méthode graphique supplée à leur insuffisance ; dans ce chaos, elle révèle un monde inconnu. Les appareils inscripteurs mesurent les infiniment petits du temps ; les mouvements les plus rapides et les plus faibles, les moindres variations de forces ne peuvent leur échapper. Ils pénètrent l’intime fonction des organes où la vie semble se traduire par une incessante mobilité. Tous ces changements dans l’activité des forces, la méthode graphique les traduit sous une forme saisissante que l’on pourrait appeler le langage des phénomènes eux-mêmes ». Et c’était là le second apport de la Méthode graphique : constituer un mode d’expression scientifique clair et partout intelligible. Les courbes tracées sur ces multiples appareils en -graphe que Marey conçut offraient au regard du chercheur une masse d’informations inaccessibles à son œil57.

Lorsque Marey utilisa la photographie – et ce fut dans les années 1870 –, son usage était déjà quelque peu raisonné. À ses débuts, elle avait soulevé une « euphorie » dans le monde savant, symbolisée par les discours « prophétiques » qu’Arago fit en 1839 à la Chambre des députés puis devant les Académies des sciences et des beaux-arts réunies, célébrant le nouveau procédé – alors le daguerréotype – comme devant devenir l’auxiliaire privilégié de la science, en donnant des images « exactes », « fidèles », voire « réelles ». Il fallut du temps pour que la prophétie se réalise pleinement, et ce fut tout autrement qu’avec l’invention de Daguerre. On ne retracera pas ici l’histoire de la photographie et de sa reproduction dans les livres. On rapportera l’opinion de contemporains qui, pour en rester à notre sujet, virent dans la nouvelle technique le moyen de surmonter les limites des sens. En 1845, Alfred Donné qui, dès 1840, avait soumis à l’Académie des sciences les premiers daguerréotypes pris au microscope, en faisait dans l’introduction de l’Atlas qui accompagnait son Cours de microscopie, l’éloge comme donnant « les objets tels qu’ils apparaissent au microscope » ; il célébrait « ces images matérielles imprimées par la nature elle-même, avec une vérité que la main de l’homme ne peut jamais atteindre ». En 1853, des zoologistes de l’Académie des sciences allaient dans le même sens à propos d’essais de photographie appliquée à la représentation des objets d’histoire naturelle du Muséum : « dans certains cas, cet art nouveau est susceptible de rendre aux sciences naturelles des services plus grands que ne sauraient le faire ni le dessin ni la gravure » ; la photographie saisissait « une multitude de détails qui échappent à l’œil » ; elle disait aussi le défaut de la main : « le dessinateur le plus habile n’aurait ni la patience ni la légèreté de main nécessaires pour reproduire fidèlement tous ces détails ».

Que ce soit pour suivre le cours des planètes ou celui du sang dans les vaisseaux du corps humain, on promut la photographie contre « l’ancienne méthode des sens ». En 1864, l’astronome Hervé-Auguste Faye rappelait dans l’Académie des sciences qu’il avait plusieurs fois entretenu ses confrères « des erreurs singulières, dépendant de l’individualité de l’observateur, qui affectent la détermination astronomique de l’heure », erreurs qui « vicient les observations au point de rendre jusqu’à un certain point illusoire la haute précision qu’on leur attribue ». Et de poursuivre : « il existe un moyen radical de les faire disparaître en supprimant l’observateur et en substituant à nos sens l’emploi simultané des deux grandes découvertes de notre époque, la photographie et la télégraphie électrique. » Il était d’avis « de supprimer la rétine humaine dont les imperfections nous sont révélées d’une manière si frappante et dont les résultats varient non seulement avec les années mais aussi d’un instant à l’autre, avec les troubles momentanés de la digestion, de la circulation du sang ou de la fatigue nerveuse ». Des expériences l’engageaient à proposer le nouveau procédé consistant « à substituer à l’œil de l’observateur une plaque photographique et à enregistrer électriquement l’instant où la lumière est admise dans la chambre noire appliquée à la lunette méridienne ». En 1869, le Dr Ozanam présentait un appareil utilisant la photographie pour enregistrer, pour traduire visuellement le phénomène tactile des battements du cœur et du pouls, et il concluait sa démonstration en ces termes : « désormais, il appartiendra à la lumière d’inscrire elle-même les battements du cœur de l’homme et de diagnostiquer ses maladies ; l’ensemble de ces signes, réunis en dictionnaire, constituera une sorte de langue que le médecin devra apprendre ; elle lui donnera, en quelques pages, la clef de l’organisme dont il est appelé à prendre soin, au lieu d’en abandonner la connaissance à l’appréciation de chaque praticien, appréciation variable pour chacun, et trop souvent trompeuse, comme l’imperfection des sens que nous recevons de la nature58. » Dans ces années d’avant 1870, les liens n’en restent pas moins « encore ténus » entre la photographie et la science, tant à cause de certaines pesanteurs du milieu scientifique que de la technique elle-même. Les choses changèrent ensuite rapidement : la photographie entra dans les instruments de travail des chercheurs, mais en se combinant à d’autres – elle ne fit pas disparaître la main du dessinateur. Dans le même temps, on revint de certains enthousiasmes quant aux images exactes, fidèles, réelles.

Depuis ces temps de fondation, les techniques d’imagerie issues de la photographie ont connu un développement considérable qui, à une époque proche de nous, a été accéléré par l’informatique. Elles ont permis d’accéder à des réalités jusqu’alors inaccessibles. L’homme vivant est devenu transparent et le monde physique visible tant dans ses espaces lointains que dans ses particules infimes59. À ces exemples, on ajoutera celui de l’exploration du passé. La photographie a été très tôt employée par les archéologues pour reproduire des sites, des monuments, des objets, des inscriptions, et son usage n’a fait que croître, amplifié tant par des progrès techniques que par de nouveaux questionnements60. Document d’enregistrement, elle est aussi pièce à conviction, témoignage de l’existence d’un objet (ou groupe d’objets) à un moment donné, l’original pouvant disparaître rapidement (dans le cas de la destruction organisée de la fouille) ou évoluer dans le temps (par exemple, pour les monuments sous l’effet de l’érosion). La photographie offre aussi un substitut de réalités difficiles à voir (c’est le cas de photos faites dans le fond des mers à grande profondeur), voire inaccessibles à l’œil humain. La photo-radiographie a permis d’explorer l’intérieur d’objets : ainsi, l’image d’un lécythe funéraire révélant l’intérieur du vase (de dimension bien moindre que l’extérieur) a montré l’artifice qui permettait de limiter les frais de parfum offert au mort. Un dispositif spécial, composé d’une sonde au bout de laquelle est placé un appareil photographique, a été conçu pour la prospection des tombes étrusques : on « voit » à l’intérieur en ne perçant qu’un petit trou et ensuite on ne fouille, sur la base de l’évidence photographique, que celles présentant un intérêt archéologique61. La photographie aérienne a permis de « lire sous le sol ce qui y est enfoui62 ». Elle a été d’un grand emploi révélant des traces du passé invisibles à l’œil nu. Elle entre au nombre des techniques de télédétection qui rendent possible le repérage et l’analyse d’objets ou de phénomènes sans entrer en contact direct avec eux, dans une approche non invasive (c’est-à-dire sans opérer de fouilles). À la photographie verticale, à la photographie oblique, aux images satellitaires, s’est récemment ajoutée la télédétection par laser ou Lidar (acronyme pour Light detection and ranging). Ces diverses techniques ont chacune leur utilité, leurs avantages et inconvénients. Le Lidar permet, pour des zones boisées et donc impropres à la photographie aérienne et satellitaire, de voir au-dessous de la couverture végétale et d’accéder à l’invisible des ressources archéologiques enfouies dans le sol63.

Au rang des « organes artificiels » qui augmentent l’empire des sens, entre le cinéma qui, dans le monde scientifique, ne se développa véritablement que dans les années 1920, n’obtenant une pleine reconnaissance dans les laboratoires que dans les années 194064. On passera sur la suite de l’évolution technologique et le développement de la vidéo pour en rester aux premiers temps du nouveau médium. Il permettait d’abord à un grand nombre de personnes de voir et de voir de leurs propres yeux. C’est ce que disait en 1899 le Dr Doyen, pionnier du film chirurgical : « vous ferez comprendre en moins d’une minute à un millier de personnes ce que toute une conférence ne pourra démontrer qu’à un petit nombre d’étudiants placés à proximité du professeur. » De surcroît, le film d’une opération ferait réellement voir « les détails techniques qui en font tout l’intérêt », c’est-à-dire tout ce que ne voyaient pas la plupart des personnes assistant à une opération : « il est nécessaire pour la sécurité du patient de reculer les spectateurs à une distance de deux mètres au moins ; les mains du chirurgien et ses aides cachent une partie du champ opératoire et les manœuvres les plus délicates ne peuvent être suivies que par l’opérateur seul65. » À cet argument qui valait pour l’enseignement et qui demeura, s’en ajoutaient d’autres qui firent du cinéma un outil de recherche reculant les limites de l’œil humain. Le Dr Stutzin, un médecin de Berlin qui était parvenu à « cinématographier » à l’aide du cystoscope la paroi vésicale de l’homme, soulignait la supériorité de la nouvelle technique : « Par l’œil du cinématographe, nous sommes mieux à même de distinguer qu’avec notre œil. Notre œil subjectif est facilement abusé et l’intense lumière rouge du cystoscope le fatigue. L’œil de l’appareil cinématographique, au contraire, reste toujours clair et bien ouvert66. » Le cinéma offrait aussi les possibilités du ralenti. Marey en avait fait un premier usage, qui ne fit que se développer. Par exemple avec la microcinématographie du Dr Comandon appliquée à des recherches sur le mouvement des cellules animales et sur la croissance des végétaux. De son propre aveu – on est en 1920 –, le cinématographe était plus qu’un « appareil de documentation, d’enseignement ou de propagande scientifique, […] un instrument de laboratoire de plus en plus indispensable dans les recherches modernes. Agissant sur le temps, comme les instruments d’optique agissent sur l’espace, il réduit toutes les vitesses à l’échelle de nos sens et rend ainsi visibles des mouvements que nous ne pouvions suivre parce qu’ils étaient trop rapides (projectiles d’une arme à feu ou vol d’un insecte) ou trop lents (division d’une cellule, comportement des globules blancs du sang, mouvements rythmiques de certains protoplasmes67) ».

Depuis ces années-là, de multiples « scopes » ont augmenté le regard scientifique. Un exemple très contemporain montrera ce qu’il en est quand se coordonnent un œil magnifié et une main potentialisée par une « invention mécanique ». Le robot Da Vinci fournit au chirurgien dans la pratique d’une chirurgie mini-invasive une vision tridimensionnelle panoramique et agrandie de la zone opératoire, qui commence à bénéficier des techniques de « réalité augmentée ». Les mini-instruments Endowrist que le chirurgien manie à distance permettent d’aller, et c’est là le slogan de la compagnie, « au-delà des limites de la main humaine ». En effet, ils possèdent sept degrés de liberté et 90° d’articulation ; un filtre électronique élimine le tremblement. Non seulement ils augmentent la dextérité et la précision du chirurgien, ils lui offrent aussi l’ambidextrie68. La chirurgie robotisée a été présentée à ses débuts comme une réduction du « corps à corps » entre le chirurgien et l’opéré, une mise à distance du patient – de fait, le chirurgien à la console se tient à 4-5 m de l’opéré – avec toutes les conséquences en termes de déshumanisation que l’on peut tirer69. Des chirurgiens ayant une pratique du robot ont une réaction différente liée à une immersion visuelle totale dans le champ opératoire – « on a l’impression d’être dans la cavité opératoire », nous savons « exactement où nous sommes dans le corps de notre patient » – et aux instruments Endowrist – « on a une mini-main dans le pelvis70 ». L’un des inconvénients de la chirurgie robotisée a été qu’elle privait le chirurgien de l’information tactile que lui donnait sa main, à la fois actor et sensor71. Cette absence de retour de force a suscité des réticences et a porté à envisager des systèmes permettant d’y remédier72. La pratique aurait, semble-t-il, raison de ce handicap qui, de plus, est atténué par le contrôle visuel73. Pour le Pr Hubert, pionnier en France de la chirurgie robotique, l’œil compense, « le cerveau imaginant [le retour de force] au vu de la déformation des tissus provoquée par l’instrument ; cela d’autant plus facilement que le chirurgien dispose d’une vision tridimensionnelle74 ». Il y a là un phénomène historiquement et anthropologiquement remarquable. L’image des mains oculaires du chirurgien laisserait place à celle, tout aussi fascinante, des yeux manuels, si tant est qu’il est possible d’écrire cela en français.



*

* *

La magnification de la vue qui ressortirait de ces quelques aides « mécaniques » n’empêche pas que les autres sens soient à l’œuvre et souvent dans des mixtes comme l’ont montré des situations du passé et du présent que l’on a rapportées. Ici aussi, toutes les ressources sont bonnes pour produire et transmettre les connaissances : parler, montrer, voir, toucher, sentir. Constater l’empire des sens dans le monde du savoir, un empire qui s’est accru au fil du temps – et l’on n’oubliera pas les appareils qui ont aussi augmenté la voix, à commencer par le micro sans lequel les énormes colloques scientifiques n’auraient pu exister – n’est pas sans poser la question d’une conciliation avec une objectivité qui apparaîtrait au XIXe siècle75. Y a-t-il un mouvement concomitant ? Et quid d’un moi scientifique qui ne demeure pas moins ? Celui d’une personne qui emploie ses sens dans son activité professionnelle et, avec eux, se relie au monde étudié. À ce point, intervient, de surcroît, une dimension plus que sensorielle, sensible. Entrer dans un laboratoire de biologie cellulaire permet de saisir le regard éduqué et informé qui voit au microscope à épifluorescence, la main experte qui fait des préparations délicates ; ressort aussi l’empathie pour l’objet étudié, le regard « affectueux » porté sur des levures, le geste « respectueux » qui les traite, autant d’éléments qui amènent « à appréhender autrement la notion d’objectivité dans les sciences du vivant76 ». Et l’on ajoutera : dans le processus de recherche tout entier, c’est-à-dire dans tout ce qui disparaît dans le livre qui « gèle » ou l’article qui « fige ». Encore que la science même la plus décapée recourt au sensible quand, pour penser ou pour communiquer, il n’est pas d’autre solution que la métaphore qui fait entendre, voir, toucher, sentir, bref, qui transporte une réalité scientifique dans l’ordre sensoriel ; on y reviendra au chapitre 7.



TROISIÈME PARTIE


UN ORDRE RAISONNÉ



Introduction



Un outillage considérable par sa quantité colossale et sa diversité infinie est employé dans les activités de transmission et de production des connaissances, un outillage composite défiant les étiquettes technologiques tranchées. Il s’accroît encore des moyens que les acteurs apportent avec eux – des techniques d’autant plus efficaces que « le pouvoir productif du corps » combine souvent des ressources multisensorielles. Ce sont là des enseignements que livrent l’inventaire et la mise en ordre d’une masse confuse dont le capharnaüm des bureaux donne une évidence visuelle ; ce sont là aussi des conclusions qui ressortent de la description en situation de l’emploi de ces moyens très souvent interreliés.

Les usagers n’ont pas manqué de donner leur point de vue sur tel ou tel de ces outils, estimant l’apport que pouvaient fournir aux opérations de la science le séminaire, le périodique, le graphique, l’excursion géographique, le microscope, les « mains oculaires », le robot chirurgical, pour donner pêle-mêle quelques exemples. Les techniques intellectuelles sont des lieux de discours, que ce soit pour les justifier, les légitimer, les décrier, les rejeter. Ici comme ailleurs dans le monde des idées, les discours sont plus fréquents lors des moments d’institution ou dans le contexte d’évolutions technologiques amenant, si ce n’est des remises en cause, des réappréciations ; ils se font bien moins entendre dans « la science normale » quand les choses vont de soi. Le poster dont j’ai étudié l’histoire et le prodigieux développement est actuellement le format quantitativement majeur des colloques scientifiques ; toutefois, les chercheurs qui en font et en présentent n’ont pas pu me dire grand-chose sur cet outil même, mis à part des trucs auxquels ils recourent pour que leur affiche attire un public. Ils font un poster parce qu’aujourd’hui dans les colloques il faut en faire : c’est comme ça. Le contraste est grand avec les années 1970-1980 quand organisateurs (eux-mêmes très souvent des chercheurs) et sociétés scientifiques indiquaient non seulement comment précisément faire et présenter un poster mais encore et surtout comment ce nouvel outil fonctionnait dans le processus de l’échange scientifique, énumérant les avantages qui en faisaient la supériorité sur la communication avec diapositives. Autant d’opinions qui étaient discutées, intégrant les avis qu’auteurs et public donnaient dans des questionnaires de satisfaction. Ces dernières années, les posters ont mis à profit les nouvelles technologies pour devenir à l’occasion électroniques. L’innovation n’a pas amené de remise en question de la modalité même : elle l’a simplement upgradée ; pour autant, elle a fait l’objet de discussions, ne serait-ce que dans la crainte de la perte du face-à-face entre auteur et public1.

Les outils du savoir font donc l’objet de discours. Ceux-ci ne relèvent pas de l’ordre abstrait. Ils ne s’inscrivent pas dans des considérations théoriques ou philosophiques (par exemple, sur l’image) ; ils sont la réponse tangible apportée à des situations concrètes quand les acteurs s’interrogent sur la meilleure façon de produire et de communiquer le savoir, bref, de travailler. D’où une double conséquence. Les réflexions qui sont les leurs ne se présentent généralement pas sous la forme de traités ou d’essais ; ce sont plutôt de courts développements, de brefs passages, par exemple, quelques lignes dans un liminaire. Elles sont souvent bâties sur le schéma, à vrai dire commun, du pro et contra, procédant par pesée comparée des avantages et inconvénients. Ce sont donc des écrits circonstanciels, nés de la pratique et ayant une portée avant tout pratique, qui seront au cœur du chapitre 7 : leur analyse amènera à reconstruire, au-delà des raisons spécifiques à l’appui de telle ou telle technique, la logique de choix reposant sur un argumentaire de fond qui, on le verra, est invariable. Pesées comparées et arguments qui en résultent seront appréciés en portant attention à leur cadre d’élaboration. Hier comme aujourd’hui, les savants ont eu le sentiment de travailler dans la hâte aux prises avec une croissance exponentielle de l’information : ils se disent toujours pressés, débordés, submergés. Le chapitre 6 explorera cet espace-temps intellectuel dont les coordonnées majeures sont la surabondance et l’urgence.





* * *



CHAPITRE 6


La surabondance et l’urgence




* * *





Le seul nom Mastodons donné à un programme lancé par le CNRS en 2012 pour stocker, gérer et utiliser les Big Data traduit bien les grands volumes de données en augmentation constante auxquels des chercheurs sont aujourd’hui confrontés, tout particulièrement, dans les sciences physiques, économiques, médicales1. À une échelle moindre, le constat d’une croissance aussi rapide qu’exponentielle de l’information est aujourd’hui commun dans le monde scientifique en son ensemble. Il est renforcé par une autre opinion partout exprimée : le manque de temps. Dans les métiers de la recherche, les acteurs ne font pas exception à la règle générale2 ; ils sont invariablement pressés, débordés, submergés.

Ces remarques que l’on tendrait à lier à la « vie moderne » sont bien moins originales si l’on se place dans le temps long. Aux XVIe-XVIIe siècles déjà, les savants ont eu le sentiment de faire face à une masse aussi imposante que croissante d’informations et, tout au long des cinq siècles ici étudiés, il est bien des témoignages déplorant le manque de temps ou constatant son accélération. C’est là, au-delà des courants d’idées et des évolutions disciplinaires, l’arrière-plan historique sur lequel ont été discutées, pesées et comparées les techniques intellectuelles mises en œuvre dans le monde du savoir. Il convient donc de lui accorder de l’attention.





Res infinita est


Res infinita est (« la matière est infinie ») : ce cri d’effroi poussé dans les années 1540 par le bibliographe Conrad Gesner devant le nombre des ouvrages qu’il s’employait à recenser donne le ton. Déjà, moins de cent ans après l’invention de l’imprimerie, la production des livres frappait par sa grande abondance. Au tout début du XVIIe siècle, un auteur anglais Barnaby Rich déplorait « la multiplicité des livres surchargeant le monde », et Campanella constatait : « on a fait plus de livres dans les cent dernières années qu’en cinq mille. » C’est que la presse à imprimer travaillait à une cadence jusque-là inouïe et, comme le nota l’un des premiers historiens de l’imprimerie, Bernhard von Mallinckrodt (1639), Gutenberg et Schoeffer avaient à eux deux plus imprimé en un seul jour que nombre d’hommes n’avaient auparavant écrit en une année entière. Les savants des XVIIe-XVIIIe siècles, en Angleterre, en France, en Hollande, dans le monde germanique, furent frappés par le volume et la croissance de la production imprimée – « la multitude effroyable des livres », « l’horrible masse des livres qui va toujours s’augmentant », pour citer Bayle et Leibniz. C’était là un fait si avéré que Chambers jugea nécessaire de placer dans la deuxième édition de sa Cyclopaedia (1738), à l’entrée Book, une section intitulée Multitude of Books. Après avoir noté qu’il y a trois mille ans déjà le roi Salomon déplorait que l’on composât sans fin des livres, il soulignait que le phénomène était maintenant d’une autre ampleur : le nombre des livres était tel « qu’on ne pouvait se les procurer et les lire tous, mais les voir, connaître leurs titres, ni même les compter ». Il citait un auteur moderne qui avait écrit qu’il était plus rapide « de vider la mer que d’épuiser l’immense océan des livres, ou de compter les grains de sable du rivage que les volumes qui existent ». Tout au long du XVIIIe siècle, le constat est invariable d’une « multitude prodigieuse de livres », par exemple dans l’Encyclopédie de d’Alembert et Diderot (s. v. Livre). Très concrètement, la surabondance de livres se donne à voir dès la seconde moitié du XVIIe siècle dans des gravures représentant des bibliothèques, telle cette estampe de 1686 qui montre la bibliothèque impériale de Vienne, une immense salle garnie de livres jusqu’à des hauteurs vertigineuses, que l’on contrastera avec ces tableaux de la Renaissance qui figurent le savant archétypal, saint Jérôme, travaillant dans un studiolo presque nu3.

En ces années-là, l’imprimerie avait suscité un nouveau produit, le périodique, qui, se multipliant et se diversifiant, alimenta dans le monde savant la surabondance de l’information et, plus encore, sa perception. En 1743, les auteurs du Journal des savants lançaient le projet d’une table générale afin de se retrouver dans 90 ans d’informations, dans une « abondance si difficile à débrouiller4 ». En 1789, un journal de médecine allemand dénonçait la prolifération de publications périodiques dans la discipline et appelait à en limiter le nombre5.

Or, la tendance fut à l’inverse et la croissance aussi rapide que continue. Entre 1851 et 1898, la production imprimée doubla dans le monde. L’augmentation concerna au premier chef les périodiques qui crurent bien plus fortement6. Rien d’étonnant que les contemporains aient été frappés par la quantité considérable d’imprimés qui s’amoncelaient. Le grand bibliographe belge Paul Otlet ouvrait son Traité de documentation (1934) sur le constat suivant : « la masse énorme accumulée dans le passé s’accroît chaque jour, chaque heure, d’unités nouvelles en nombre déconcertant, parfois affolant7. » Dans les mêmes années, Julien Cain, dans l’introduction du volume La Civilisation écrite qu’il dirigea au sein de l’Encyclopédie française, faisait état de « la masse énorme et sans cesse croissante que représente l’imprimé sous toutes ses formes », « un flux sans fin qui s’écoule, et qui vient recouvrir presque en totalité la masse qui émerge encore » ; évoquant la production périodique, il la qualifiait d’« exubérante ». Revenant sur le sujet dans le chapitre des bibliothèques, celui qui était le directeur de la Bibliothèque nationale appuyait son propos par une citation du philosophe espagnol Ortega y Gasset : « Dans toute l’Europe, on a l’impression qu’il existe trop de livres. C’est le contraire de la Renaissance. Le livre a cessé d’être un attrait. Il est senti comme une lourde charge8. » Un diagnostic similaire venait sous la plume de la bibliographe Louise-Noëlle Malclès : elle faisait état d’« une production imprimée démesurée contre laquelle l’homme moderne est acculé à se défendre » ; encore ses remarques ne portaient que sur les seuls périodiques scientifiques9.

Avec la Big Science, leur nombre a explosé10. De surcroît, la masse de livres et de revues, sur laquelle le diagnostic de la surabondance porte traditionnellement, s’augmente de façon considérable si l’on prend en compte la littérature grise. Charles P. Auger, le premier à s’être penché sur le sujet dans son Uses of Literature Reports (1975), avait d’emblée noté les deux caractères frappants de « masse » et de « croissance continue » que présentait cette production et, en conséquence, la confusion qui en résultait pour les usagers11. Les ressources électroniques et le Web n’ont fait qu’augmenter son volume et ont posé avec une acuité nouvelle le problème du repérage des documents ; selon un expert, le risque est grand que « le wild growth ne rende la littérature grise even more greyish12 ».

Dans la dernière décennie, les ressources documentaires à disposition des chercheurs ont très considérablement augmenté. Les études, qu’elles portent sur le numérique en général, l’édition électronique, la documentation scientifique et technique, le libre accès, la fouille de données et de textes, les systèmes de recherche d’information, soulignent, toutes également, une croissance prodigieuse, rapide, constante. Les termes abondance, prolifération, explosion, surabondance reviennent sans cesse pour rendre compte du nombre de publications et de données, pour qualifier le volume de l’information disponible, quel que soit le domaine scientifique considéré13. Il est des chiffres aussi éloquents que faramineux. Prenons Medline, la base de référence dans les sciences de la vie : depuis 2005, entre 2 000 et 4 000 références sont ajoutées chaque jour (du mardi au samedi), soit 700 000 pour l’année 2010 ; on est ainsi passé de 15 millions de notices en 2007 à 19 millions aujourd’hui14. Milliers et millions d’unités bibliographiques conservent encore un sens. Celui-ci échappe totalement au lecteur non spécialisé quand il lit que le Sloan Digital Sky Survey, un programme d’observations astronomiques, a enregistré 140 téraoctets d’images entre 2000 et 2008, et que son successeur le Large Synoptic Survey Telescope en rassemblera autant en cinq jours seulement ; même avec l’équivalent papier indiqué – un téraoctet correspondant à six millions de livres, soit presque la moitié du catalogue de la BNF –, l’esprit a du mal à se figurer la masse de données livrée par ces grands instruments15.

Cette croissance de l’information scientifique, toujours prodigieuse et toujours constante, est due à de multiples causes : technologiques, comme il ressort des développements qui précèdent, démographiques avec l’augmentation dans le temps de la population des chercheurs, ce qu’avait noté Derek J. de Solla Price dans son fameux Little Science, Big Science (1963), institutionnelles, avec la pression et les exigences académiques de plus en plus grandes en matière de publication16. Jouent, bien sûr, des facteurs intellectuels avec l’introduction au fil des siècles de nouvelles méthodes et approches, plus récemment, avec l’éclatement en sous-disciplines et, en parallèle, les incidences de l’interdisciplinarité. Entre aussi en ligne de compte l’élargissement des champs disciplinaires qui passa, d’abord et très tôt, par l’augmentation même des objets étudiés. On s’en tiendra à deux exemples, à deux moments différents. La botanique changea d’échelle à la Renaissance : voyages et explorations apportèrent en Europe une masse de plantes que les Anciens avaient ignorées. Au cours du XVIe siècle, le nombre des espèces connues passa de quelques centaines à plusieurs milliers. Désormais, comme l’écrivait en 1554 le médecin flamand Rembert Dodoens, la vie d’un, voire de plusieurs hommes ne suffisait plus à maîtriser le savoir en la matière. D’autant que dénominations et publications croissaient de pair. Ainsi se créa une « explosion de l’information » qui ne fit que se poursuivre, connaissant un autre pic lors du Second Great Age of Discovery (1750-185017). Plus près de nous, l’archéologie a connu, depuis les années 1955-1960, une extension considérable de son domaine, englobant tous les produits de la technique humaine. Aux quantités déjà imposantes d’objets que l’archéologie classique, pour en rester à elle, avait amassées depuis la fin du XIXe siècle – il n’est que de penser aux énormes collections d’antiquités des musées et aux corpus monumentaux publiés sous l’égide des académies nationales –, sont venus s’ajouter en nombre incalculable les vestiges de tous ordres. Alors que l’archéologie n’est plus une archéologie de l’objet, mais du terrain, incluant objet et contexte ainsi que leur relation, c’est à un volume considérable de données que les archéologues doivent faire face. Rien d’étonnant à ce qu’ils évoquent des « masses fantastiques d’informations nouvelles » à traiter, avec pour corollaire une « inflation éditoriale ». Ce constat est usuel dans les années 199018. Il ressort bien concrètement de la quantité de données recueillies lors d’une fouille, limitée dans son terrain et dans le temps, mais exceptionnelle par les moyens employés, la fouille sous-marine en mai-août 1998 d’un navire disparu à la fin du XVe siècle au large de l’île de Bornéo : 13 261 objets ont été inventoriés ; plus de 200 tonnes de vase ont été tamisées livrant plusieurs centaines de kilos de refus de tamis à analyser ; plus de 20 000 photographies numériques ont été prises ; plus de 500 dessins d’objets significatifs ont été réalisés ; sans compter quelque 20 000 pages de données (relevés, descriptions, etc.19).

De ce rapide parcours entre les XVIe et XXIe siècles, il apparaît qu’hier comme aujourd’hui les savants ont eu, tous en leur temps, conscience du volume considérable des données à leur disposition et de sa croissance. Les chiffres du passé ne sont pas ceux du présent, mais pour un contemporain de Gesner ou de Leibniz la masse des livres était également perçue comme énorme, écrasante, infinie. Autant que par le constat, l’historien est frappé par les termes dans lesquels il est fait. Ce sont toujours les mêmes mots qui reviennent, tempérant l’enthousiasme de voir, avec l’abondance de l’information, s’ouvrir un nouvel univers plus riche de connaissances. Déjà les termes fréquents profusion, prolifération, surabondance, surcharge disant l’excès et le trop plein ont une dimension inquiétante. Celle-ci ressort nettement des métaphores employées pendant toute la période pour qualifier la masse des livres, des documents, des données : un labyrinthe, une montagne et, plus fréquemment, un flot, un torrent, un déluge, un océan20. Elles se trouvent sous la plume de bien des auteurs qui ont été cités dans les pages précédentes pour dire leur crainte face à une situation informationnelle lourde de ces menaces que sont la confusion, la désorientation, l’ensevelissement, l’étouffement, la noyade.

Ces images sont toutes présentes dès le XVIIe siècle. On s’en tiendra à quelques jalons. Le journaliste Basnage de Beauval faisait état en 1688 d’« une espèce de déluge et un débordement de livres qui menace d’inonder la République des Lettres21 ». Aux yeux de Leibniz, la multitude des livres qui se publiait prenait l’allure d’un « torrent », les connaissances dont on disposait apparaissaient comme un immense « labyrinthe » et l’humanité lettrée comme « une troupe de gens qui marchent en confusion dans les ténèbres22 ». Cabanis, dans un discours lu à l’Institut en 1797 sur le « Projet d’une bibliothèque universelle », était amené à déplorer les inconvénients qui avaient été ceux de l’imprimerie et il concluait sur une note sombre : « nous en sommes maintenant au point que le nombre de livres menace de nous étouffer entièrement23. » Pour Paul Otlet, la masse des livres et des documents qui croissait de façon déconcertante, voire affolante, était assimilée à « une montagne24 ». Dans la préface au volume de l’Encyclopédie française consacré à la civilisation écrite, Lucien Febvre comparait la production des imprimés à « un flux incessant, une marée qui d’heure en heure s’amplifie » et Julien Cain, dans l’introduction à ce même volume, évoquait le « torrent des livres25 ». C’est par l’image du labyrinthe que Vannevar Bush représentait la masse d’informations en expansion constante dans laquelle, grâce à sa machine – Memex –, le chercheur pourrait se retrouver26. L’âge numérique a fait trésor de ces métaphores que l’on trouve couramment employées. On s’en tiendra à deux exemples récents. Un dossier paru dans The Economist en 2010 donne d’emblée le ton en titrant l’une de ses sections : All too Much. Monstrous amount of data. Dans ces pages, l’image de la corne d’abondance qui dit la richesse et la prolifération de l’information scientifique et économique s’effaçait vite au profit de figurations neutres – « le flot qui va augmenter » –, mais plus souvent menaçantes – « le déluge d’informations » ou « les torrents d’informations qui submergent27 ». Une enquête publiée en décembre 2012 dans le Journal du CNRS sur le sujet Internet, Science, Technologies utilise une succession d’images disant le désarroi, voire l’effroi : le premier article s’intitule Des masses de données à donner le vertige ; un contributeur fait état de « la jungle [des données] à défricher » comme une masse hostile à pénétrer ; un gros usage est fait de la métaphore de l’élément liquide déchaîné : le sous-titre du dossier est La déferlante des octets ; un chercheur interviewé parle d’« un véritable déluge d’informations », expression qui d’ailleurs revient à plusieurs reprises en quelques pages ; il est aussi fait état de la crainte d’« être rapidement submergés par le flot d’informations à gérer » et du risque de « la noyade dans l’océan numérique des grandes masses de données28 ». À des fléaux accablant depuis des siècles l’humanité lettrée sont venues s’ajouter des menaces nouvelles, liées au temps présent : l’infobésité29 et la crainte se perdre dans l’hyperespace30.

Que le risque qui guette le monde savant soit celui du tournis et de la désorientation ou, plus grave, celui de la maladie, voire funeste, celui de l’ensevelissement ou de la noyade, hier comme aujourd’hui, la masse d’informations a été perçue comme pouvant affecter le progrès des connaissances, voire provoquer un déclin dans la civilisation et le retour de l’ignorance. C’est ce qu’écrivait Adrien Baillet dans l’avertissement du premier volume des Jugemens des savans (1685) : « On a sujet d’appréhender que la multitude des livres qui augmente tous les jours d’une manière prodigieuse ne fasse tomber les siècles suivants dans un état aussi fâcheux qu’était celui où la barbarie avait jeté les précédents depuis la décadence de l’Empire romain… » Cabanis, dans son discours de 1797 à l’Institut, après avoir établi que l’invention de l’imprimerie avait « rendu impossible tout retour durable des sociétés vers la barbarie », ne dénonçait pas moins les effets pervers de cette technologie qui, en multipliant les livres, avait amené sclérose de l’esprit et paralysie de l’examen critique, autant de pathologies intellectuelles qui, nées de la pléthore, risquaient à terme de causer une involution dans la civilisation31. Aujourd’hui, le passage au numérique n’est pas sans effrayer certains qui y voient, comme le rapportent deux spécialistes de l’édition électronique, la disparition d’un type de culture, voire une évolution vers « une nouvelle forme de barbarie32 ». D’autres redoutent que, devant la masse des données dessinant un « espace flou », la recherche ne devienne elle-même « floue » ou que, dans la désorientation née d’une crise de l’abondance, le chercheur ne trouve sa route dans le conformisme ou encore que, face au volume colossal des données du Web, il n’aille au hasard33.

D’autant que dans cette abondance, il y a des informations de qualité fort variable, ce qui ressort des avertissements invitant les usagers à faire « un travail d’évaluation34 ». La même remarque vaut aussi pour les livres comme il l’apparut dès les premiers temps de l’imprimerie. Pour Érasme, les publications qui étaient ainsi multipliées étaient de moindre valeur que les anciens textes, la multitudo librorum n’avait pas la qualité pour corollaire35. De surcroît, la nouvelle invention avait suscité un véritable prurit d’écrire et produit en nombre des ouvrages inutiles et frivoles – des « livrets horaires », selon Leibniz – qui, par une sorte de loi de Gresham du monde typographique, chassaient les bons36. La production imprimée qui augmenta considérablement dans les siècles suivants fut à l’avenant, comme le déplorait Paul Otlet : « Dans ces publications, que de redites, que d’allégations définitivement controuvées, que de désordre aussi37… »

Le désarroi et l’accablement réels qui ont pu résulter face à la masse énorme des produits de l’imprimé et du numérique n’ont pas porté à envisager le retour au passé, à l’ère prétypographique ou prénumérique ; et, devant le nombre des revues qui augmenta très tôt, nul ne songea à les supprimer. Bien différemment, on élabora des outils efficaces pour gérer les gros, voire très gros volumes de publications et de données de tous ordres ; et ces outils étaient d’autant plus nécessaires que si la quantité, déjà infinie aux yeux des hommes du XVIe siècle, ne faisait que croître, le temps, lui, était toujours compté, manquant, filant, courant.





« Le temps marche »


Les autoportraits en action que depuis le XVIe siècle les savants livrent démentent les représentations picturales classiques – un homme assis à sa table de travail la plume la main et les yeux dans le vague de la méditation ou posant solennellement devant un arrière-plan de livres ou de machines –, représentations qui non seulement figent le temps mais laisseraient penser que tous ces gens, vivant dans d’autres temps, avaient, eux, le temps. Il n’en est rien. Ils se présentent accablés de tâches, travaillant dans l’urgence, soucieux de ne pas perdre le moindre instant.

Les correspondances savantes des XVIe-XVIIIe siècles sont décevantes pour qui y cherche des élégances et des effets de style. Leurs auteurs écrivaient vite, raptim, currente, voire volante calamo (« à la hâte, au courant ou au fil de la plume ») pour citer des expressions qui alors ne sont pas rares. Ils n’avaient pas le temps de faire des « lettres à être montrées ». Pour la même raison, des éditions de correspondances savantes qui parurent au début du XVIIIe siècle furent sélectives tant dans le choix des documents que dans les documents retenus, parfois même publiés sous la forme d’extraits ou de résumés ; on s’en tenait au « noyau des choses dignes d’être connues ». Ainsi, comme l’écrivait en 1716 l’éditeur d’une correspondance « choisie », on devait, devant la masse des livres existants, s’interroger sur l’utilité d’une publication afin d’éviter de faire perdre aux savants un temps d’autant plus précieux qu’il leur était compté38.

Les savants sont des gens pressés. Ils l’étaient assurément dans le lointain XVIe siècle, se présentant accablés par une masse d’occupations, manquant de temps pour en venir à bout et pour se livrer à l’étude39. C’est le cas d’Érasme affirmant souvent « qu’il n’a pas de temps à perdre ou qu’il est écrasé de travail40 ». Calvin se disait tout autant « surchargé d’affaires » et faisait état du « manque de temps » ; en 1557, il déplorait « la multitude d’affaires et le présent fardeau de travaux qu’il me faut porter ». Pour l’humaniste, pour le réformateur aussi bien que pour Casaubon ou pour Henri et Robert Estienne, le temps est un bien précieux : il ne faut pas le perdre, mais le régler soigneusement et employer utilement tous les instants ; ainsi, les deux Estienne travaillaient en voyage afin de « remplir des heures perdues41 ». Une même discipline était mise en œuvre par Cardan : la quatrième règle de vie qu’il s’était donnée avait été d’« être extrêmement économe de mon temps. À cheval, à table, au lit, en veillant, en causant, je réfléchissais sans cesse42 ».

Ce qu’étaient les tâches écrasantes et la course contre le temps d’un savant, la biographie de Gerardus Joannes Vossius (1577-164943), un des plus grands noms de la République des Lettres, permet de le voir concrètement. Vossius enseigna successivement à Dordrecht, à Leyde, puis à Amsterdam, cumulant parfois deux chaires, assurant bien des fonctions administratives dont le rectorat de l’Athénée illustre d’Amsterdam, siégeant tout au long de sa carrière dans de multiples commissions. Il publia beaucoup dans les domaines de la rhétorique, de la poétique, de la linguistique ainsi que de l’histoire de l’Église où il accomplit un travail pionnier ; encore, outre des ouvrages savants, il donna des manuels pour les étudiants. Sa notoriété fit que visites et demandes ne manquaient pas, et que Vossius intervint et écrivit bien des fois pour recommander un étudiant ou un candidat à un poste. Plus largement, il maintint une correspondance importante avec d’autres savants de son temps – 3 300 lettres sont actuellement connues. L’illustre professeur fut étroitement mêlé aux polémiques théologiques qui déchirèrent la Hollande et il y prit une part active en fournissant bien des matériaux à son ami Grotius. Si l’on ajoute que Vossius fut un père soucieux de l’éducation de ses enfants et qu’il eut à régler des situations familiales embrouillées, on comprend qu’il fut parfois accablé par tout ce qu’il avait à faire, avouant qu’il n’avait « même pas le loisir de respirer44 ». Pourtant, il essayait de limiter le temps que lui prenaient ses nombreux visiteurs, ne leur accordant qu’un quart d’heure mesuré par un sablier posé sur sa table45. Pris par mille affaires, ce n’est souvent que la nuit qu’il pouvait faire sa correspondance : des lettres sont écrites « à la nuit noire », « à minuit », « entre une heure et deux heures quand plus personne ne peut le déranger46 ». La nuit était aussi parfois le seul moment où il pouvait se consacrer à ses travaux, comme il l’indiquait dans la préface à son De Theologia gentili (1641). Cet ouvrage, il l’appelait familièrement les Noctes amstelodamenses [Nuits amsterdamoises] à l’instar des Nuits attiques d’Aulu-Gelle, et d’expliquer : « Ayant été appelé de l’université de Leyde à cet Athénée illustre par les généreux gouvernants de cette ville pour enseigner l’histoire ecclésiastique et l’histoire du monde ainsi que la science politique, j’ai toujours été si occupé tant par mon emploi public que par d’autres activités que c’est seulement la nuit que j’ai trouvé le temps pour transmettre quelque chose à la postérité47. »

La correspondance d’Antonio Vallisneri (1661-1730) montre le rythme tout aussi soutenu d’une vie professionnelle au début du XVIIIe siècle : celle d’un professeur de médecine à l’université de Padoue, tiraillé entre les cours, les étudiants, les doctorats, des responsabilités administratives, les visites aux malades et les consultations écrites, la correspondance, les travaux dans les domaines des sciences naturelles et médicales48. Premier signe dénotant cette intense activité : des expressions justifiant ou excusant des lettres brèves ou écrites au fil de la plume. Bien souvent, Vallisneri écrivait ou répondait « à la hâte », « en toute hâte » « dans la plus grande hâte49 ». C’est sur le même mode qu’il lui arrivait de prendre congé de ses correspondants : la formule finale, neutre, respectueuse ou amicale, dit la hâte, une grande hâte, une extrême hâte50. C’est qu’il était occupé par « plein d’affaires », par « mille affaires51 », formule générale qui est le plus souvent explicitée, d’abord par le temps dévolu à l’enseignement. Vallisneri, qui était devenu professeur à l’université de Padoue en 1700, était depuis 1711 titulaire de la prestigieuse chaire de médecine théorique ; en 1713, il fut en plus chargé du cours de pulsibus et urinis, c’est-à-dire de sémiologie, à l’hôpital San Francesco ; s’ajoutèrent des obligations occasionnelles : ainsi, en 1719, il dut faire le cours d’anatomie. Suivant le règlement en vigueur, les leçons publiques devaient être faites en latin et sans notes : ce qui amenait un travail de mémorisation, autrement dit à « perdre toute la soirée et une bonne partie de la matinée pour se mettre le cours en tête52 ». Outre l’enseignement à l’université, Vallisneri, comme nombre de ses contemporains, donnait chez lui un enseignement privé. Il en ressort que les leçons lui « volent son temps », « tout son temps53 ». D’autant qu’elles s’accompagnaient des doctorats, des examens et du suivi des étudiants qui l’épuisaient : « excusez, je vous en prie, cette lettre décousue, explique-t-il à un correspondant, car je l’ai écrite en toute hâte, entouré d’étudiants qui me cassent la tête avec leurs balivernes54. » La mesure était comble lorsqu’en 1715 il fut nommé président de l’université : il lui faudrait « deux têtes et quatre bras » pour venir à bout de sa double activité pédagogique et administrative55.

Ce n’est que lors des vacances universitaires qu’il pouvait se livrer à ses recherches et à l’écriture de ses livres. Encore ce temps béni se réduisait comme une peau de chagrin car la pratique médicale, elle, ne s’arrêtait pas56. Vallisneri était une autorité que des malades venaient consulter et à laquelle des avis (consulti) étaient demandés ; le 22 juin 1724, il en avait « sept à rédiger et il ne savait pas par lequel commencer ». S’ajoutaient encore des visites à faire, sans pouvoir refuser quand les malades étaient « des personnes de rang57 ».

Tenir une correspondance, ce qui était une nécessité pour un savant du temps, prenait des proportions considérables pour qui jouait l’un des premiers rôles dans la République italienne des lettres et dans les études naturalistes et médicales en Europe. Vallisneri fait souvent état, au titre de ses occupations, de lettres à écrire, de réponses à faire, le plus souvent en grand nombre58 ; ce n’est pas moins de 20 à 30 lettres par semaine qu’il écrivait et, en une absence de quelques jours, s’amoncelaient 40, voire 100 lettres59. Encore dans son activité savante entrait le Giornale de’ letterati d’Italia qu’il avait contribué à fonder (1710) et auquel il travailla activement, notamment en fournissant des extraits de livres60.

Si l’on ajoute les visites d’amis ou d’étrangers de passage à Padoue ainsi que des obligations familiales ou mondaines61, le Pr Vallisneri avait un emploi du temps des plus chargés : il pouvait se présenter comme « très occupé62 ». En fait, il « croulait » sous ses multiples occupations63. À peine avait-il le temps de manger et de respirer64. En regard, la situation de l’âne qui fait tourner le moulin lui paraissait enviable, l’animal se reposant les jours de fête65. Pour venir à bout de tout, et les obligations croissant, en 1720, ce n’était plus deux têtes et quatre bras qu’il lui fallait comme cinq ans plus tôt, mais « dix têtes et vingt-quatre bras66 ».

Le manque, voire le grand manque de temps revient comme un leitmotiv dans ses lettres67 ; les cours, les étudiants, les malades, la correspondance, tout lui « vole » du temps pour ses travaux68. À peine parvenait-il, pendant l’année universitaire, à dégager de petits moments, parfois « en volant », à son tour, du temps au sommeil ou à ses obligations de professeur et de médecin. Le temps de l’étude apparaît comme un bien rare et précieux qui ne doit pas être gâché : aussi voit-on Vallisneri s’agacer contre un ouvrage dépourvu de table, ce « qui est fort gênant pour qui n’a pas de temps à perdre69 ». En dehors des vacances, il ne pouvait travailler que « par bonds » et le travail procédait à un rythme souvent haché : ainsi, le Trattato nel fine della sterilità, e dei suoi rimedj a été fait « en cent fois70 ». Plus généralement, le manque de temps l’amena à s’interrompre dans la composition d’un ouvrage, à différer un projet, à ne pas pouvoir satisfaire sur-le-champ la demande d’un libraire, à demander à autrui de corriger pour l’impression un de ses textes et, bien sûr, à s’avouer en retard71.

Cette longue déploration renferme des motifs qui se retrouvent tout au long de l’époque contemporaine jusqu’à nos jours. Un jalon intermédiaire peut être planté à la toute fin du XIXe siècle quand les technologies du travail intellectuel, du moins dans les disciplines humanistes, ne s’étaient que relativement peu modifiées. Il est fourni par la correspondance que Durkheim, alors professeur à l’université de Bordeaux, échangea avec son neveu Marcel Mauss. Il y a là des lettres écrites « à la hâte », « très à la hâte » ; parfois « le temps manque » pour une « véritable lettre » ; ce sont alors « deux mots à la hâte » ou une lettre écrite le dimanche « pour être sûr de ne pas manquer de temps72 ». Lorsque Durkheim parle de lui, c’est pour se dire « occupé », « très occupé », « très pressé », « dans la besogne jusqu’au cou », « débordé de besognes73 ». En juin 1897, il expliquait un retard à répondre en mettant en avant « mes épreuves [de son livre, Le Suicide], mon cours, l’Année sociologique74 ». En janvier 1898, il était « sur les dents par suite de la correction des épreuves » [de la revue75]. S’il ne consacrait à ses leçons « que trois jours », ceux-ci étaient « pleins76 ». S’ajoutaient les réunions, des visites comme cette après-midi de novembre 1901 où il en eut cinq – « de 1 h 30 à 4 heures, tout mon temps y a passé » –, ainsi que des tâches occasionnelles, telle la correction en juillet 1898 de 144 copies de bachot77. D’où parfois un « arriéré de cours et de correspondance78 », synonyme de retard. Durkheim avait beau être un grand travailleur, il n’avait pas le temps pour le livre dont il rêvait ; aussi le voit-on dans une lettre de février 1898 exprimer ce souhait : « Si je pouvais me trouver quelque bonne petite place à Paris, me laissant des loisirs79 ! » Tout cela explique encore qu’il fut parfois excédé par l’attitude de son neveu qui ne lui répondait pas aussi rapidement qu’il le souhaitait, qui se perdait dans les grands projets ou dans les minuties et qui, pis, lui semblait parfois « flemmer ». Les doléances et les remontrances qui ne manquent pas s’accompagnèrent un jour de l’avertissement : « ne sens-tu pas le temps qui marche80 ? »

Le manque de temps est une réalité du monde scientifique contemporain. Il ressort explicitement d’enquêtes portant sur le travail, ses modalités et ses rythmes. Dans les années 1970, des ingénieurs disaient ne tirer que 30 % de leur information de revues ; la raison majeure (40 %) était qu’ils n’avaient pas le temps de lire81. En 2004, des enseignants-chercheurs s’avouaient, pour plus de la moitié d’entre eux, « débordés » face à l’augmentation des tâches d’enseignement, d’administration et de gestion. Le temps de travail empiétait sur la vie privée, sur les vacances. 52 % disaient travailler onze mois sur douze, ou de façon plus qualitative : « je travaille toujours », « ma journée s’achève à minuit », « je travaille tout le temps, ma maison est un lieu de travail et les vacances sont organisées en fonction du travail (archives, colloques, bibliothèques) ». L’activité de recherche, perçue comme la plus motivante, se trouvait par la force des choses, reléguée dans les annexes de la vie scientifique. « On n’a plus le temps de lire des livres (hormis ceux qui relèvent du champ de recherche strict). » On avance sa recherche « durant quelques heures grappillées par-ci par-là » et surtout l’été. Si des nuances doivent être apportées suivant les fonctions exercées et les disciplines, le temps était toujours perçu comme « une ressource manquante82 ».

C’est d’ailleurs là l’une des raisons principales d’une faible, voire très faible fréquentation des bibliothèques universitaires par les enseignants-chercheurs, comme le montrent des enquêtes qui ont été conduites ces dernières années tant à Paris qu’en province. Le record appartiendrait à Paris 8 où en 2010, ils ne représentaient que le 1 % du public. Partout, les personnes interrogées avouent qu’étant débordées, elles n’ont pas le temps d’aller à la bibliothèque, d’autant qu’elles disposent d’accès plus commodes à la documentation, dans leur institut ou depuis leur ordinateur. Quand elles y vont c’est juste, tels des « nomades pressés », le temps d’emprunter quelques livres, d’ailleurs plus pour les cours que pour la recherche. Pour des gens qui manquent de temps, se déplacer jusqu’à la bibliothèque est « une perte de temps », quand ce n’est pas la bibliothèque qui, par ses horaires et par le refus du libre accès aux magasins, synonyme d’attente, en vient à être considérée en soi comme « une perte de temps83 ».

Cette crainte de perdre ne serait-ce qu’un instant est entrée dans les hésitations ou les réticences que des chercheurs ont eues initialement face aux ressources numériques. Ainsi, une étude menée au Commissariat à l’énergie atomique (CEA) en 1994-1995 sur l’usage des revues électroniques a fait ressortir – et le cas n’était pas alors exceptionnel – le non-usage de ce nouveau support en contraste avec l’usage croissant des outils de communication électronique dont la messagerie. Parmi les raisons multiples qui étaient avancées, il y avait l’inquiétude de se perdre dans la déambulation en ligne et, avec elle, de perdre du temps84. Plus près de nous, une étude de 2004 a montré que les colloques virtuels ont suscité chez certains la crainte d’un investissement coûteux en temps : il était fait état du risque que cette dépense d’un bien précieux soit disproportionnée par rapport au gain espéré85. Ce qui n’est d’ailleurs que l’actualisation d’un motif ancien : une enquête de 1962-1963 sur les modalités de la communication scientifique dans le monde de la recherche biomédicale aux États-Unis établissait que les réunions formelles, tels les colloques, devenaient de moins en moins efficaces et étaient de plus en plus considérées par les chercheurs comme « une perte de temps86 ».

Ce qu’ils ne pouvaient se permettre. La nature compétitive de la science porte à faire trésor de tout instant. Ce phénomène, qui n’est pas récent, comme l’a montré Robert Merton à grand renfort d’exemples depuis le XVIIe siècle, a fait l’objet d’une immense littérature. Il a été analysé en termes politiques, sociologiques et éthiques avec ces lieux obligés que sont les rivalités nationales, les conflits et les négociations, la reconnaissance et le prestige, la fraude et autres comportements déviants. On s’est bien moins intéressé à sa dimension temporelle qui est pourtant constitutive : la course pour la priorité est aussi et d’abord, pour les acteurs, une course contre le temps87.

Ce temps, qui manque toujours, a pu paraître encore plus précieux que les découvertes scientifiques et les innovations techniques donnent le sentiment d’une accélération de l’histoire. Il y a là une opinion commune à l’époque contemporaine : la science avance à un rythme de plus en plus rapide et, aujourd’hui, le numérique « met tout sens dessus dessous, et vite88 ». Un même constat se trouve dans un lointain passé. Il venait sous la plume de Campanella qui, dans les années 1620, après avoir évoqué les grandes découvertes ainsi que les inventions techniques de la Renaissance, écrivait : « il y a plus d’histoire en cent ans que le monde n’en eut en 4 00089. » C’est ce qui apparaissait également à Leibniz vers 1690-1691 quand il décrivait la formidable dilatation du champ du savoir qu’en un seul siècle la boussole, l’imprimerie, les lunettes à longue-vue, les microscopes avaient opérée90. À leur tour, les revues savantes qui se multiplièrent au XIXe siècle prirent acte du progrès rapide des disciplines. La Revue archéologique liait sa fondation (1844) à « l’extrême développement », depuis une trentaine d’années, des recherches en la matière. Et d’expliciter : « Rien ne peut faire encore présumer jusqu’à quelles limites ces recherches seront poussées, car chaque jour des objets nouveaux s’offrent à l’examen et à la sagacité des antiquaires ; on peut dire sans exagération que les progrès marchent, à cet égard, avec une telle rapidité qu’une différence de quelques années suffit pour faire changer ou modifier notablement la face de chacune des branches de la science archéologique91. » Le même phénomène s’observait dans les domaines techniques où les revues devaient suivre un mouvement de plus en plus rapide. C’est ce qu’exposait l’ingénieur Paul Planat dans le premier numéro de La Construction moderne qu’il fonda en 1885. Le bref historique qu’il traçait montrait que la presse de l’architecture et de la construction se transformait « d’année en année. Dans l’origine, des recueils coûteux de quelques planches, paraissant quelque fois dans l’année, à la manière des magazines anglais, avaient semblé bien suffisants […] L’architecture ne pouvait plus se traîner en char à bœufs […] Un premier progrès se fit : des revues mensuelles se fondèrent, qui parurent avec beaucoup plus de régularité […] L’activité moderne ne s’arrête pas et s’accélère de jour en jour ; talonnée par elle, la presse architecturale dut bientôt faire un pas de plus : on vit surgir des publications bimensuelles. La presse spéciale du bâtiment alla plus loin encore ; résolument elle se fit hebdomadaire92 ».

Le sentiment d’une évolution rapide des connaissances ressort on ne saurait mieux du constat que les publications et l’information qu’elles contenaient se périmaient vite, de plus en plus vite. L’imprimerie, qui avait paru garantir l’immortalité aux écrits des savants, réduisait rapidement à l’oubli les ouvrages qu’elle multipliait en abondance. Pour le libraire Andrew Maunsell, qui publia le premier catalogue des livres imprimés en Angleterre (1595), la vie des livres ne dépassait pas 20 à 30 ans93. Constat ancien fait au premier siècle de l’imprimerie qui a son équivalent dans le propos moderne « l’imprimé enterre au moins autant qu’il archive94 ». À s’en tenir à la matérialité des publications, les périodiques qui, devant la lenteur des livres, avaient paru la solution pour suivre le progrès des connaissances montrèrent vite leurs limites aux yeux des savants. « De nos jours, écrivait l’un d’eux en 1894, la science procède par de tels sauts et bonds qu’un délai de dix-huit mois peut dans la pratique, détruire l’utilité des recherches qu’on aurait à faire dans un périodique. À vrai dire l’intérêt des publications de ce genre est épuisé dans l’espace de deux ans après leur apparition95 ». Jugement un peu excessif, mais qui n’atteste pas moins le sentiment que les articles des revues perdaient vite de leur valeur et de leur intérêt. Ce que disait, en des termes plus positifs, Louise-Noëlle Malclès dans son traité de bibliographie (1950). Considérant la situation du chercheur, elle notait que celui-ci ne pouvait plus sacrifier aux dépouillements de périodiques « un temps précieux pour la recherche pure, temps qui ne lui suffirait d’ailleurs pas pour déblayer chaque domaine ou portion de domaine, obstrué à tout instant par un foisonnement de travaux » ; entrait en action le bibliographe dont le travail était, par une prospection méthodique de ces « mines d’information » que sont les périodiques, de « mettre en valeur cette matière première pendant que son pouvoir actif est intact, et non encore réduit ou éteint par une actualité toujours plus exclusive96 ».

Aujourd’hui, on ne parle plus de « pouvoir actif » mais d’obsolescence. C’est là un des concepts de la science de l’information, qui caractérise le degré d’intérêt d’une information en fonction du temps. La croissance exponentielle de la quantité d’articles a son corollaire dans une obsolescence également rapide du stock d’informations disponibles. Cette caractéristique fait l’objet de mesures et, pour en rester à des notations très générales à la hauteur du début des années 2000, elle a été estimée à 4,6 années pour la physique, 7,2 années pour la psychologie, 10,5 années pour les mathématiques97. On ne rentrera pas dans le détail de ces études hautement techniques ; on observera simplement qu’elles établissent scientifiquement cette vérité empirique, à savoir que la science va très vite. Prenant acte d’un flot rapide de l’information couplé à une surcharge informationnelle, un concept voisin s’est développé : celui du « juste-à-temps de la connaissance » (just-in-time knowledge) ; il s’agit de fournir l’information qui importe au moment où il le faut98.



*

* *

Cette formulation résume on ne saurait mieux le désir profond de tout chercheur aujourd’hui aussi bien qu’hier. La condition savante a grandement changé en cinq siècles d’histoire, et ce serait un jeu de pointer tous les changements institutionnels, sociaux ou économiques qui sont intervenus, sans compter bien sûr les évolutions dans les régimes de savoirs. Pour autant, surabondance des informations et manque de temps sont des données constantes, quasiment structurelles, de l’activité des hommes de science, des données liées, voire se renforçant par une sorte d’effet mécanique. C’est dans ce contexte d’abondance et d’urgence qu’ont été pensées les réponses bien concrètes qui ont été apportées tout au long de la période afin de maîtriser tant la masse que le temps, quand le problème était et demeure : comment trouver et se retrouver dans de toujours gros volumes d’information ? Comment ne pas perdre du temps, voire comment en gagner ?




CHAPITRE 7


L’économie de la pratique




Hier comme aujourd’hui, les savants ont été affrontés à une surabondance de l’information et à un manque de temps qui, se conjuguant, ont augmenté encore leur incidence sur le travail quotidien. Afin de répondre au mieux à cette situation, ils ont mis en œuvre des techniques intellectuelles aussi nombreuses que variées. Leur invention, leur introduction, leur perfectionnement se sont accompagnés d’argumentaires à l’appui du meilleur outil qui soit pour telle ou telle opération. La comparaison est alors une modalité commune dans la pesée des avantages. Elle peut être d’ordre général lorsque sont confrontées des technologies – par exemple, l’oral et l’écrit – ou particulier quand le parallèle est fait entre des produits de même nature – ainsi entre ces deux imprimés que sont le périodique et le livre – ou au sein des variétés d’un même produit – comme dans la gamme des images. Dans un cas et dans l’autre ainsi que dans tous les états intermédiaires, les arguments qui sont produits sont, bien sûr, spécifiques aux objets comparés ; ils ne ressortissent pas moins à un certain nombre d’invariants.

Un exemple concrétisera le propos. Il est emprunté à un ouvrage fameux, l’Advis pour dresser une bibliothèque de Gabriel Naudé (1re éd. : 1627). Dans ce petit livre emblématique de la res libraria, le bibliothécaire du président Henri de Mesmes et futur garde des livres de Mazarin donnait des principes pour former une bibliothèque à « l’usage du public », c’est-à-dire ici des savants. Il traitait de l’acquisition des livres, de l’architecture du local qui les abriterait mais aussi des modalités facilitant l’accès aux collections. C’est là l’objet du chapitre VII : De l’ordre qu’il convient de leur donner. Alors que les livres étaient là pour « en tirer service », il fallait les mettre en place sur les tablettes de façon à pouvoir les « trouver facilement et à point nommé ». Naudé n’approuvait pas ce qui se faisait dans des bibliothèques telles que l’Ambrosienne de Milan où tous les livres étaient « pêle-mêle et indifféremment rangés suivant l’ordre des volumes et chiffres » ; il rejetait tout autant des systèmes de classement basés sur les principes de la mémoire artificielle qui aboutissaient à de « vaines pointilleries et subtilités chimériques ». Il proposait d’adopter l’ordre « le plus facile, le moins intrigué, le plus naturel, usité », qui consistait à ranger les livres par grandes disciplines et, à l’intérieur de chacune d’elles, en allant du général au particulier. Alors qu’il fallait que « l’esprit pût, quand il lui plaira, les discerner les uns d’avec les autres, et les trier et séparer à sa fantaisie, sans labeur, sans peine et sans confusion », avec un tel ordonnancement, « il serait facile, en un moment, de trouver dans une bibliothèque plus grande que n’était celle de Ptolémée, tel livre que l’on pourrait choisir ou désirer ». Le dispositif d’accès serait complété par deux catalogues : l’un, par nom d’auteurs, « tant afin de ne point acheter deux fois, que pour savoir ceux qui manquent, et satisfaire à beaucoup de personnes qui sont quelquefois curieuses de lire particulièrement toutes les œuvres d’un auteur » ; l’autre, par matières, de sorte que l’on pût « voir et savoir en un clin d’œil tous les auteurs qui s’y rencontrent sur le premier sujet qui viendra en fantaisie ». Au fil de cet exemple, on voit un processus de comparaison multiple (entre bibliothèques, systèmes de rangement et catalogues) fonctionnant sur la base d’un argumentaire de fond qui repose sur les principes de rapidité, sûreté et simplicité.

Un large échantillon de cas permettra d’apprécier sur le temps long et au-delà des différences disciplinaires une modalité de choix à l’œuvre dans l’ordre intellectuel et d’évaluer le jeu des arguments avancés. Il ne s’agira pas pour moi de dire ce qui, toutes sommes faites, vaut mieux, mais d’explorer la logique des opinions qui furent celles des acteurs en leur temps en fonction des nécessités auxquelles ils étaient affrontés. On sera ainsi amenée à reconstruire, au-delà des raisons données, un pan de l’économie de la pratique scientifique, en identifiant des principes fondant une organisation du travail qui mobilise un outillage conçu afin de réduire ce qui coûte en temps et en effort (voire en argent), et donc de maximiser l’activité de la production et de la transmission des connaissances. Ainsi, en portant le regard sur des techniques, majeures et mineures, du travail scientifique, on mettra en évidence des éléments structurels qui ne sont pas sans conditionner l’histoire des savoirs. Un développement particulier sera consacré à un instrument dont il n’a pas été fait mention jusqu’ici : le style, la façon d’écrire la science.





« La conversation enseigne plus que les livres »


Des circonstances multiples de la vie intellectuelle ont porté à comparer le livre à des formes d’oralité – de la séance académique au colloque en passant par le cours ; dans ces examens pro et contra, la balance penche généralement en faveur des secondes1. Un texte du XVIe siècle donne le ton : il est tiré d’un ouvrage qui eut une fortune européenne, la Civil conversazione de Stefano Guazzo (1574). Les conversations de lettrés dans les académies étaient un moyen simple de s’instruire plus amplement et plus rapidement que par la lecture solitaire des livres : « Le fruit que l’on recueille de ces académies est inestimable et ils sont bien avisés ceux qui y mettent le pied parce que sachant qu’un seul ne peut de lui-même acquérir beaucoup de science […], ils obtiennent là tout ce qu’ils veulent parce que, parlant les uns des histoires divines, les autres des histoires humaines, qui de philosophie, qui de poésie et d’autres matières diverses, ils participent tout à fait de ce que chacun a appris avec peine et au prix d’un long travail ». Ainsi, on apprenait davantage que dans l’étude solitaire ; on apprenait aussi plus facilement, plus vite et mieux. Entrait dans la supériorité des académies, un argument général, « la conversation enseigne plus que les livres », que Guazzo explicitait ainsi : « Et je veux vous dire en plus que ce serait une erreur de croire que le savoir s’acquiert plus dans la solitude au milieu de livres que dans la conversation entre hommes doctes ; parce que c’est une maxime philosophique – et on en a la preuve – que l’on acquiert mieux le savoir par les oreilles que par les yeux […] ; outre que rencontrant dans la lecture quelque obscure difficulté, vous ne pouvez pas prier le livre de vous l’éclaircir, et il vous faut alors le quitter mécontent, lui disant : Si tu ne veux pas être compris, je ne te comprendrai pas. D’où vous pouvez reconnaître qu’il est plus utile de parler avec les vivants qu’avec les morts2 ». Ces arguments vont de soi aux XVIIe et XVIIIe siècles dans les discours que les académies ont tenues sur elles-mêmes ; on ne les explicite plus.

Depuis des chaires et dans des ouvrages, des professeurs ont comparé les deux formes de communication du savoir qu’ils mettaient en œuvre, le cours et le livre, appuyant leur propos sur leur pratique ou sur l’observation de celle d’autrui. Le livre avait pour lui la durée et une plus ample diffusion ainsi que l’avantage de l’exactitude – les maîtres étaient sans illusion sur la qualité des notes prises par les étudiants ; mais, outre l’inconvénient qu’avait pointé Guazzo, il péchait par son uniformité, présentant à tous le même contenu, quand il n’était pas encombré par une masse de faits et de détails qui empêchait l’apprenti de saisir l’important et de s’élever à des vues générales. Dans le processus de transmission des connaissances, le cours montrait toute sa supériorité : cette médiation était non seulement plus vivante et plus agissante, mais encore elle l’emportait en termes de flexibilité et d’adaptation à l’auditoire et surtout elle fonctionnait à l’instar d’un guide qui, dans la masse des faits et des opinions, traçait la voie et l’aplanissait ; elle montrait en un temps limité ce qui devait être retenu et allait, comme l’écrivit au tout début du XXe siècle le grand historien allemand du monde pédagogique Friedrich Paulsen « à l’essentiel, à la réalité, à la vérité3 ». Tout cela se retrouve dans les propos de Farabeuf qui, dans les mêmes années, donnait, pour la chirurgie, l’avantage à l’enseignement du professeur. « Un maître instruit, disert, adroit et bon mime, opérant sous les yeux de ses élèves est le meilleur des livres ». Le livre avait pour seul atout sa permanence ; encore son utilité était fonction d’une présentation calquant celle du cours : il devait être « écrit et figuré avec la préoccupation de rappeler autant qu’il est possible, comme un phonographe et un cinématographe, la parole et les gestes du démonstrateur idéal, parlant et gesticulant à la fois, avec ordre, clarté, sûreté, élégance et rapidité4 ».

Un argumentaire similaire se trouve dans les parallèles qui furent faits entre les colloques aux premiers temps de leur existence, et les livres et revues. Face à la surabondance de la production imprimée, les premiers avaient un atout dans leur caractère « économique » : en peu de temps beaucoup d’informations étaient transmises. De plus, comme le soulignait Jean-Jacques Gourd dans son discours inaugural lors du IIe congrès international de philosophie (Genève, 1904), exposés, discussions en séance, libres conversations avaient dans la communication des idées une force que n’avait pas l’imprimé et ils permettaient de faire saisir « l’élément caractéristique, original, qui devrait agir fortement sur notre esprit5 ». Bien des années plus tard – on est en 1956 –, le format original de la small conference était présenté par Margaret Mead comme le moyen d’aller vite et sûrement dans un monde d’informations de plus en plus dense. « À ceux qui sont épouvantés par le volume croissant des publications ou par la possibilité que la science asiatique ou africaine nous submerge un jour, il est possible de répondre : Non, parce que nous avons mis au point une nouvelle méthode par laquelle ceux qui connaissent un domaine dans un pays peuvent partager rapidement et succinctement les résultats de milliers d’heures de lecture et de travail, parfois en un temps moins long qu’il n’en faut pour incliner ou hocher la tête6 ».

Ce qui valait pour des formes canoniques d’oralité, se retrouve à l’appui de la libre discussion. La formule de Guazzo – « la conversation enseigne plus que les livres » – a une traduction quantitative dans ces remarques fréquentes dans le monde du savoir, dont on donnera un exemple avec le propos de Goethe au sujet du grand philologue allemand Friedrich August Wolf : « une heure d’entretien avec un tel homme valait une année d’études7 ». Peu importe la mesure d’équivalence retenue, la supériorité de la conversation en termes de densité de l’information et de rapidité dans la communication était manifeste. Elle ressort tout particulièrement de situations d’apprentissage. Muratori quand il rendit hommage à son maître Bacchini recourait à ces mêmes arguments. On était pourtant en cette fin du XVIIe siècle dans un temps où les livres désormais nombreux suffisaient à « dégrossir un esprit » ; mais c’était là « un chemin long et difficile ». D’où l’importance pour le novice de « trouver de bonne heure un excellent directeur qui le libère rapidement des faux préjugés et lui instille les préceptes du bon goût […]. C’est là raccourcir de beaucoup le chemin, puisque ce qu’un autre a rassemblé pour lui en y employant bien du temps devient nôtre en un peu de temps. J’étais donc suspendu à la bouche de cet homme très savant dérobant en tout bien tout honneur ce que je pouvais de ses raisonnements familiers8 ». Dans les mêmes années, Louis Joblot mettait en avant l’importance d’une relation personnelle dans l’initiation à la microscopie, dans l’apprentissage du maniement du microscope dit universel : « une explication par écrit, quelque ample qu’elle soit, ne donnera jamais l’intelligence qu’il faut avoir pour conduire toutes les pièces de ce microscope, pour préparer les objets qu’on y peut observer ; […] en deux heures de conversation avec une personne qui en aura l’intelligence, on apprendra plus de choses que l’on ne ferait durant huit jours, d’une lecture qui rebuterait ceux qui ne sont pas accoutumés à lire ces sortes d’explications9 ». Des termes analogues de comparaison ressortent des remarques de Darquier quand en 1786 il mit sur le papier les instructions d’astronomie pratique qu’il avait données de vive voix : « Ce qui était aisé, pour ainsi dire, les armes à la main, devient plus difficile par un détail que l’exemple ne réalise pas sur-le-champ ; et deux mots, dans l’observatoire, l’œil à la lunette, ne sauraient être remplacés par dix pages d’instructions10 ».

Cette vérité d’expérience reçut un cachet scientifique dans des études qui furent faites, principalement aux États-Unis dans les années 1950-1970, sur le sujet de la communication dans le monde de la recherche. Le contexte est celui d’une situation de crise. Les revues, principal organe de la communication scientifique, connurent alors une croissance exponentielle ; dans le même temps, leur coût augmenta, parfois de façon prodigieuse ; leur difficulté à suivre le développement scientifique s’accrut ; s’ajoutaient le constat, avec des taux de lecture inégaux suivant les titres, d’une perte non négligeable de l’information et, moins quantifiable mais tout aussi réelle, l’impossibilité de mettre par écrit tous les éléments d’une recherche. Ces problèmes prirent un caractère d’urgence avec le développement d’une hyperspécialisation, l’instauration d’une mondialisation de la science, l’accroissement d’une compétition aux enjeux multiples. Les études qui furent conduites, principalement dans les sciences de la vie et de la matière, visaient des objectifs de nature tant intellectuelle qu’économique : il s’agissait de rationaliser l’information et d’en déterminer les canaux les plus efficaces. De façon unanime, elles ont conclu à la supériorité de l’oralité informelle, d’une communication de personne à personne ; l’écrit était relégué à une fonction archivale et les réunions (colloques et autres) jugées moins efficaces et de plus en plus considérées comme une perte de temps. Si les canaux formels et informels de l’information étaient jugés complémentaires, les seconds qui procuraient une interaction directe entre les chercheurs démontraient leur supériorité en termes de pertinence de l’information obtenue, d’efficacité, de flexibilité, de rapidité ; ces atouts ressortaient encore du fait que des discussions informelles offraient l’opportunité d’envisager des questions ou des aspects qui initialement n’étaient pas prévus et qu’elles fournissaient immédiatement, sans attendre une présentation formelle, la confirmation qu’un chercheur pouvait désirer dans le cours de son travail.





L’imprimé, le numérique et « l’élément rapidité d’information »


La période qui nous occupe est d’abord marquée par l’apparition et le triomphe du livre imprimé11. Les savants firent, très tôt, l’éloge de la nouvelle invention dans laquelle ils virent le moyen de donner à leurs écrits une vaste diffusion et, si ce n’est l’immortalité, du moins une longue durée12. Ils adoptèrent vite cette technologie et, suivant une expression qui se rencontre au XVIIe siècle, ils firent « gémir les presses ». Leurs publications relèvent des règles de fabrication qui régissent la production imprimée dans son ensemble. Cependant, elles furent munies, à la mesure de leur rôle d’outils, d’un certain nombre d’éléments paratextuels – qui ne sont point exclusifs mais s’y trouvent plus fréquemment et leur donnent une physionomie particulière, les constituant en des systèmes de lecture pertinents13. On prendra un premier exemple, assez représentatif, avec le De re diplomatica de Mabillon (1681), ouvrage fondateur de la diplomatique et, avec cette science, de l’érudition moderne. Après la dédicace et la préface, se trouvait la table analytique des livres et des chapitres. Chaque chapitre qui était divisé en paragraphes numérotés en chiffres romains était précédé d’un sommaire (reproduit dans la table analytique) reprenant le découpage du texte. En marge de chaque page de cet in-folio, étaient placées à intervalles réguliers les lettres repères A, B, C, D, E, F, ainsi que les notes (en fait de simples références abrégées) appelées à la hauteur correspondante par les lettres a, b, c, etc. L’ouvrage s’achevait sur un imposant Index universel, les renvois étant faits très précisément à la page et à la lettre repère. La seule énumération de ces éléments permet de mesurer l’aide qu’ils apportaient au lecteur dans la consultation de l’ouvrage. Plus exceptionnelle est l’architecture de l’Animalium specierum in classes, ordines, genera, species methodica dispositio (Leyde, 1759) de Linné, en correspondance étroite avec le propos de l’ouvrage, comme l’a souligné Yann Sordet ; elle en permet une lecture efficace. « Le corps de l’ouvrage est structuré par le système qu’il expose : le titre courant indique la classe et l’ordre ; les capitulations, numérotées en continu, correspondent aux genres ; et les paragraphes, numérotés à l’intérieur des chapitres, correspondent aux espèces. Les retraits d’alinéa, en début de paragraphe, sont un élément supplémentaire mis au service d’une évidence de la page. Enfin, un index alphabétique des espèces figurant en fin de volume permet un accès direct – et non plus structuré selon la systématique – à l’information élémentaire14 ».

Des éléments tels que tables, index, notes15 se sont imposés dans les publications scientifiques ; leur manque fait sens et pose problème. La fonction des paratextes fut, à l’occasion, expliquée, et des arguments avancés, qui précisent la notion générale de facilitation de la lecture. On s’arrêtera à l’index et à deux éléments typographiques, l’alinéa et le jeu des caractères.

L’index fait partie de ces instruments de repérage que les médiévaux présentèrent comme permettant de trouver une information sans peine et rapidement, voire immédiatement, soit, suivant des expressions latines du XIIe siècle, sine labore, presto habere, citius, voire statim invenire16. Il est entré très tôt dans les ouvrages imprimés et on ne manqua pas de vanter l’avantage qu’il procurait17. Ainsi, l’avertissement d’une édition bolonaise des Trionfi de Pétrarque (1475) présentait l’index comme permettant au lecteur de « trouver d’un coup ce qu’il désirait voir, sans beaucoup se fatiguer à chercher et sans avoir à remuer tout le livre ». Les index s’imposèrent rapidement dans les ouvrages imprimés ; leur présence est parfois annoncée dans le titre même du livre, mentionnant un ou plusieurs index (par exemple, de noms, de choses) et vantant leur richesse (cum locupletissimis ou copiosissimis indicibus). Les éditions de correspondances savantes publiées aux XVIIe-XVIIIe siècles furent dotées d’index, le plus souvent au nombre de trois (par correspondants, par noms de personnes, par noms de choses) ; avec les sommaires, parfois placés en tête de chaque lettre, ils permettaient d’éviter des lectures longues et fastidieuses18. Ce n’est pas moins de quatre index que Morgagni dressa pour le De sedibus et causis morborum per anatomen indagatis (1re éd. : 1761), ouvrage fondateur de l’anatomie pathologique. Le premier, très court, était une sorte de table des matières du livre ; les trois autres étaient par ordre alphabétique, les entrées pouvant être très détaillées : le quatrième relevait des noms propres et « autres choses remarquables » ; le deuxième indiquait les maladies, les symptômes, leurs causes externes, les âges, le genre de vie, les professions et autres choses similaires, le troisième les lésions observées sur les cadavres à l’intérieur et à l’extérieur. Ces deux index-ci étaient les plus importants et pas seulement par leur longueur ni le détail et l’organisation interne des entrées, mais par leur fonction éminemment pratique dans un savoir nouveau établissant qu’à chaque altération anatomique correspondait une altération fonctionnelle s’exprimant par une maladie. Morgagni avait fait ces deux index « moins pour que l’on puisse retrouver facilement les observations contenues dans cet ouvrage, mais pour une utilité bien plus grande. L’un indique ce qui a été observé pendant la vie, l’autre après la mort ; de telle sorte que si un médecin ou un anatomiste, remarquant, l’un un symptôme singulier ou autre de la maladie, l’autre une lésion sur le cadavre, veulent savoir à quelle lésion interne répond le plus ordinairement le symptôme, ou quel symptôme a précédé la même lésion dans d’autres cas analogues, ils trouveront sur-le-champ, ne jetant les yeux celui-là sur le premier [index], celui-ci sur le second, l’observation qui rend compte de tous les deux, si je les ai observés tous les deux. Cela sera d’autant plus facile que, quand j’ai été obligé de m’étendre sur ces objets, je ne les ai pas indiqués sans un certain ordre19 ».

Des chercheurs ont aussi fait des index de livres imprimés, soit que ces publications n’en avaient pas, soit que les index existants ne leur suffisaient pas20. Il en est aussi qui ont fait des index de leurs propres notes afin d’abord de s’y retrouver facilement, tel Faraday qui, de surcroît, se défiait beaucoup de sa mémoire21. Joseph J. Hobbs, ce géographe américain, spécialiste d’écologie culturelle, que nous avons vu partir sur le terrain chargé d’un lourd barda, transcrivait chaque soir ce qu’il avait enregistré au magnétophone durant la journée tant pour éviter par la suite un travail fastidieux que pour faire immédiatement d’éventuelles vérifications. Il indexait quotidiennement aussi ses transcriptions, d’abord manuellement puis, à partir de 1997, à l’ordinateur. Au terme de chaque séjour sur le terrain, il avait en mains un « journal courant » et « un journal trié par sujets ». Non seulement cela se traduisait par un gain de temps pour de futures publications – la matière était déjà classée dans le second produit –, mais encore l’indexation, en faisant ressortir des associations, était le gage de nouvelles idées qu’il pouvait immédiatement explorer lors d’entretiens tant qu’il était encore sur place22.

La typographie fut un moyen de faciliter la lecture, en donnant à voir un raisonnement sur le papier. L’alinéa fut présenté par Guez de Balzac qui en fit un usage pionnier dans Le Prince (1631) comme « une chose qui aide extrêmement celui qui lit et démêle bien la confusion des espèces23 ». Ce que disait un grand siècle et demi plus tard (1793) l’imprimeur Momoro qui le définissait comme « un discours coupé qui se fait pour reposer le lecteur et faciliter l’intelligence d’un ouvrage24 ». La diversité des caractères joue au même effet. Le journaliste Pierre Des Maizeaux, retraçant l’histoire de ce « petit rien » qu’était l’italique, montrait comment un usage excessif avait fait perdre de sa fonction à « ce moyen de distinction » ; on ne pouvait plus saisir immédiatement ce qui était citation et pensée de l’auteur25. Autre rôle des caractères : leur emploi différencié dans un index fonctionne comme un système d’aiguillage rapide. Ainsi, dans le volume consacré à la musculature des mammifères (1971) du Traité de zoologie du Pr Grassé, un numéro de page en romains gras renvoyait à la page où un muscle était décrit, en romains maigres où il était mentionné, en italiques maigres où il était figuré ; du jeu typographique, le lecteur pouvait immédiatement conclure au type d’information qu’il trouverait – une description, une mention, une figure26.

Un inventaire détaillé de tous « les éléments graphiques » composant le livre – du titrage à l’index en passant par la mise en page – fut dressé par Paul Otlet dans son Traité de documentation. Il en souligna, outre la variété, le caractère éminemment fonctionnel. Ils devaient permettre au lecteur de procéder aisément et sûrement, de passer tout ce qu’il juge superflu, de voir d’un seul coup d’œil l’intérêt du livre ou d’une de ses sections, voire de ne pas être gêné par des opérations de manipulation : ainsi, Otlet signalait le « dispositif innovant » d’un index en dépliant27.

Si l’on a fait en sorte d’équiper, typographiquement parlant, le livre afin d’en faciliter la lecture, il est arrivé, au même effet, qu’on le dépouille de tout ce qui pourrait l’encombrer. La reliure mobile sert à cela : munie d’un système à pinces ou à anneaux, elle permet d’adapter le contenu d’un ouvrage à l’évolution du savoir, de le mettre à jour, ce qui signifie d’abord ôter ce qui est périmé ; cette solution simplifie la tâche du lecteur et lui évite la perte de temps que serait se reporter à des suppléments. Elle a été largement adoptée par les répertoires juridiques28. Elle fut aussi choisie par l’Encyclopédie française, encyclopédie méthodique publiée à partir de 1935 sous la direction de Lucien Febvre et Anatole de Monzie. Elle répondait au propos de l’ouvrage qui se voulait « un répertoire actif et non inerte » et, comme l’a noté Jean-Yves Mollier, elle se révélait « adaptée à son époque et à ses besoins, la vitesse s’étant emparée de tous les domaines et de tous les esprits29 ».

Quels que soient les aménagements apportés, le livre n’a pas manqué d’apparaître comme un produit lent et lourd ; d’où très tôt des projets de livres uniques présentant de façon abrégée et ordonnée l’ensemble des connaissances. Nombre d’entre eux restèrent de splendides idées, tels ceux formés par Leibniz qui visaient d’abord à « abréger le temps ». Mais, il en est qui se traduisirent dans la réalité, par exemple l’Encyclopédie de Diderot et d’Alembert présentée par ses promoteurs comme pouvant « tenir lieu de bibliothèque dans tous les genres à un homme du monde, et dans tous les genres, excepté le sien, à un savant de profession30 ». On passera sur les aspects d’ordre intellectuel pour en rester à la matérialité des choses et à un produit de type nouveau que, dans ses réflexions sur la rationalisation du livre, Paul Otlet conçut en 1911. Ce livre – « car c’est encore un livre » – n’aurait plus la « disposition traditionnelle en texte linéaire disposé sur un plan unique », mais il serait composé de fiches octogonales percées d’un trou au centre et portant sur leurs côtés des saillies correspondant à des indexations. Il prenait une forme quasi circulaire et devenait rotatif : il se trouvait « transformé en quelque sorte en un corps à plusieurs dimensions, à autant de dimensions que d’entrées différentes et permettant de faire servir à des recherches différentes les mêmes éléments graphiques ». Alors que la masse innombrable des livres augmentait la difficulté à en extraire les connaissances, ce nouveau produit joindrait les avantages de la rapidité puisque le tri des fiches qui le composaient pourrait être fait par des machines à sélectionner31.

La « lenteur » du livre ressortit de ce concurrent que fut le périodique qui, depuis 1665, date de création du Journal des savants, se multiplia avec succès. Généraliste ou spécialisé, il afficha une ambition de rapidité dans la communication de l’information. Prenons l’exemple des Observations sur la physique, sur l’histoire naturelle et sur les arts (1773) de l’abbé Rozier. Alors que les collections des sociétés savantes ne publiaient les mémoires que bien des années après leur lecture, cette revue leur assurerait une diffusion en temps utile ; non seulement elle véhiculerait vite l’information – la périodicité était mensuelle – mais, ce faisant, elle éviterait que les savants perdent du temps à refaire ce qui avait été déjà fait et trouvé ailleurs. De plus, rassemblant des résultats et leurs preuves, elle permettrait au lecteur de voir d’un coup d’œil la progression des faits conduisant à l’établissement de vérités importantes32.

D’emblée les journaux savants furent, comme les ouvrages, munis d’index qui, par volume ou par année, donnaient un accès sûr et rapide à l’information qu’ils contenaient. Des tables furent aussi dressées couvrant plusieurs années – 85 pour la Table générale du Journal des savants (1753-1764, 10 vol.). L’Avertissement en tête de la publication rappelait les termes du projet qui avait été initialement formé : dresser « des tables exactes » et que « l’ordre en fût simple et facile, en sorte qu’en rapprochant sous un même point de vue les matières qui y sont répandues, le lecteur puisse aisément trouver ce qu’il y cherchera ». La réalisation était présentée en ces termes : « le savant, l’homme de lettres, l’historien, enfin tous les genres de lecteurs y trouveront un secours d’autant plus nécessaire qu’il abrégera de grandes recherches, souvent importunes, fatigantes et parfois inutiles ». Des exemples étaient donnés pour montrer comment les entrées avaient été composées : brièveté, commodité, clarté avaient été les principes directeurs.

Dans le grand mouvement de création de périodiques spécialisés qui eut lieu au long du XIXe siècle s’observe, entre autres, le souci de suivre au plus près le progrès rapide des connaissances dans la discipline soit, selon une expression aussi usuelle qu’éloquente, de « tenir au courant » un lecteur qui ne peut plus faire individuellement ce travail. C’est ce que disaient dans leurs avertissements la Revue archéologique (1844), la Revue historique (1876), la Nouvelle revue historique de droit français et étranger (3e série, 1877) ou les Annales de géographie (1892). Il en ressortait que les ouvrages généraux étaient incapables de saisir l’évolution des choses ; le lecteur qui s’en contenterait serait, pour la Revue archéologique, « en arrière ». Face au progrès des savoirs, le livre parut de moins en moins adéquat ; ce qu’écrivait en 1905, un professeur de physiologie à la faculté des sciences de Paris : « Les livres se font trop lentement pour rester au courant d’une science qui marche très vite. Aussi est-ce dans les périodiques qu’il faut suivre le mouvement, en lisant à mesure le compte rendu des travaux en cours33 ». Dans cette perspective, le périodique devait éviter tout ce qui pourrait retarder une marche rapide. Le prospectus publié en tête du premier numéro de la Revue zoologique (1838) explicitait l’absence, a priori surprenante, de figures. Alors que l’on offrait ici aux chercheurs « un moyen facile de publier promptement l’analyse de leurs découvertes », des images contrarieraient cet impératif qui était de prendre date : on rappelait que « le mode de publication offert par les journaux à figures est nécessairement plus lent à cause du temps qu’exige l’exécution des planches ; or pendant ce temps, on peut être devancé ».

Les journaux scientifiques se multiplièrent tout au long du XIXe siècle, et leur masse commença à poser problème. Leur nombre, même dans un domaine étroit, constituait un premier inconvénient : on déplorait le temps perdu à les feuilleter ne serait-ce que pour s’informer. En 1898, paraissait sous les auspices de l’Institut international de bibliographie de Paul Otlet et Henri La Fontaine, aussi les promoteurs de la classification décimale universelle (CDU), le projet de « revue à découper ». Son auteur, Charles Didier, rappelait que la base du travail scientifique (ici étaient particulièrement visées les sciences appliquées) était désormais l’article de revue qui l’emportait sur le livre « déjà démodé lorsqu’il vient de paraître ». Cependant, les revues impliquaient « une manipulation constante d’une quantité de volumes : d’où perte de temps, impossibilité d’emporter avec soi un dossier, etc. ». Lui-même pratiquait « des coupures », ce qui n’allait pas sans un inconvénient : quand on découpait un article, on en mutilait un autre. D’où son projet de « revue à découper » consistant à imprimer les articles de plusieurs pages en fascicules indépendants, et les petits articles, notes, etc. sur un seul côté de page, l’autre étant occupé par des annonces qui pouvaient être mutilées sans perte. Chaque unité à découper porterait une indication abrégée de la revue et de la date ainsi qu’un indice décimal grâce auquel regrouper méthodiquement les « découpures ». Ce « mode plus rationnel de publier les articles de revues » en leur donnant « une forme scindable et classable » permettrait au lecteur « d’avoir à tout moment, tout prêt, sous la main, sous une forme condensée, maniable, l’ensemble le plus complet possible des derniers documents parus sur une question » ; il servirait au mieux « l’élément rapidité d’information » qui, dans les sciences appliquées, était essentiel. On ne sait quel sort eut ce projet. Toutefois, dans ces mêmes années l’impression sur le seul recto se fit pour des bibliographies, ce qui permettait ensuite de découper des notices et de les coller sur des fiches34.

Le XXe siècle a vu une croissance exponentielle du mouvement de création des périodiques. Présentés au siècle précédent comme la solution « pour rester au courant d’une science qui marche très vite », ils révélèrent leurs limites quand celle-ci se mit à aller plus vite encore. Les délais d’édition étaient lourds de conséquences, et la crainte s’exprimait que l’article ne soit périmé lorsqu’il était enfin publié. Ce sont là les conclusions d’études menées sur le sujet de la communication scientifique dans les années 1960-1970. En conséquence, on s’employa à diminuer le temps s’écoulant entre la soumission de l’article et sa publication. À la fin des années 1960, on a créé des revues for rapid communication, et certains journaux ont mis en place une section express où étaient publiés des résumés des articles dès leur acceptation35. Avec l’électronique, les délais de fabrication et de diffusion se sont raccourcis, ainsi que tout ce qui touche à la correspondance avec les auteurs et les réviseurs. Restait à réduire l’étape initiale, de la soumission par l’auteur à l’acceptation par la revue, y compris les éventuelles révisions par les auteurs. Ecology Letters (fondé en 1998) a ramené la décision éditoriale à une moyenne de trente-trois jours, et le délai entre l’envoi du manuscrit et sa publication à environ dix semaines ; cette rapidité – que l’on appréciera encore davantage au regard des 1 400 manuscrits annuellement reçus – n’est pas sans expliquer le succès de cette publication, aujourd’hui la référence internationale en la matière36.

Le nombre même des périodiques avait commencé dès la seconde moitié du XVIIIe siècle à poser le problème de l’accès à une masse de données dispersées. Des journaux d’abstracts se créèrent – on en a compté quelque 310 entre 1780 et 1920 – fournissant de façon périodique sous une forme synthétique la littérature sur un sujet (notamment, sciences et médecine). Quels que soient leur contenu et leur forme, ils se présentèrent invariablement comme un moyen aussi économique que rapide de mise à disposition de l’information ; l’abstract lui-même au début du XXe siècle tendit à évoluer d’un format long et discursif vers un format bref et informatif. Ces remarques valent au premier chef pour la publication majeure du genre, les Chemical Abstracts qui, fondés en 1895, ont offert une couverture de plus en plus large des publications dans la discipline et, par là même, tendu à fournir dans un seul répertoire toute l’information utile. L’informatique a accéléré le travail d’indexation ; si un temps, les chimistes ont dû passer par un bibliothécaire pour consulter les bases de données des CA, avec la diffusion des micro-ordinateurs, ils peuvent y accéder directement, sans formation particulière, gagnant ainsi en rapidité et en précision dans la recherche de l’information37. Il y a là des remarques qui ressortissent plus généralement à la démarche bibliographique dont l’un des motifs, depuis d’ailleurs, les premiers répertoires de livres du XVIe siècle, est de permettre de retrouver l’information sur-le-champ (statim), d’un seul coup d’œil (uno intuitu38).

Unité de base des périodiques scientifiques, l’article s’est trouvé réglé au XXe siècle suivant le format dit IMRAD. Si cette disposition est contraignante, elle constitue aussi un système de lecture qui permet de localiser au plus vite le type d’information qui intéresse. Ce schéma efficace s’appuie aussi sur les ressources de l’image dont la part est de plus en plus importante, et il intègre un type d’écriture particulièrement performant. On reviendra sur ces deux aspects dans les sections qui suivent. Restons à l’IMRAD et ses paratextes. Titre, résumé, mots-clefs constituent autant de voies d’accès rapides au contenu, plus précisément de niveaux de lecture permettant de se rendre compte, avant d’arriver à l’article même, s’il vaut la peine d’être lu en son entier ou dans une de ses sections. Leur composition a donné lieu à réflexions et à propositions afin de les faire fonctionner au mieux39.

Au fil de ce développement sur l’imprimé, le livre, la revue et leurs équipements, on voit se déployer à l’appui de tel ou tel produit, de tel ou tel élément, un argumentaire qui se cristallise autour de la rapidité dans l’accès à l’information. On comprend ici l’échec dans le monde scientifique de cette technologie que fut la microforme (microfilm et microfiche). Utilisée dans les bibliothèques dès les années 1930, elle fut considérée comme une excellente solution de stockage et de conservation des documents, étant, de surcroît, peu coûteuse. Les lecteurs, eux, en ont jugé différemment, même avec les perfectionnements des appareils de lecture. Leur résistance s’est alimentée à de multiples raisons qui, pour plusieurs, ont comme facteur commun la perte de temps : la nécessité de se déplacer jusqu’à l’appareil de lecture qui, de surcroît, offre une lecture peu ergonomique ; la difficulté d’aller facilement et rapidement d’un passage à un autre du texte, et encore plus de « feuilleter » ; l’impossibilité de comparer deux documents à moins de disposer de deux appareils côte à côte ; la manipulation de plusieurs microfiches pour un même document40. Ce constat ancien – il date de 1975 – est toujours valable ; peut-être même s’est-il renforcé à l’ère du numérique.

Alors que la communication scientifique était affrontée à une masse d’information croissante, qu’elle soit véhiculée par les livres, par les périodiques ou par la littérature grise, la nouvelle technologie montra vite ses avantages. Ils ressortent des comparaisons multiples faites avec l’imprimé. Le numérique, dans son formidable développement, a aussi suscité un volume inouï de données qui s’augmente chaque jour à un rythme exponentiel. Ce qui a porté à l’élaboration d’outils, eux aussi, nouveaux. On l’a vu au chapitre 1. On n’y reviendra pas. On insistera ici sur l’aspect « économique » de la technologie et de ses moyens, et l’on s’en tiendra à quelques repères dans un monde dense et qui, lui aussi, change vite. Ainsi, le cédérom qui parut la solution rapide, facile et économique, pour la mise à jour de répertoires (par exemple, en droit) ou pour la publication de données (par exemple, la documentation archéologique), a cédé devant l’usage de l’Internet, ne serait-ce qu’en termes de temps, le cédérom figeant les données et étant de consultation médiate41.

L’ordinateur fut initialement utilisé pour du calcul puis, au cours des années 1980, pour du traitement de texte et pour le travail d’édition scientifique. Permettant les modifications dans un texte et une gestion aisée des notes, évitant de retaper le document pour la mise au net et pour la publication, il signifia un gain de temps appréciable42. Il en a été de même pour le courrier électronique. Solution économique, simple et facile d’utilisation, il a accéléré les échanges : l’envoi se fait sans qu’il soit besoin de se déplacer et le message circule en temps réel. Cet avantage de rapidité dans la communication l’a emporté sur les inconvénients que la technique elle-même (ou plutôt un usage déviant) a contribué à engendrer, soit, pour en rester à l’ordre temporel, l’envoi trop précipité de courriels, une rédaction hâtive et parfois alors ambiguë, le ralentissement que peut susciter un déluge de messages reçus43.

L’ordinateur apparut aussi la solution face à la masse croissante des informations, par exemple, en médecine où dans les années 1960 les spécialistes se trouvèrent submergés par le flot des données que leur fournissaient des technologies de plus en sophistiquées et la littérature qui les évaluait et les discutait. Seule, la « machine » pouvait stocker de telles quantités de données, les trier et les analyser. Pour l’auteur d’un ouvrage paru en 1966 sur l’introduction de l’automation en médecine : « N’importe quel ordinateur fera en moins d’une heure ce qu’un homme avec un stylo et du papier fera en une année44 ».

Quel que soit l’équivalent-temps indiqué, une accélération des processus est un constat largement partagé au-delà des disciplines et des usages. En 1995, la communauté enseignement et recherche, livrant un état des lieux ainsi que des témoignages sur l’Internet, concluait en termes positifs, voire élogieux quant aux nouveaux outils et produits dont les chercheurs pouvaient désormais disposer. L’argument de la rapidité dans la recherche et la diffusion de l’information, joint à ceux de la simplicité et du moindre coût, était celui qui se faisait le plus entendre ; il jouait à plein dans une démarche qui serait critique (face à des informations non validées) et dans une gestion rigoureuse du temps (pour ne pas le perdre). Les revues électroniques l’emportaient sur les revues papier qui étaient dites « lentes ». Aux nouveaux périodiques ne manquaient plus que prestige et légitimation45. Sept ans plus tard, alors que les produits et les services numériques s’étaient multipliés, les réticences face à tel ou tel outil ressortissaient moins à un refus qu’à une exigence d’amélioration afin de pouvoir trouver, au moment voulu et le plus rapidement possible, l’information souhaitée46. Une enquête menée à l’université Paris-Dauphine (économie, gestion) montrait que le support (papier, cédérom, numérique) en tant que tel importait peu au chercheur. Celui-ci conservait bien un attachement pour les revues classiques, mais ne consultait plus les bibliographies papier. En conclusion, se dégageait l’idée que « la rapidité et la facilité d’accès sont primordiales » ; d’où la demande faite à la bibliothèque de nouveaux services dont la veille et « l’accès le plus rapide et le plus transparent à une information personnalisée et pertinente47 ». En 2008, alors que la documentation numérique s’était banalisée, sa supériorité sur la documentation imprimée était ainsi résumée : « elle est certainement, avec la puissance de l’informatique, beaucoup plus repérable, emmagasinable, transférable et accessible » ; et ce dernier terme signifiait aussi un avantage majeur pour l’utilisateur : avoir tout sur son bureau, voire chez lui, sans se déplacer48.

Le chercheur a désormais à sa disposition une gamme de produits et d’outils dont le maniement – correct et maîtrisé – accélère les procédures de recherche. Qu’il s’agisse de catalogues numérisés, de bases de données, de bibliothèques numériques, de plateformes ou de portails, il trouve là réunie une masse documentaire parfois colossale et il y accède aussi simplement que rapidement en quelques clics ; des outils de veille et d’alerte permettent, pour un domaine préalablement défini, d’être automatiquement et directement informé. Ces réalités étant des plus familières, on se bornera à quelques exemples en objectivant une efficacité, qui va souvent de soi.

On prendra d’abord un outil généraliste d’utilisation courante : le Karlsruhrer Virtuelle Katalog (KVK), méta-interface de recherche qui donne accès à un nombre considérable de catalogues numérisés de bibliothèques dans le monde entier ainsi qu’à des catalogues commerciaux ; à l’heure actuelle, il répertorie environ 500 millions de titres de monographies et de périodiques. Il a été développé par la Bibliothèque universitaire de Karlsruhe à partir de 1976 et est accessible via Internet depuis juillet 1997. Il a reçu en 2012 une valeur ajoutée des plus précieuses pour le chercheur en commençant à signaler les ressources numériques de tous types. Pas besoin d’insister sur le gain de temps que permet le KVK qui, de surcroît, traite les requêtes en des dixièmes de secondes comme l’indique le temps qui s’affiche à côté de la réponse.

Un second exemple est fourni par les portails documentaires. Ils dateraient de la toute fin des années 1990. Ils fournissent un accès unique à une masse d’informations d’origine et de type différents ; en une seule requête, l’usager consulte plusieurs sources de données. Le développement même d’Internet portait à la création de cet outil. C’est ce qu’exposait en 2000 une association d’enseignants-chercheurs formant le projet d’un portail généraliste afin de mutualiser les ressources, d’éviter la déperdition de l’information et d’affranchir la recherche des frontières disciplinaires. Une enquête avait mis en évidence comme première source (et de loin) d’insatisfaction lors des recherches sur Internet : « problèmes de temps trop long, lenteur, bruit, référencement, dispersion des informations, non-coordination des sites, éparpillement… ». Un portail fédérant les moyens, permettant de « tout trouver au même endroit », serait le gage de « gains de temps49 ». Ce projet ne fut, semble-t-il, pas mené à bien. Depuis lors, de très nombreux portails ont été créés ; donnant accès par un point d’entrée unique à de très grandes quantités d’information, ils sont d’utilisation simple, intègrent des outils de recherche performants et des fonctionnalités telles que la personnalisation des recherches et des systèmes de veille. La réunion en un seul lieu d’une information nombreuse et hétérogène est économie de temps, et doublement comme il ressort de la présentation du portail de veille documentaire de la bibliothèque Durkheim (sciences sociales) de l’ENS Cachan ouvert en 2011. Après avoir souligné l’importance et la variété de la documentation offerte, on insistait sur la rapidité et l’actualisation de l’information qu’il fournissait : il permettait de « connaître en un clin d’œil les dernières actualités » de différents sites tout en proposant « les dernières mises à jour » des sites consultés50.

Troisième exemple : les bibliographies. Instrument de travail fondamental, elles ont mis à profit la nouvelle technologie qui s’est avérée encore plus précieuse pour les répertoires courants dont le propos est de saisir l’information au plus près de sa production. L’Index Medicus, qui s’était automatisé en Medlars (1964), avec déjà un gain de temps notable, est devenu à son passage en ligne en 1971 Medline. Cette base de données indexe aujourd’hui plus de 5 000 journaux de médecine et surtout de biomédecine, la mise à jour étant quotidienne ; de surcroît, elle offre une série de services facilitant et accélérant la recherche de l’information : outre des filtres divers, des alertes, des liens vers des articles sur le même sujet, des abstracts, des citations et des comptes-rendus d’articles, ainsi que le renvoi vers le texte de l’article qui intéresse51.

Le dernier exemple est celui du produit le plus commun dans le monde scientifique : les revues. Elles sont, pour un très grand nombre, passées au numérique, totalement ou sous une double présentation, qu’elles soient nées numériques ou qu’elles le soient devenues. Elles se sont généralement dotées d’un site donnant des tables, des résumés, annonçant le numéro à paraître, permettant parfois des recherches rétrospectives et fournissant, à titre gratuit ou onéreux, le texte des articles. Des plateformes comprenant un plus ou moins grand nombre de revues permettent grâce à un moteur de recherche d’interroger l’ensemble. En devenant numérique, l’article de recherche a conservé son format, mais il s’est doublé d’un second niveau, qui, dans le cas d’éditions papier et électronique, n’apparaît qu’à l’écran, soit : en tête, une table des matières avec des liens aux différentes sections de l’article ; des liens avec des articles sur le même sujet dans la revue ; des liens avec les références citées dans le texte qui peuvent être appelées d’un clic sur leur numéro, tout comme depuis les références on peut accéder à l’article ; des hyperliens dans la bibliographie renvoyant pour les articles mentionnés aux citation records et parfois à l’article cité ou à son abstract ; à la fin de l’article, sous la rubrique « Information complémentaire », un ensemble d’informations scientifiques relatives aux méthodes et aux résultats, utiles aux chercheurs, ou s’adressant à un autre public (par exemple, une vidéo de vulgarisation). En conséquence et pour en rester aux chercheurs, le journal électronique ou ayant une version électronique peut publier un texte allégé de lecture plus rapide, tout en offrant à l’expert un ensemble de données de recherche et d’informations bien plus nombreuses que dans la version papier ; il lui fournit même dans la section « Information complémentaire » par le jeu des hyperliens « une petite bibliothèque de la littérature sur le sujet52 ». En contraste avec le large passage des revues scientifiques au numérique, le livre en sciences humaines et sociales demeure largement un produit papier53. Les exceptions sont mises en évidence, telle l’encyclopédie en ligne Sociopedia lancée en 2007-2008 sous les auspices de l’Association internationale de sociologie. Elle publie des entrées assez longues qui sont revues par au moins deux lecteurs et seront actualisées au fil de l’évolution des savoirs. L’un de ses promoteurs la présentait en 2010 comme « un concept nouveau » alliant « la rapidité et souplesse qu’offre Internet » à la rigueur scientifique des procédures ; et il en soulignait sa différence avec les encyclopédies classiques sur papier qui n’offrent que des « textes datés », un « contenu vite vieilli, jamais mis en débat54 ».

Rapidité et simplicité connotent donc bien des outils que la nouvelle technologie a mis à la disposition de chercheurs, et pour un dernier exemple, on citera cette modalité de la communication scientifique qu’est le carnet de recherche. Il est présenté sur la plateforme d’hébergement Hypothèses.org (sciences humaines et sociales) comme « un mode de publication rapide et léger permettant de rendre compte régulièrement de recherches en cours, […] de dialoguer avec ses lecteurs par le biais des commentaires. Il repose […] sur l’utilisation d’un outil simple, ne nécessitant pas de connaissance informatique particulière ».

Ces caractéristiques, on les a vues invoquées tout au long de notre parcours depuis la naissance du livre imprimé. Encore ressortent-elles de ces petits carrés de papier manuscrits que l’on peut voir collés sur ce symbole de la modernité qu’est l’ordinateur. Les post it expriment la volonté de l’usager d’aller simplement et vite (et l’écriture y est souvent rapide, abrégée, informe), et ils répondent d’autant mieux à cette double exigence qu’ils ont leur affordance, c’est-à-dire qu’ils s’utilisent sans apprentissage ni effort55. Cela, Gabriel Naudé le revendiquait déjà en 1627 en soulignant l’avantage des solutions qu’il proposait pour la disposition et le catalogage des livres, quand la rapidité d’accès allait de pair avec sa sûreté et sa facilité – « sans labeur, sans peine ». Dans les débuts du numérique, il a été noté, chez les chercheurs, une réticence à l’emploi des nouvelles ressources liée à la crainte du temps qui serait passé en une formation ; et cette attitude a perduré56. Les notions de temps, efficacité et simplicité restent des arguments régulièrement avancés pour ne pas se confronter à des outils nouveaux ; il en ressort une méconnaissance de la typologie et du champ d’application des instruments à disposition. Cela ressort de l’emploi routinier d’un moteur de recherche généraliste – Google – en dépit du « bruit » qu’il occasionne. Il est vrai que, permettant de façon simple une interrogation libre via des mots-clés approximatifs et fournissant toujours des réponses, il donne à l’usager une confiance qui le dissuade d’investir du temps dans l’apprentissage d’instruments spécialisés. Sans parler du bouton « J’ai de la chance », il nourrirait même un sentiment de hasard heureux dans la recherche, une forme de sérendipité57. Quoi qu’il en soit, cette sorte de « déclic » serait une illustration de plus de l’élément rapidité qui, dans la navigation sur l’océan des données, a caractérisé les pratiques savantes tout au long des cinq siècles ici étudiés.





« Une image vaut mille mots »


Les données, ce sont des mots, mais aussi des images, une masse d’images qui n’a fait que croître en nombre et variété, ne serait-ce qu’au fil des évolutions technologiques. En cela même, la culture savante apparaîtrait déjà comme une culture visuelle, si l’on oubliait le statut de document scientifique qu’elle a accordé à l’image58 – à l’instar des discours oraux et imprimés mais en mieux, comme l’indiquerait l’aphorisme cité au début de cette section. Formule « rapide » qui proclame le caractère économique de l’image, et que l’on trouve développée dans des textes permettant d’en apprécier le contenu et d’en mesurer la portée.

Un graphique vaut « 700 mots » pour Edward Tufte ; un manuel d’histologie contemporain fait la part belle à l’illustration (plus de 650 photos et schémas) selon le principe « une image vaut mieux qu’une centaine de mots » ; dessiner sur les radios est pour les professeurs de radiologie préférable à montrer avec un pointeur car « une image vaut vraiment un millier de mots » ; quant aux produits de l’infographie, « si une image vaut mille mots, ils valent un nombre énorme de points de données59 ». On trouve une variante – et une explicitation – de la comparaison sous la plume du géographe Jean Brunhes écrivant en 1914 : « Telle image en dit plus que des dizaines de pages ; elle dit ce qu’elle dit autrement et avec une clarté spécifique qui est la sienne ; elle exprime des idées sous une forme concrète et saisissante qui rend ces idées mêmes plus vivantes et qui les hausse en vérité60 ».

Sans que la comparaison soit utilisée, l’emploi de l’image dans les ouvrages scientifiques s’est trouvé justifié et légitimé en soulignant sa supériorité par rapport au discours écrit ou oral. Et très tôt. En 1542, le botaniste Leonhardt Fuchs, anticipant pour les 512 xylographies contenues dans son De historia stirpium d’éventuelles critiques – les réserves restaient fortes quant à une représentation figurée des plantes –, écrivait dans l’épître dédicatoire : « Qui est celui qui, sain d’esprit, condamnerait les images qui peuvent communiquer l’information de façon bien plus claire que les paroles, y compris du plus éloquent des hommes ? […] Les choses qui sont présentées aux yeux et figurées sur des panneaux ou du papier se fixent de façon plus ferme dans l’esprit que celles décrites avec les mots nus61 ». En 1686, Edmond Halley publiait dans les Philosophical Transactions un article sur le régime des vents alizés qu’il accompagna d’une carte, ce qu’il expliquait ainsi : « Pour aider la compréhension du lecteur dans une matière d’une si grande difficulté, je juge nécessaire de joindre un schéma montrant en une seule vue toutes les étendues et directions de ces vents ; il permettra que la chose soit mieux comprise que par quelque description verbale que ce soit62 ». En 1704, Morgagni dans la publication qu’il assura du De aure humana tractatus de son maître Antonio Maria Valsalva justifiait l’utilité des 42 figures accompagnant cet ouvrage qui marqua une avancée notable dans la connaissance de l’anatomie et du fonctionnement de l’oreille humaine : elles « aidaient à saisir immédiatement ce qui dans des descriptions ne se comprenait que lentement ou pas du tout » ; d’autant que les descriptions pouvaient parfois sembler un peu obscures alors que des parties de l’oreille étaient difficiles à décrire et que le traité contenait bien des choses nouvelles63. En 1746, l’éditeur et traducteur français du Medicinal Dictionary de Robert James justifiait l’importance des planches : « Les descriptions les plus vives et les plus justes ne donnent jamais des idées aussi nettes et aussi précises que celles que l’on peut prendre d’un seul coup d’œil64 ». En 1754 paraissait la Natural History of Carolina, Florida and the Bahama Islands du naturaliste anglais Mark Catesby, première description de la flore et de la faune d’Amérique du Nord ; dans la préface de ce gros ouvrage anglais-français qui contenait des planches nombreuses – 220 – et en couleurs, il mettait en évidence le soin qu’il avait eu « d’enluminer les dessins » : « je puis assurer qu’on se formera une meilleure idée des plantes et des animaux en les voyant représentés avec leurs couleurs naturelles que par la description la plus exacte sans le secours des figures65 ». En 1821, le chirurgien anglais Charles Bell soulignait dans sa préface aux Illustrations of the Great Operations of Surgery l’importance majeure de l’image dans la transmission du savoir en la matière : « pour ce qui touche à la description, les mots seuls n’informeront jamais le chirurgien des choses les plus nécessaires pour une opération sûre66 ». En 1871, Lionel Beale qui, par de multiples initiatives promut une médecine scientifique, lançait les Archives of medicine ; dans ce périodique, il donnait la première place à l’image : « J’introduirai des illustrations copieuses, étant persuadé que des dessins sont bien plus utiles que de longues descriptions » ; en conséquence, « le texte serait aussi court qu’il est compatible avec un clair exposé des faits67 ».

Dans la dernière décennie du XIXe siècle, alors que la photographie était l’objet d’un grand engouement dans l’illustration médicale, des médecins notaient son efficacité sans égal : « un coup d’œil apprend plus que des pages de description », disait l’un d’eux. Un autre, plus nuancé, ne serait-ce que face à la multitude de détails qui étaient figurés sur les photos – « un chaos », ne concluait pas moins à la supériorité qu’elles avaient sur le texte : « Comme un croquis souvent complète, voire remplace, une interminable description topographique, dans des cas qui sont difficiles à décrire, une bonne image photographique à laquelle un bref commentaire est ajouté peut dire plus qu’une encombrante description68 ». Les Drs Maxence Deguy et André Guillaumin présentaient leur Traité de microscopie clinique (1906) destiné à des médecins et des pharmaciens désireux de faire leur « éducation en diagnostic microscopique », comme « à la fois un traité et un atlas, plus un atlas qu’un traité ». Le « traité » avait sa valeur alors qu’il condensait en un volume toute la littérature sur le sujet ; cependant, il venait en importance après l’atlas et ses 93 planches en couleurs : car « la description la plus minutieuse et la plus précise du fait observé ne vaut pas la représentation visuelle69 ». L’article de méthodologie « La documentation graphique en ethnographie métropolitaine » que donna Marcel Maget en 1948 justifiait l’intérêt que présentait le dessin pour la discipline. Il était noté que « la documentation graphique économise de longs discours et, plus qu’eux, elle est susceptible d’examens renouvelés à mesure que les connaissances se développent ». La question technique de la mise au net des dessins l’amenait à revenir sur le sujet à propos des légendes et autres inscriptions ; elles devaient être réduites au minimum : « une planche de dessin est faite pour remplacer ou alléger le discours ; elle n’en doit pas être un à son tour70 ». Dans un travail d’ordre assez similaire, Yves Rigoir posait en 1975 « les bases d’une écriture et d’une grammaire » pour le dessin technique en céramologie alors que l’archéologie se trouvait affrontée à une documentation des plus considérables et, avec elle, au problème de rendre ces matériaux exploitables. La mise en fiche montrait « l’impuissance du langage naturel dans les descriptions d’objets […] Au lieu de les raconter, il faut donc [les] représenter […], et ce de la manière la plus précise possible et qui doit être aussi la plus rapide afin de pouvoir en traiter le plus grand nombre possible71 ». Très récemment, fin des années 2000, il a été proposé de remplacer le texte du résumé des articles scientifiques par un graphical abstract, soit un dessin, une formule, une figure, un schéma résumant de façon concise les principaux résultats. Il doit « permettre aux lecteurs de saisir rapidement le principal message à retenir (take-home message) de l’article ». L’éditeur Elsevier donne sur son site des exemples explicitant ce qu’il faut faire et éviter afin que ce mini-résumé visuel soit simple et clair et qu’il fournisse une compréhension immédiate de l’article72.

Ce florilège de citations, au fil du temps et des disciplines, montre le caractère économique de l’image quelle qu’elle soit, et ce à plusieurs titres. Elle est une solution simple, parfois même très simple – pensons au croquis – pour traduire une réalité complexe. En un espace minime, elle concentre une somme d’informations qu’elle donne à voir dans le rien de temps du coup d’œil. Elle est immédiatement intelligible, du moins, pour les membres d’une communauté, et ceci vaut aussi, comme on le verra, pour des langages symboliques, tel celui de la chimie. Elle joint parfois à l’avantage de l’instantanéité celui de la longue durée ; elle conservera toute sa valeur quand le commentaire, lui, sera périmé ; c’est ce que disait Renan à Mommsen à propos du Corpus inscriptionum semiticarum qu’il dirigea de 1867 à 1892 : « Nos explications feront peut-être sourire nos enfants, quand la science aura fait des progrès par de nouvelles trouvailles ; mais nos héliogravures seront toujours bonnes ; c’est la part de vérité définitive dans notre recueil73 ».

L’emploi de procédés graphiques et l’usage de la couleur augmentent encore les atouts de l’image, outil simple et rapide. Paul Tillaux recourut à la couleur pour les figures de son Traité d’anatomie topographique (1877), un ouvrage sur lequel des générations de chirurgiens français se sont formées : « il m’a semblé, précisait-il, que l’emploi des couleurs simplifierait encore la démonstration et frapperait l’œil en même temps que l’esprit du lecteur74 ». La couleur contribuait encore à l’efficience des cartes topographiques sur lesquelles Lasègue conseillait de reporter les bruits entendus à l’auscultation ; alors que ces « cartes muettes » donnaient une valeur visuelle et durable aux phénomènes auditifs fugaces, les observations portées avec des crayons de couleur contribueraient à une lisibilité aussi rapide qu’aisée75.

L’image est encore plus économique quand elle ne concentre pas seulement des données mais révèle des rapports entre des réalités. Ce que soulignait Condorcet à propos de ces « méthodes techniques » que sont les tables et les tableaux, les présentant comme « l’art de réunir un grand nombre d’objets sous une disposition systématique, qui permette d’en voir d’un seul coup d’œil les rapports, d’en saisir rapidement les combinaisons, d’en former plus facilement de nouvelles76 ». Les tableaux que contiennent des ouvrages d’histoire naturelle publiés fin XVIIIe siècle-début XIXe déclinent cet argumentaire : on saisit « en peu d’instants ce que peut-être on n’aurait pas appris après des lectures de détails arides », on « voit ensemble » des affinités entre groupes de plantes ou d’animaux. En 1797 paraissait le Tableau synoptique de la méthode botanique de Durande : il reprenait dans une carte unique d’environ 32 × 60 cm, « les cinq tableaux d’un volume très embarrassant » de la Flore de Bourgogne que cet auteur avait publiée en 1782. Les avantages en étaient soulignés dans un compte rendu : « Pour faire embrasser d’un seul coup d’œil ce système dans toutes ses ramifications et faciliter les rapprochements, on a réuni ces cinq tableaux dans un seul qui, quoique cinq fois moins volumineux, contient dix fois plus de matière77 ». L’exemple de la carte géographique serait ici majeur ; sa supériorité sur la description textuelle ne ressort que mieux de cette remarque de Vidal de la Blache : « Où trouver un moyen d’expression aussi capable de concentrer les rapports qu’il s’agit de présenter ensemble à l’esprit78 ? ». À un niveau général et élémentaire du travail intellectuel, le même avantage est procuré par cette sorte d’image textuelle qu’est la mise en tableau synoptique ou le simple emploi d’accolades : ils créent des relations au sein d’une information diverse qui a été concentrée et permettent sur un espace limité « de voir les choses d’une seule vue79 ».

Des remarques similaires valent pour les graphiques qui sont devenus la forme majeure de la visualisation scientifique80. Elles ressortent de la comparaison avec une autre forme de présentation des données qui a précédé et subsiste, le tableau de chiffres. Le parallèle fait dans un ouvrage de pédagogie de l’écriture scientifique par deux auteurs qui ont aussi retracé l’histoire de l’article est éloquent. « Les tableaux ont un avantage important en ce qu’ils enregistrent des valeurs exactes et qu’ils facilitent la comparaison de séries de données […] Le principal défaut des tableaux est qu’ils ne sont pas particulièrement utiles pour découvrir ou communiquer des tendances. Les graphiques ont l’avantage considérable que l’on peut voir d’un coup d’œil la relation entre plusieurs ensembles de données et que l’on peut traduire des tendances qui ne sont pas facilement évidentes dans des colonnes de données. Les graphiques ont pour inconvénient qu’en règle générale le lecteur ne peut pas saisir des valeurs exactes. Il y a aussi des limites au nombre de points et de courbes qui peuvent être fourrés sur un seul graphique sous peine de le transformer en un enchevêtrement […] incompréhensible81 ». Cette comparaison des avantages et inconvénients réciproques montre l’atout principal du graphique : la visualisation rapide – aux dépens de la précision – de tendances ainsi que de relations.

Edward Tufte a illustré ce point à partir d’exemples nombreux pris entre le XVIIIe siècle et nos jours. Explorant les diverses modalités de présentation des données quantitatives, il montre l’intérêt supérieur qu’a le plus souvent le graphique par rapport au texte et au tableau de chiffres. De ces remarques, il a tiré un ensemble d’indications pratiques pour atteindre à « l’excellence graphique ». Il la définit comme « donn[ant] au lecteur le plus grand nombre d’idées dans le temps le plus court, en utilisant le moins d’encre possible et en s’en tenant dans le plus petit espace qui soit82 ». Les sparklines (parfois traduit en français par « lignes de tendance ») qu’il a inventés en sont un parfait exemple. Ce sont des graphiques minuscules qui, insérés dans une feuille de calcul, permettent d’afficher les tendances d’une série de valeurs. Ils n’ont ni légende, ni ligne d’axe, ni étiquette, ni graduation. Leur auteur les décrit comme « des graphiques intenses en données, de dessin simple et ayant la taille d’un mot ». Ils sont donc concis et aisément mémorisables tout en représentant des masses de données chiffrées et en offrant, par leur superposition, la possibilité de la comparaison, soit une information de plus83.

Les techniques numériques de fouilles de données et de fouilles de textes permettent de traiter automatiquement et rapidement des masses énormes et complexes défiant la recherche d’information classique. Elles font apparaître des informations, des tendances, des corrélations, des hypothèses auxquelles le spécialiste n’aurait pas pensé, bref, des « informations enfouies ». Elles s’accompagnent souvent de techniques de visualisation afin de rendre certains types de résultats plus suggestifs ou intelligibles, par exemple de faire voir « en un coup d’œil » des tendances84.

La visualisation, ses multiples techniques, outils et produits, tout cela n’est pas allé sans critiques dans le monde scientifique. Celles-ci ont rarement été radicales concluant au refus des images quelles qu’elles soient dans des disciplines où pourtant elles étaient communes. Elles ont largement porté sur l’abus des images inutiles ou impropres, ainsi que sur les défauts multiples de représentations visuelles, de la surcharge à l’ambiguïté en passant par la médiocrité et le manque de standardisation85. Elles n’ont pas freiné le développement de l’image ; il s’en est produit de plus en plus dans le monde scientifique et, au fil des inventions techniques, d’autres images y sont apparues. Le débat pro et contra n’a plus été seulement celui de l’image et du texte, mais celui des images entre elles, entre photo et dessin, entre images fixes et images animées, entre modèles et images sur le papier, etc. L’enjeu central n’en est pas moins resté le même : donner à voir vite, simplement, sûrement86.





Les « habits transparents » du savoir


Cet argumentaire est aussi celui du vecteur linguistique, des modalités langagières et stylistiques pour dire et écrire la science. Il ressort du désir d’une langue scientifique unique et d’un idéal de style d’écriture ; on le voit également à l’œuvre dans l’emploi de technolectes et dans le recours à la métaphore. Du moins, est-ce là que nous le saisirons. Il peut arriver que les arguments se combinent diversement, que l’un soit mis en avant et un autre en retrait ; reste qu’ils se retrouvent comme des invariants, ici et là, jadis et maintenant.

L’aspiration à la restauration ou à l’instauration d’une langue universelle fut forte dans le monde savant. Elle s’exprima dès les années 1640 alors que les vernaculaires gagnaient du terrain dans l’écriture du savoir : le latin était le recours. Ainsi Mersenne proposa la création d’une académie internationale de traducteurs qui mettraient en latin les œuvres jugées d’intérêt commun. Le latin toutefois n’était pas exempt de difficultés et d’ambiguïtés ; s’ajoutait le problème de son inadéquation à dire les réalités de la science moderne. Ces critiques furent particulièrement fortes chez les fabricateurs de langues philosophiques aux XVIIe et XVIIIe siècles. Ceux-ci, quel que soit le système élaboré, se proposaient de construire une langue universelle qui serait rationnelle et d’abord simple, transparente et sans ambiguïté. Rien de concret ne sortit de ces projets, et devant la multiplication croissante des langues, le latin demeura la solution, ne serait-ce que pour éviter de perdre du temps. C’était l’avis de d’Alembert constatant « l’inconvénient » qu’avait généré l’usage, qu’il n’approuvait pas moins, de tout écrire dans sa langue : « avant la fin du dix-huitième siècle, un philosophe qui voudra s’instruire à fond des découvertes de ses prédécesseurs, sera contraint de charger sa mémoire de sept à huit langues différentes ; et, après avoir consumé à les apprendre le temps le plus précieux de sa vie, il mourra avant de commencer à s’instruire. L’usage de la langue latine, dont nous avons fait voir le ridicule dans les matières de goût, ne pourrait être que très utile dans les ouvrages de philosophie, dont la clarté et la précision doivent faire tout le mérite, et qui n’ont besoin que d’une langue universelle ».

Le babélisme ne fit que croître au siècle suivant, et des savants déplorèrent la perte du latin. Pour suivre la production étrangère, Laennec dut se faire lire des travaux et introduire un intermédiaire, ce qui n’allait pas, outre une perte de temps, sans conséquence : « l’interprète le plus intelligent ne peut suppléer à la lecture que l’on ferait soi-même ». Quarante ans plus tard, Marey regrettait tout autant la perte de « la langue scientifique de nos pères, le latin, qui établissait une communication facile entre tous les savants du monde. Il faut aujourd’hui consacrer une partie de sa vie à l’étude des langues, ou se résigner à ne connaître les travaux étrangers que d’une façon sommaire par les analyses si rares et si incomplètes qu’on en fait chez nous ». À la fin du XIXe siècle, la question devint cruciale : si dans l’Europe de 1800 on publiait des ouvrages scientifiques en une dizaine de langues, en 1900 c’est avec plus de vingt langues qu’il fallait compter. Le problème apparaissait dans toute son évidence dans les colloques scientifiques internationaux. La médiocrité des connaissances en langues étrangères qui était celle de la majorité des savants et la multiplication de celles-ci dans ces réunions – de deux à trois au début des années 1880 on était passé à six, voire à sept en 1914 – empêchaient de véritables débats et réduisaient les séances à la lecture de communications que bien des participants ne pouvaient pas comprendre. Cet obstacle linguistique fut d’autant plus préoccupant que les colloques scientifiques internationaux furent alors considérés, devant le fractionnement des disciplines, comme le lieu privilégié d’une nécessaire synthèse. D’où la recherche d’une langue qui servît de véhicule aux échanges dans le monde du savoir. Les tensions nationalistes, particulièrement fortes au tournant du siècle, disqualifiaient d’emblée les langues nationales alors les plus parlées dans la science, le français, l’anglais, l’allemand. Certains s’efforcèrent de restaurer le latin qui avait pour lui des titres historiques ainsi qu’une neutralité de fait ; les critiques quant à son inadéquation à dire parfaitement la science furent les plus fortes.

Au début du XXe siècle, la recherche d’une langue internationale pour la science s’orienta vers une langue artificielle dans un moment, rappelons-le, de grande invention en la matière. La plus remarquable, l’ido, fut scientifiquement construite sous l’égide de savants ; destinée à la communication scientifique, elle se voulait rationnelle, transparente et d’acquisition aisée. Des controverses, puis la guerre, eurent raison d’un succès initial87. Au cours du XXe siècle, l’anglais est devenu la langue internationale de la science. Les grandes revues scientifiques partout dans le monde sont passées à l’anglais – on se rappellera « l’émotion » que provoqua en 1989 l’abandon du français par l’Institut Pasteur pour ses publications ; les périodiques qui demeurent dans des langues autres publient des résumés en anglais88. Ce quasi-monopole de l’anglais a été encore accentué par le discours électronique d’emblée dominé par cette langue, par la supériorité numérique de la communauté anglophone dans le réseau Internet. On reviendra sur les traits stylistiques qui, le distinguant de l’anglais standard, servent sa fonction de communication au sein d’un milieu donné. Il suffisait ici de pointer la fonction de langue véhiculaire unique remplie par l’anglais scientifique qui, conjurant un babélisme croissant, est d’abord le moyen de gagner du temps.

Quelle que soit la langue utilisée, l’écriture de la science moderne a adopté un idéal stylistique afin de transmettre au mieux les connaissances. Mabillon se déclara en faveur d’un style simple et clair qu’il mit en pratique dans ce monument qu’est le De re diplomatica (1681). L’érudit italien Muratori voyait un modèle à imiter dans Descartes « disant clairement tout ce qu’il veut dire, le disant en peu de paroles et avec les seuls mots propres ». Si le style dit simple est un niveau de style qui n’a rien de relâché, si ces érudits connaissaient et employaient au besoin toutes les ressources de la rhétorique pour convaincre du bien-fondé de leurs recherches et pour les diffuser, ils donnaient la primauté à la précision et à la clarté. Une telle écriture était commandée par la démarche érudite visant à établir sur des fondements indiscutables, via une méthode critique, la vérité des faits, une vérité qu’il fallait livrer sans que rien ne vînt la gauchir ou l’occulter. C’est ce qu’avaient eu en vue les savants auteurs de l’Histoire littéraire de la France (1733) : « attentifs jusqu’au scrupule à ne pas altérer cette vérité que nous cherchons sur toutes choses, nous l’exprimons avec fidélité de la manière la plus simple, la plus claire et la plus nette qu’il nous est possible ». La transparence était ici plus qu’un idéal une réalité, à l’instar de ces « habits transparents et subtils » dont Benedetto Bacchini, grand admirateur de Mabillon outre-monts, avait habillé son histoire du monastère de San Benedetto di Polirone (1696), ouvrage où il s’était livré sur la base d’un gros travail documentaire à un sérieux décapage historiographique89.

Cet idéal de style se trouve à la même époque dans le monde des philosophes de la nature. La Royal Society exigeait de ses membres « une façon de parler naturelle, sans ornements, serrant la réalité de près, des expressions précises, des idées claires, une facilité naturelle amenant toutes choses aussi près que possible de l’évidence mathématique90 ». La prose scientifique qu’élabora Robert Boyle ressortit à de mêmes principes. Sa prolixité, qui pourrait amener à une conclusion différente, est justifiée et explicitée par lui en ces termes : « J’ai refusé cette façon succincte d’écrire [… J’ai parfois] rapporté les choses, pour les rendre plus claires, avec une telle multitude de mots que j’apparais, même à mes yeux, coupable de verbosité en divers endroits ». Cette prose, riche en détails, était aussi parfois contournée et Boyle s’en expliquait : « J’ai transgressé sciemment et à dessein les lois de l’éloquence en un point particulier, en l’occurrence, en allongeant parfois à l’excès mes périodes ou mes parenthèses ; car quand je ne pouvais pas dans une période normale inclure ce que j’estimais nécessaire de rapporter en une fois, je préférais négliger les principes de la rhétorique plutôt que de ne pas mentionner ces choses que je jugeais pertinentes à mon sujet et utiles pour vous, mon lecteur ». Détails et détours traduisaient une démarche scientifique : ils suivaient au plus près les réalités observées ; ils étaient aussi la preuve des résultats obtenus et ils facilitaient la reproduction des expériences. Ils ressortissaient à un souci de clarté, comme la manière d’écrire « nue » que revendiquait Boyle disant son hostilité aux ornements et fleurs du discours. Ce style simple que Steven Shapin et Simon Schaffer ont présenté comme une forme d’expression de la modestie me paraît répondre à un tout autre but, d’ordre rhétorico-scientifique : non seulement il est celui qui convient pour ce type de discours mais encore, dans sa nudité, il offre au lecteur l’accès le plus immédiat et le plus sûr au contenu, à la vérité des choses91. Une même « transparence narrative » caractérise l’écriture des savants suisses du XVIIIe siècle, tout particulièrement de ceux qui donnèrent des travaux d’histoire naturelle. Le Journal des savants qui publia un compte rendu élogieux des Mémoires pour servir à l’histoire d’un genre de polypes d’eau douce (1744) d’Abraham Trembley salua tout particulièrement la clarté des descriptions, « telle qu’on pourrait presque se passer de figures, si ce n’est dans des cas fort compliqués » ; le naturaliste genevois, il est vrai, n’avait, de son propre aveu, « rien négligé pour faire voir à d’autres tout ce que j’ai vu ». Pour René Sigrist qui a analysé cet exemple et d’autres, « cette narration transparente, destinée à prouver la qualité des observations et l’habileté de l’observateur lui-même, doit en même temps faciliter la circulation des découvertes au sein de la communauté savante92 ».

Gross, Harmon et Reidy qui ont étudié l’évolution de l’article entre le XVIIe siècle et nos jours ont noté, dès les débuts, l’emploi d’une prose qui peut déjà être qualifiée de « scientifique », ne serait-ce que par l’impression générale d’objectivité qui ressort de l’écriture que ce soit en en anglais ou en français : celle-ci se caractérise « par la quasi-absence des ornements et par une tendance vers un style plus impersonnel ». Au terme de cette histoire, l’anglais scientifique, qui est devenu le discours international de la science, est non seulement une langue spécifique mais aussi un ensemble de traits stylistiques : « des phrases relativement courtes et syntaxiquement simples contenant des propositions nominales complexes, des verbes au passif, des groupes nominaux complexes, des abréviations techniques, des expressions quantitatives et des équations, des références abrégées ». Il en ressort une écriture qui met le focus non sur l’auteur ou sa prose mais sur l’objet de la recherche, une phrase brève qui facilite la lecture, une prose concise et dense en information (les groupes nominaux complexes en sont l’exemple emblématique), soit un système économique qui permet au spécialiste d’aller vite et sûrement dans l’appropriation de l’information. Une culture commune autorise les implicites et les raccourcis : un mot allègue tout un pan de théorie et il est des « trous » que le lecteur comble sans peine ; des développements que le format éditorial court, voire très court de l’article rend impossibles, seraient inutiles, voire contre-productifs93.

Ce souci d’une transparence de l’écriture a pu être impliqué par l’évolution même d’une discipline. La géographie vidalienne et surtout post-vidalienne se caractérise par son réalisme, un attachement aux « réalités », aux « faits » ; d’où un certain nombre de caractéristiques de l’écriture de la géographie avec la mise en place de genres spécifiques ainsi que l’adoption d’un style. Sur ce dernier point, l’écart fut réel et croissant avec le fondateur de l’école française de géographie. Il est vrai que le style de Vidal de la Blache « mêlant explication et compréhension, profondeur des analyses et jubilation scientifique, objectivité et subjectivisme, démonstrations et métaphores [était] difficilement reproductible ». C’est une manière tout autre qui s’instaura, non sans modulations suivant les auteurs. Déjà, la prose de ces élèves de Vidal que furent Albert Demangeon et Lucien Gallois pouvait paraître « comme la quintessence d’une écriture « blanche », dégraissée de tout effet de style, au nom d’un idéal de transparence et d’objectivité ». Le Guide de l’étudiant en géographie de Gérard Cholley (1942) qui constitua surtout dans sa seconde version (1951) le bréviaire du réalisme post-vidalien, contribua à diffuser auprès des impétrants (et jusqu’au début des années 1970) une manière opposée au verbalisme et à tout ce qui était littéraire. Plus généralement, la description littéraire se trouva disqualifiée comme « vague », et un pas supplémentaire dans la délittérarisation de la discipline fut franchi quand on demanda, à l’instar de Philippe Pinchemel, de donner au discours géographique « un caractère scientifique » en y insérant un vocabulaire précis, des valeurs numériques et des données statistiques. Dans les années 1950-1970, les tableaux de données qui ont dans les travaux de Pierre George une place majeure, sont la traduction emblématique, avec le rejet du verbalisme, du souci de « saisir les réalités immédiatement94 ».

Les technolectes, ou langues spécialisées dans une discipline, se caractérisent par « une composante économique, au sens d’efficace, soit l’utilisation d’un minimum de moyens pour un maximum de résultats dans l’échange. Dire beaucoup, vite et sans ambiguïté95 ». On prendra deux exemples. La langue chimique telle qu’elle se construisit aux XVIIe-XVIIIe siècles récupéra, en leur donnant un sens différent, les symboles alchimiques. Ils furent ainsi employés dans des travaux sur les affinités chimiques où, pour présenter les différents degrés d’affinités entre un grand nombre de substances, un système d’abréviations était pratiquement nécessaire ; en recourant à ces symboles au lieu de mots, on pouvait déployer sur un seul tableau tout le système de relations chimiques d’une entière classe de substances. Le chimiste suédois Torbern Bergman dans ses travaux sur le sujet insistait sur la solution économique que ces symboles représentaient : ils sont « particulièrement utiles, écrivait-il en 1775, quand quelque chose doit être écrit rapidement parce qu’en les utilisant on gagne du temps et de l’espace ». Ce devint là un lieu commun. La classification des sels dont beaucoup avaient été découverts dans la première moitié du siècle fut un autre domaine d’emploi des symboles alchimiques, néanmoins adaptés et rationalisés : ici encore, ils permettaient d’abréger un grand nombre de mots en une seule table. À la fin des années 1760, toutefois, se développa l’idée que la chimie ne deviendrait pas ou ne serait pas considérée comme une science tant que son langage ne serait pas entièrement fondé sur la nouvelle philosophie expérimentale, ce qui amenait à réformer radicalement la nomenclature et le symbolisme chimiques ; d’ailleurs, dans bien des cas toutes les formes de symbolisme chimique ou alchimique avaient été abandonnées au profit d’une présentation purement verbale de la science. On passera sur les multiples solutions qui furent projetées pour arriver à celle qui s’imposa avec la Méthode de nomenclature chimique (1787). Lavoisier qui donna les deux mémoires les plus théoriques de cet ouvrage pointait le caractère exemplaire de l’algèbre sur laquelle fonder la langue de la chimie : l’algèbre, écrivait-il, est « la méthode analytique par excellence ; elle a été imaginée pour faciliter les opérations de l’esprit, pour abréger la marche du raisonnement, pour resserrer dans un petit nombre de lignes ce qui aurait exigé un grand nombre de pages de discussion, pour conduire d’une manière plus commode, plus prompte et plus sûre à la solution de questions très compliquées ». Les symboles chimiques construits en conséquence – sur la base de formes géométriques élémentaires – faciliteraient aussi la communication entre savants du monde entier. Il en résulta une table de 54 symboles représentant les substances simples qui, dans leur combinaison, ouvraient sur un nombre considérable de possibilités y compris pour caractériser des substances non encore découvertes96.

Le second exemple est emprunté à la langue juridique. Comme d’autres langues de spécialité, elle est employée par un milieu professionnel donné où elle est facteur d’économie : les locuteurs se comprennent à demi-mot, ce qui se traduit linguistiquement par l’emploi de formules abrégées ou elliptiques, d’abréviations et de sigles, et autres modalités langagières qui peuvent passer pour un jargon. Ce qui est inintelligible pour des non-initiés est parfaitement clair pour les membres de la communauté qui trouvent là un moyen d’aller vite à l’essentiel. Cette modalité est au cœur d’une forme d’énoncé propre au discours juridique : l’adage. Il en est un nombre considérable – en latin ou en français – d’usage courant (et aujourd’hui plus pour les seconds que pour les premiers) dans la doctrine et l’enseignement. Les adages sont concis, voire extrêmement concis : ils tiennent en peu de mots ou, plus précisément disent beaucoup de choses en peu de mots ; bien plus, ils disent l’essentiel, la quintessence d’un savoir partagé dont, par des moyens littéraires (rimes, allitérations, balancements, répétitions, etc.), ils facilitent la mémorisation. Ces formules brèves ont une fonction économique en ce qu’en trois-quatre mots simples elles véhiculent un contenu de savoir parfois hautement complexe sur lequel s’accorde la communauté ; un développement serait long, moins clair quand il ne susciterait pas de multiples exceptions amenant à perdre de vue le principe de base97.

Les technolectes seraient peu perméables à la métaphore, l’à-peu-près de l’image n’étant guère compatible avec les besoins de précision et de rigueur du vocabulaire scientifique98. D’ailleurs, des savants ont condamné cette figure du discours. Pour Hobbes, les métaphores sont absurdes et induisent en erreur à cause de leur caractère affectif ; si elles sont légitimes dans le langage courant, « dans le calcul et la recherche de la vérité, de telles façons de parler ne doivent pas être admises ». Locke montra un même mépris pour le langage figuré décrit comme un ennemi de la vérité : il ne peut qu’« insinuer de fausses idées dans l’esprit » ; il faut donc l’« éviter absolument dans les discours qui sont destinés à l’information et à l’instruction […], partout où la vérité est intéressée99 ». Plus près de nous, Bachelard a dénoncé le danger de l’emploi des métaphores, sources d’approximation : « l’esprit scientifique, écrit-il, doit sans cesse lutter contre les images, contre les analogies, contre les métaphores100 ».

Pourtant le langage scientifique en fait un grand usage. Ainsi, le technolecte du droit ne les ignore pas et celui de la médecine en regorge ; cette dernière discipline est « sans doute [celle] qui utilise le plus d’images » : le seul langage anatomique est riche de plusieurs milliers de métaphores dont l’origine métaphorique a d’ailleurs souvent disparu ; le mot tibia n’évoque plus la flûte latine d’origine101. Bien des savants ont utilisé des métaphores pour énoncer des réalités nouvelles alors que les mots manquaient pour les dire ou les dire aussi bien. C’est ce qu’avouait Laennec dans son Traité de l’auscultation médiate quand il eut recours à la comparaison, à un riche vocabulaire auditif et visuel tiré de l’expérience quotidienne pour exprimer les bruits qu’il entendait au stéthoscope102. Aujourd’hui encore, alors que des tutoriels sur le Web permettent aux apprentis d’entendre les bruits pulmonaires, de surcroît, traduits en courbes de fréquence, le recours à la comparaison demeure : ainsi les râles crépitants sont comparés à un bruit de pas sur la neige ou à du sel jeté dans le feu ou bien sur une poêle (ici Laennec disait « dans une bassine103 »). La métaphore n’a pas servi qu’à mettre en forme et à transmettre ; elle a aussi été pour des chercheurs un moyen d’explorer leurs objets d’étude104. À son désavantage, on a noté son caractère « situé » – il est des métaphores auditives qui ne fonctionnent pas dans une autre langue105 – et le risque qu’il peut y avoir à ne pas s’en déprendre106. Reste que dans une utilisation maîtrisée107, la métaphore est, par « sa capacité à produire de la connaissance et à dénommer », un véritable « outil scientifique108 » ; elle permet d’aller tout aussi vite et sûrement que simplement en ce qu’elle repose sur des éléments de culture familiers et partagés dans une communauté. Encore son caractère frappant joue dans l’économie du processus.



*

* *

Tout au long de ce chapitre où l’on a pris le point de vue des usagers, sont revenus de mêmes arguments caractérisant les outils intellectuels à leur disposition : ils permettent d’aller vite, simplement et sûrement, c’est-à-dire de façon économique en temps et en moyens, du moins par rapport à une modalité précédente ou autre. À vrai dire, cet argumentaire n’est pas si extraordinaire que cela ; ce sont les raisons contraires qui le seraient. Sa banalité, toutefois, prend un certain relief quand on constate qu’il fonctionne, et quasiment dans les mêmes termes, tout au long des cinq siècles étudiés, pour quelque instrument que ce soit, du catalogue-matières de bibliothèque à la métaphore en passant pêle-mêle par le journal d’abstracts, le graphique, le format IMRAD ou le portail documentaire. Il vaut tout autant pour les bureaux que projetèrent autrefois Paul Otlet ou Vannevar Bush et aujourd’hui pour les tables de travail informatiques. Tout le Web, soit une masse colossale d’informations, est à portée de main avec des facilités de travail et les économies de temps qui vont de pair ; en parallèle des techniques sont mises au point ou à l’étude pour pallier les problèmes (et notamment la dépense de temps) qu’amènent de nouvelles pratiques. La création de murs interactifs permet des usages impossibles avec les écrans d’ordinateurs aux dimensions limitées. La plateforme Wild (Paris-Sud, 2009), concrètement un mur (5,5 × 1,8 m) tapissé de 32 écrans d’ordinateurs, permet d’accéder « immédiatement à un grand nombre de documents », d’« appréhender d’un coup d’œil d’importantes quantités d’informations », « de passer d’une vue d’ensemble à une vue détaillée simplement en se déplaçant physiquement », tout en offrant les moyens d’une interaction directe avec les informations affichées109.

Ces arguments auraient comme leur symbole dans une expression qui est revenue très fréquemment : d’un coup d’œil, locution qui dit à la fois un laps de temps très court (celui du clin d’œil) et l’acuité d’un regard. Elle connoterait le travail intellectuel même, tel que le décrit d’Alembert quand il s’agit d’embrasser l’encyclopédie des connaissances, de les rassembler dans « le plus petit espace possible ». Le philosophe doit se placer « au-dessus de ce vaste labyrinthe dans un point de vue fort élevé d’où il puisse apercevoir à la fois les sciences et les arts principaux ; voir d’un coup d’œil les objets de ses spéculations et les opérations qu’il peut faire sur ces objets ; distinguer les branches générales des connaissances, les points qui les séparent ou les unissent, et entrevoir même quelquefois les routes secrètes qui les rapprochent110 ». Ce regard rapide et expert saisissant l’information qui importe dans une masse touffue de données, matérialise à son meilleur l’économie de la pratique scientifique.



Conclusion




* * *





L’émission Apostrophes consacrée à Georges Dumézil s’ouvre sur un panoramique de sa bibliothèque montrant « des milliers, milliers de livres ; il y en a partout », et la caméra de suivre ces livres « montant des planchers, descendant des plafonds ». Vision assurément saisissante mais qui pourtant ne dévoile qu’un seul des outils mobilisés par un savant qui en employa d’autres : l’écriture, la parole et, même si c’est dans une petite mesure, l’image1.

Au terme d’un parcours de cinq siècles dans le monde du travail scientifique, le constat s’impose de la masse et de la diversité de l’outillage, que l’on zoome sur une époque, sur une discipline ou sur une activité. Et l’inventaire s’augmente considérablement lorsque de la bibliothèque on passe dans d’autres lieux du savoir, le laboratoire, la salle de cours et de conférences, l’hôpital, le terrain ; il n’est pourtant pas exhaustif. Plus encore que le nombre qui défie le comptage, frappe la déclinaison presque à l’infini de certains outils, processus qui augmente encore l’effet de masse : ainsi, le périodique savant a, depuis 1665, engendré une gamme immense de produits, et le graphique, inventé au XVIIIe siècle, s’est diversifié à l’extrême. À ce point, on ne peut qu’être fascinée par l’inventivité humaine. S’ajoutent encore les ressources que les usagers apportent avec eux, leur corps, un corps dressé, des sens éduqués, aiguisés et affinés, le coup d’œil de l’historien d’art, le toucher expert du céramologue, le « flair médical » du clinicien.

L’outillage livré par l’inventaire n’est pas seulement nombreux, voire pléthorique ; il est souvent plus complexe qu’il ne semble. Des outils, apparemment simples, sont en fait des composites unissant des éléments dérivés de technologies diverses, en quelque sorte des produits multimédias. On a pu caractériser ainsi le cahier de laboratoire habituellement classé parmi les manuscrits. Les combinaisons intègrent à l’occasion les progrès successifs de la technique quand ce ne sont pas des innovations. Le livre dit illustré est un produit bimodal qui, au fil du temps, a inclus les avancées de la gravure, puis de la photo. Le poster papier fusionne écrit et image en un tout interactif au service de la parole, intégrant dans sa version électronique de l’audiovisuel. Cette multimédialité ressort davantage dès que l’on déplace le regard des outils vers leur mise en œuvre quand ils se combinent entre eux, quand s’interrelient ressources matérielles et sensorielles comme il l’a été abondamment montré aux chapitres 3 et 4. La description de bien des outils et, plus encore, l’observation du travail scientifique, pour le présent comme par le passé, révèlent des combinaisons ou des agencements que l’on pourrait qualifier de transhistoriques en ce qu’ils conjuguent des ressources nées à des époques diverses, sans compter, et on ne sait toujours trop où les situer sur l’échelle du temps, les techniques du corps et des sens. Ceci ne chasse pas cela.

Ce constat amène une question de fond. Depuis la publication de l’ouvrage de Jack Goody, La Raison graphique – et le titre français n’a pas été sans radicaliser la thèse –, on tend à lier changement dans les outils de la connaissance et changement dans les opérations cognitives. Ce serait presque devenu un lieu obligé2. Qu’en est-il alors que les savants manient en même temps de multiples techniques, que des techniques elles-mêmes sont multimodales, qu’une nouvelle technique s’ajoute aux précédentes, voire se combine avec elles ? La complexité est parfois extrême et les conséquences paraissent difficilement identifiables et rapportables à une seule technologie de l’intellect. Aujourd’hui alors que l’on parle de révolution numérique, les témoignages sur les usages de la nouvelle technologie dans le monde savant, outre qu’ils dénotent un certain illettrisme, modéreraient l’idée d’une révolution cognitive. En 1996, une étude portant sur la question (limitée) de la transformation de la communication scientifique liée au passage de l’imprimé à l’électronique dans trois domaines de pointe (le projet génome humain, la physique des hautes énergies et l’astrophysique) concluait en termes non de révolution, mais d’évolution, de modernisation, non de transformation. On était, il est vrai, à un stade précoce de l’usage de la nouvelle technologie. Les auteurs constataient la permanence du système des valeurs attaché à la science. Des changements ne se faisaient pas moins jour qui affectaient l’économie scientifique (compétition accrue, changements dans les institutions et forces de travail, plus grande inégalité dans la distribution des ressources) ainsi que le travail même : mais c’était en termes de vitesse, de sûreté, de facilité, d’échange d’idées3. Près de nous, en 2011, alors que le numérique n’est plus dans son enfance, des historiens, utilisateurs actifs des nouveaux outils, font état de changements dans le travail quotidien, soit des transformations dans les pratiques documentaires, dans les modes de diffusion des travaux, dans les formes de collaboration ; pour autant, à la lumière des retours d’expérience, « la révolution numérique ne […] semble pas conduire à un changement des fondements épistémologiques qui président aux conditions de production de la vérité historique » ; et s’il est fait état d’« importantes conséquences cognitives », c’est pour le futur et sans plus de précisions4. Ici, comme ailleurs et par le passé, l’apparition de nouveaux outils et, plus exactement, leur utilisation ont bien une incidence, mais c’est sur les arts de faire qu’elle s’exerce, sur le travail même. Pour les modes de pensée et la structure de la connaissance, demain, peut-être ?

Ces outils multiples, qu’ils soient anciens ou modernes, sont généralement employés sans dire. Leur objectivation donne à voir non seulement leur rôle dans la production du savoir mais plus encore montre qu’ils en sont partie constitutive. Ce qui ressort de bien des situations qui ont été décrites. On y insistera en reprenant l’exemple modeste de la fiche. Pour Langlois et Seignobos, elle rendait déjà le travail intellectuel plus sûr comme il ressortait du contraste qu’ils opéraient avec « ce procédé barbare » qui, mis en œuvre par des historiens, consistait à « enregistrer simplement les documents dans sa mémoire, sans en prendre note par écrit » ; le résultat était des citations et références inexactes. La fiche, comme tout écrit, offrait une garantie face à la fragilité de la mémoire. Mais faire des fiches était plus que se livrer à un simple enregistrement. Le travail, tel que Langlois et Seignobos le prescrivaient, n’était pas un acte mécanique de copie ; c’était une opération intellectuelle de choix et d’analyse, comme l’étaient les mots-clefs et les cross-references dont le « travailleur » assortirait chaque fiche, conjuguant pour cette opération idées et « habitudes matérielles5 ». Dans « le système des fiches » exposé par les deux historiens n’entrait pas un outil minuscule qui pourtant complète le dispositif, le cavalier6. Jean Guitton, dans son ouvrage consacré au travail intellectuel, en justifia l’usage. Après avoir détaillé ce que devait être l’élaboration toute matérielle des notes en « fiches verticales » et indiqué des modes de classement, il s’arrêtait au rôle des cavaliers, qui n’était pas que de simple aide à une manipulation efficace et rapide d’un gros fichier. Placés sur certaines fiches et distinguant par un jeu de couleurs, par exemple, celles qui étaient jugées plus importantes ou, dans une série classée en ordre historique, celles qui se rapportaient à une même idée, « ces moyens de signalisation » permettaient « de donner à un même paquet de fiches des axes différents » et « sans modifier l’ordre provisoirement choisi de préparer d’autres séries, d’autres mobilisations possibles ». Sans cavaliers, le fichier serait une masse compacte et muette de bristols verticaux. Ces « petits signes en carton ou en acier souple verni » lui donnaient organisation et sens ; ils ouvraient des possibilités de connaissance autres que les contenus un jour notés7. Comme la fiche et son cavalier, le format IMRAD, les graphiques, les maquettes, la photo aérienne et bien d’autres instruments que l’on a décrits sont des outils authentiques de production du savoir. Le dessin scientifique et technique n’est pas seulement la réalisation d’une image mais un acte d’analyse et de pensée. C’est ce que disent des archéologues, des ingénieurs ou des zoologistes et que l’on retrouve dans un propos anecdotique de l’architecte Michael Graves qui fut aussi professeur à l’université de Princeton. « Il y a des années, j’assistais à un conseil plutôt ennuyeux de l’université. Pour passer le temps, je sortis un bloc et je me mis à dessiner un plan, probablement de quelque bâtiment que j’étais en train de concevoir. Un collègue qui s’ennuyait tout autant me regarda avec amusement. Après un moment d’indécision, je lui passais le bloc. Il ajouta quelques traits et me le rendit. La partie commença. Les allers-retours se succédèrent. […] Alors que nous ne nous parlions pas, nous étions engagés dans un dialogue sur ce plan. […] C’était l’acte de dessiner qui nous permettait de spéculer8. »

Prêter attention aux outils multiples mis en œuvre dans la production et la communication du savoir amène, pour le moins, une vision plus riche du travail scientifique que celle que ne livrent la triade chronologique écrit-imprimé-numérique ou le produit fini du livre, de l’article ou de l’image. Alors que l’histoire intellectuelle tendrait à placer ces outils, lorsqu’elle les considère, dans une sorte d’à-côté des idées, une archéologie des usages amène à un point de vue autre, en montrant le jeu complexe des instruments et des idées. Comme l’on a pu parler d’une « histoire sociale des idées » en mettant l’accent sur les agents qui les portent ou les relaient, on pourrait ici parler d’une « histoire matérielle des idées », en intégrant aussi dans cette matérialité les ressources de l’outil-corps.

À ce point s’ouvre une question que l’on ne fera que poser. Les techniques du corps, dont on a vu la place et le rôle, s’accompagnent, toutes réglées qu’elles soient, d’un élément personnel, d’une dimension sensible. Ce qui ressort particulièrement bien dès que toucher, voir, entendre, sentir sont en jeu, n’apparaît pas moins ailleurs dans ce qui a été notre domaine d’investigation : dans des témoignages affectifs des chercheurs envers leurs objets de recherche ou leurs instruments de travail ; dans des traductions graphiques qui, liant vérité et beauté, plaisent aux yeux sans pour autant sacrifier le sens (Beautiful Evidence s’intitule un des ouvrages d’Edward Tufte sur la visualisation scientifique) ; dans une écriture qui use de toutes les ressources rhétoriques pour véhiculer le savoir, à commencer par une transparence sublime (simplex sed tamen sublimis, disait, non sans admiration, Jean Bernoulli à propos du style de Leibniz9). Ces quelques remarques, sans compter toutes celles que suggère la mise en œuvre des outils10, amèneraient à s’interroger dans les faits sur ce principe cardinal du travail scientifique qu’est l’objectivité. Cette notion, qui serait apparue au XIXe siècle11, ne résiderait-elle pas davantage dans les méthodes et les idées que dans les outils maniés ? Peut-être parce que ceux-ci sont d’un emploi le plus souvent tacite ou, plus précisément, moins réfléchi, je n’ose écrire moins objectivé, que ne le sont les méthodes et les idées.

Ce qui ne veut pas dire que les outils en soi n’ont pas été discutés, raisonnés, pour le moins quand ils sont apparus ou quand ils ont laissé place à d’autres. Les discours des usagers révèlent, au-delà des argumentaires particuliers, des raisons de fond peu nombreuses et toujours les mêmes à l’appui de tel ou tel outil : il permet d’aller vite, simplement, sûrement, à la chose qui importe, et cela dans un contexte qui a toujours pour coordonnées l’abondance et l’urgence. Il en ressort une efficacité dans le travail, une rapidité et sûreté de l’action, que symbolise on ne saurait mieux le coup d’œil. L’anthropologie des savoirs les rapporte volontiers à des ruses de l’intelligence, à la mètis12 ? Faut-il s’arrêter aux Grecs et à l’histoire ? On peut aller, je pense, plus loin, jusqu’à des principes mêmes de l’activité humaine, à ce que l’on appelle aujourd’hui simplexité. Cette notion – qui n’a rien à voir avec la simplification – désigne des solutions mises en place par les êtres vivants pour réaliser des choses complexes par des procédures simples, pour « traiter très rapidement des informations ou des situations […] sans dénaturer la complexité du réel » ; et ces solutions ne sont « ni des caricatures, ni des raccourcis, ni des résumés », mais des modalités qui, « posant le problème autrement, […] permettent d’arriver à des actions plus élégantes, plus rapides, plus efficaces. Elles permettent aussi de maintenir ou de privilégier le sens, même au prix d’un détour ». Ces citations sont empruntées à un ouvrage d’Alain Berthoz qui porte largement sur le domaine hautement spécialisé de la neurophysiologie. Les deux très rapides remarques que cet auteur fait, pour l’ordre littéraire, sur la métaphore ainsi que sur le dessin « qui vaut mieux que mille mots » inviteraient à placer nombre des outils qui ont été ici décrits dans un futur « dictionnaire de la simplexité » et, en attendant, de les qualifier de simplexes13. Ne se proposent-ils pas de traiter la complexité des choses avec rapidité, efficacité, économie et parfois aussi une grande élégance ?